{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data prepossessing\n",
    "\n",
    "`reuters_data` comes in two flavours: json and sgm. Although we were not allowed to use json data, a comparison of prepossessing of both data sets was compiled. json was easier to use, as it is structured as a dictionary: one can access the desirable field via key:value pair. Also, due to the nature of processing data in sgm format, the time complexity rises dramatically, when dealing with sgms. BS4 has to read-in and search all the required tags, then they are cleaned with regex. One can also create a class `ReutersParser`, where end and start tags are stored as booleans and make it more efficient, yet this method was not used. A decision had to be made how to deal with multi-labels and NaNs. One of the options was to process only the first label of the list, second option was to use `MulitLabelBinarizer()`. First option was chosen, however, it also impacted the models' ability to predict data in real-world: if it's trained only on one label, it can predict only one as well. Finally, ideally the data would be shuffled, but in this design it is not.\n",
    "\n",
    "**Newsgorups**\n",
    "As `newsgroups_data` is part of sklearn utilities, it has many pre-defined functionalities, which come in handy: shuffling, `target_names` and others are available as attributes. Unlike \\path{reuters_data}, the classes in this dataset are less numerous, more balanced and there are none tags with missing data. Thus, the model has more to train on, which allegedly will yield higher accuracy as compared to Reuters data set.\n",
    "\n",
    "**Data splitting**\n",
    "For both data sets two versions of data splitting were used, 90/10 and 80/20, respectively.\n",
    "\n",
    "**Feature extraction**\n",
    "For all three models and both data sets `CountVectorizer()` and `TfIdfTransformer()` were chosen. As best practice dictates, stop-words were eliminated from the data. Initially bi-grams were used, however, after evaluating different parameters, uni-grams were chosen, as it resulted in higher accuracy. There was no need for either pre-tokenization or parsing because it is automatically done by CountVectorizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import path\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Followed this cheat_sheet: https://intellipaat.com/mediaFiles/2018/12/Sklearn-cheat-sheet.png\n",
    "\n",
    "**DATA**\n",
    "\n",
    "1. Reuters. \n",
    "   1. a) json: More infromation at: https://github.com/mihaibogdan10/json-reuters-21578\n",
    "   1. b) sgm: More infromation at: http://kdd.ics.uci.edu/databases/reuters21578/reuters21578.html\n",
    "2. Newsgroups. More infromation at: https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading data: REUTERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 1 json version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_json(path_name):\n",
    "    corpus, json_dict, index = list(), dict(), 0\n",
    "    title_list = [title for title in os.listdir(path_name) if title.endswith('.json')]\n",
    "    for title in title_list:\n",
    "        with open(os.path.join(path_name, title)) as json_file:\n",
    "            json_text = json.load(json_file)\n",
    "            for item in json_text:\n",
    "                json_dict[index] = item\n",
    "                corpus.append(item[\"body\"].lower())\n",
    "                index += 1\n",
    "    return corpus, json_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    corpus, all_files = from_json('./json-reuters-21578/json-data')\n",
    "except:\n",
    "    !git clone https://github.com/mihaibogdan10/json-reuters-21578.git\n",
    "finally:\n",
    "    corpus, all_files = from_json('./json-reuters-21578/json-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21578"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_files.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counts of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['money-fx', 'interest'] 1\n",
      "['crude', 'nat-gas'] 14\n",
      "['crude', 'ship'] 16\n",
      "['trade', 'gnp', 'bop', 'dlr'] 18\n",
      "['interest', 'money-fx', 'dlr'] 19\n",
      "['gnp', 'jobs', 'cpi', 'bop', 'dfl'] 23\n",
      "['money-fx', 'gnp'] 30\n",
      "['money-fx', 'interest'] 43\n",
      "['hog', 'livestock'] 56\n",
      "['money-fx', 'interest'] 59\n",
      "['trade', 'bop', 'money-fx', 'crude', 'gnp', 'dlr'] 64\n",
      "['money-fx', 'interest'] 67\n",
      "['money-fx', 'dlr', 'dmk'] 75\n",
      "['grain', 'oilseed'] 81\n",
      "['grain', 'meal-feed', 'carcass', 'soy-meal', 'livestock'] 83\n",
      "['pet-chem', 'acq'] 119\n",
      "['money-fx', 'interest'] 120\n",
      "['grain', 'wheat', 'barley'] 131\n",
      "['meal-feed', 'fishmeal'] 134\n",
      "['money-fx', 'interest'] 136\n",
      "['grain', 'wheat', 'corn'] 137\n",
      "['crude', 'nat-gas'] 144\n",
      "['interest', 'money-fx'] 163\n",
      "['crude', 'nat-gas'] 168\n",
      "['acq', 'crude', 'nat-gas'] 173\n",
      "['grain', 'corn', 'sugar'] 190\n",
      "['oilseed', 'rapeseed'] 205\n",
      "['acq', 'earn'] 241\n",
      "['gnp', 'money-supply'] 245\n",
      "['money-fx', 'dlr', 'trade', 'acq'] 266\n",
      "['grain', 'wheat'] 271\n",
      "['hog', 'l-cattle', 'livestock'] 277\n",
      "['oilseed', 'soybean', 'grain', 'corn', 'wheat'] 281\n",
      "['interest', 'stg'] 282\n",
      "['money-fx', 'interest'] 291\n",
      "['grain', 'corn', 'wheat', 'oilseed'] 298\n",
      "['grain', 'corn'] 305\n",
      "['cocoa', 'coffee', 'sugar', 'heat'] 309\n",
      "['grain', 'wheat'] 313\n",
      "['carcass', 'livestock', 'hog'] 317\n",
      "['grain', 'wheat'] 322\n",
      "['grain', 'barley'] 323\n",
      "['grain', 'wheat', 'corn'] 329\n",
      "['grain', 'wheat'] 333\n",
      "['grain', 'wheat'] 334\n",
      "['grain', 'corn'] 336\n",
      "['trade', 'bop', 'money-fx', 'dlr'] 337\n",
      "['grain', 'corn', 'wheat', 'rice'] 357\n",
      "['grain', 'ship'] 385\n",
      "['grain', 'wheat', 'corn'] 400\n",
      "['gnp', 'cpi', 'money-fx'] 410\n",
      "['money-fx', 'dlr', 'yen'] 418\n",
      "['money-fx', 'dlr', 'yen'] 420\n",
      "['grain', 'corn', 'wheat'] 428\n",
      "['grain', 'wheat', 'rice'] 444\n",
      "['oilseed', 'soybean'] 452\n",
      "['zinc', 'lead', 'copper'] 453\n",
      "['oilseed', 'soybean'] 457\n",
      "['oilseed', 'soybean'] 466\n",
      "['interest', 'money-fx'] 492\n",
      "['earn', 'strategic-metal'] 496\n",
      "['veg-oil', 'palm-oil'] 498\n",
      "['trade', 'bop'] 511\n",
      "['money-supply', 'interest'] 523\n",
      "['money-fx', 'yen', 'trade'] 531\n",
      "['money-fx', 'stg', 'can'] 534\n",
      "['oilseed', 'soybean', 'veg-oil', 'palm-oil', 'coconut-oil'] 539\n",
      "['gold', 'silver'] 573\n",
      "['trade', 'money-fx', 'cpi', 'reserves'] 592\n",
      "['hog', 'livestock'] 594\n",
      "['bop', 'trade'] 609\n",
      "['copper', 'earn'] 612\n",
      "['bop', 'trade'] 614\n",
      "['gold', 'silver'] 645\n",
      "['money-fx', 'stg'] 665\n",
      "['trade', 'sugar'] 689\n",
      "['grain', 'wheat'] 736\n",
      "['crude', 'nat-gas'] 797\n",
      "['grain', 'corn'] 846\n",
      "['gas', 'grain', 'corn'] 854\n",
      "['copper', 'zinc', 'silver'] 861\n",
      "['acq', 'silver'] 867\n",
      "['crude', 'ship'] 868\n",
      "['grain', 'corn'] 880\n",
      "['grain', 'wheat'] 896\n",
      "['carcass', 'livestock'] 900\n",
      "['grain', 'wheat'] 903\n",
      "['acq', 'crude'] 905\n",
      "['grain', 'wheat'] 912\n",
      "['lumber', 'plywood'] 941\n",
      "['grain', 'corn'] 948\n",
      "['veg-oil', 'sun-oil', 'corn-oil', 'rape-oil'] 949\n",
      "['coffee', 'ship'] 954\n",
      "['grain', 'corn', 'soybean', 'oilseed'] 978\n",
      "['grain', 'corn', 'sorghum', 'sunseed', 'oilseed'] 980\n",
      "['gas', 'fuel', 'crude'] 994\n",
      "['grain', 'corn'] 1032\n",
      "['grain', 'corn', 'sorghum', 'sunseed', 'wheat', 'oilseed', 'soybean'] 1042\n",
      "['pet-chem', 'crude', 'acq', 'earn'] 1062\n",
      "['grain', 'wheat'] 1096\n",
      "['grain', 'corn', 'oilseed', 'soybean'] 1105\n",
      "['oilseed', 'rapeseed'] 1128\n",
      "['grain', 'wheat'] 1131\n",
      "['money-fx', 'dlr', 'interest'] 1211\n",
      "['crude', 'earn'] 1237\n",
      "['livestock', 'carcass'] 1253\n",
      "['trade', 'iron-steel'] 1261\n",
      "['grain', 'wheat'] 1270\n",
      "['grain', 'wheat'] 1272\n",
      "['grain', 'corn'] 1286\n",
      "['livestock', 'l-cattle'] 1289\n",
      "['trade', 'iron-steel'] 1312\n",
      "['nat-gas', 'crude'] 1321\n",
      "['gas', 'crude'] 1338\n",
      "['veg-oil', 'grain', 'corn', 'wheat'] 1340\n",
      "['gas', 'crude'] 1343\n",
      "['crude', 'gas'] 1350\n",
      "['interest', 'money-fx'] 1363\n",
      "['grain', 'rice'] 1366\n",
      "['acq', 'trade'] 1371\n",
      "['trade', 'money-fx'] 1374\n",
      "['money-fx', 'interest'] 1377\n",
      "['wheat', 'grain'] 1387\n",
      "['platinum', 'strategic-metal', 'palladium'] 1419\n",
      "['dlr', 'money-fx'] 1430\n",
      "['money-fx', 'interest'] 1435\n",
      "['dlr', 'money-fx'] 1441\n",
      "['money-fx', 'interest'] 1443\n",
      "['dlr', 'money-fx'] 1448\n",
      "['trade', 'money-fx'] 1451\n",
      "['dlr', 'money-fx'] 1459\n",
      "['wheat', 'grain'] 1471\n",
      "['grain', 'oilseed', 'veg-oil', 'sorghum', 'sun-meal', 'lin-oil', 'groundnut-oil', 'soy-oil', 'rape-oil', 'sun-oil', 'wheat', 'meal-feed'] 1499\n",
      "['crude', 'heat'] 1519\n",
      "['money-fx', 'interest'] 1521\n",
      "['grain', 'ship'] 1530\n",
      "['hog', 'livestock'] 1531\n",
      "['oilseed', 'soybean'] 1535\n",
      "['money-fx', 'interest'] 1538\n",
      "['dlr', 'yen'] 1548\n",
      "['interest', 'money-supply', 'trade'] 1551\n",
      "['grain', 'rice', 'wheat', 'sorghum'] 1566\n",
      "['grain', 'wheat'] 1571\n",
      "['oilseed', 'groundnut'] 1573\n",
      "['wheat', 'grain'] 1581\n",
      "['money-fx', 'interest'] 1614\n",
      "['grain', 'corn', 'wheat', 'barley'] 1617\n",
      "['dlr', 'money-fx'] 1624\n",
      "['carcass', 'livestock'] 1641\n",
      "['trade', 'bop'] 1645\n",
      "['corn', 'grain'] 1647\n",
      "['grain', 'barley'] 1648\n",
      "['grain', 'barley', 'corn', 'wheat'] 1675\n",
      "['dlr', 'money-fx'] 1676\n",
      "['oilseed', 'soybean', 'grain', 'corn', 'wheat'] 1685\n",
      "['dlr', 'money-fx'] 1688\n",
      "['sugar', 'ship'] 1695\n",
      "['grain', 'ship'] 1709\n",
      "['grain', 'corn'] 1719\n",
      "['oilseed', 'rapeseed'] 1720\n",
      "['trade', 'coffee'] 1724\n",
      "['grain', 'ship'] 1725\n",
      "['sugar', 'ship'] 1726\n",
      "['grain', 'ship', 'wheat', 'barley'] 1727\n",
      "['trade', 'coffee'] 1736\n",
      "['veg-oil', 'soy-oil'] 1750\n",
      "['livestock', 'carcass'] 1797\n",
      "['grain', 'wheat'] 1835\n",
      "['grain', 'corn', 'wheat', 'oilseed', 'soybean'] 1844\n",
      "['grain', 'wheat', 'cotton', 'soybean', 'soy-oil', 'veg-oil', 'oilseed', 'soy-meal', 'meal-feed'] 1852\n",
      "['grain', 'corn'] 1855\n",
      "['grain', 'corn', 'wheat'] 1859\n",
      "['grain', 'wheat', 'corn'] 1862\n",
      "['grain', 'wheat'] 1863\n",
      "['oilseed', 'soybean'] 1864\n",
      "['grain', 'wheat'] 1865\n",
      "['grain', 'wheat'] 1867\n",
      "['grain', 'wheat'] 1868\n",
      "['grain', 'wheat'] 1869\n",
      "['grain', 'corn', 'oilseed', 'soybean', 'soy-meal', 'meal-feed', 'veg-oil', 'soy-oil', 'cotton', 'sorghum', 'cotton-oil', 'barley', 'oat', 'rice'] 1870\n",
      "['grain', 'wheat'] 1873\n",
      "['grain', 'oilseed', 'meal-feed', 'veg-oil', 'corn', 'wheat', 'soybean', 'soy-oil', 'soy-meal', 'cotton', 'rice', 'sorghum', 'barley', 'oat'] 1874\n",
      "['grain', 'corn'] 1876\n",
      "['grain', 'oilseed', 'meal-feed', 'veg-oil', 'wheat', 'corn', 'soybean', 'soy-oil', 'soy-meal', 'cotton'] 1889\n",
      "['grain', 'wheat'] 1892\n",
      "['grain', 'wheat'] 1894\n",
      "['meal-feed', 'soy-meal'] 1902\n",
      "['grain', 'corn'] 1903\n",
      "['grain', 'wheat', 'corn', 'oilseed', 'soybean', 'meal-feed', 'soy-meal', 'veg-oil', 'soy-oil', 'cotton', 'rice'] 1905\n",
      "['grain', 'corn'] 1909\n",
      "['grain', 'meal-feed', 'wheat', 'corn', 'soy-meal'] 1910\n",
      "['grain', 'wheat'] 1915\n",
      "['grain', 'wheat', 'soybean', 'corn', 'sorghum', 'oilseed', 'sunseed'] 1916\n",
      "['oilseed', 'soybean'] 1920\n",
      "['meal-feed', 'soy-meal'] 1921\n",
      "['veg-oil', 'soy-oil'] 1922\n",
      "['grain', 'wheat'] 1926\n",
      "['grain', 'rice'] 1927\n",
      "['grain', 'ship'] 1941\n",
      "['grain', 'wheat', 'corn', 'barley', 'oat', 'sorghum'] 1951\n",
      "['oilseed', 'soybean', 'soy-meal', 'meal-feed'] 1952\n",
      "['grain', 'oilseed', 'meal-feed', 'veg-oil'] 1974\n",
      "['grain', 'corn', 'oilseed', 'soybean'] 1998\n",
      "['gnp', 'cpi', 'bop'] 2004\n",
      "['money-fx', 'dlr'] 2020\n",
      "['money-fx', 'dlr'] 2022\n",
      "['money-supply', 'money-fx', 'dlr'] 2027\n",
      "['money-fx', 'reserves'] 2039\n",
      "['ship', 'grain'] 2054\n",
      "['oilseed', 'soybean'] 2056\n",
      "['grain', 'rice'] 2058\n",
      "['money-fx', 'dlr', 'yen', 'bop', 'gnp'] 2060\n",
      "['gnp', 'bop'] 2074\n",
      "['veg-oil', 'palm-oil'] 2087\n",
      "['crude', 'nat-gas'] 2109\n",
      "['acq', 'gold'] 2151\n",
      "['grain', 'corn', 'rice'] 2164\n",
      "['grain', 'wheat'] 2168\n",
      "['interest', 'money-fx'] 2200\n",
      "['grain', 'wheat'] 2212\n",
      "['money-fx', 'interest'] 2228\n",
      "['money-fx', 'interest'] 2236\n",
      "['livestock', 'carcass'] 2268\n",
      "['acq', 'nat-gas'] 2270\n",
      "['grain', 'wheat', 'oat', 'barley'] 2274\n",
      "['oilseed', 'rapeseed'] 2276\n",
      "['grain', 'wheat'] 2321\n",
      "['tin', 'veg-oil', 'palm-oil', 'alum'] 2366\n",
      "['rice', 'grain', 'meal-feed'] 2387\n",
      "['crude', 'pet-chem', 'propane'] 2396\n",
      "['ship', 'crude'] 2402\n",
      "['zinc', 'lead'] 2430\n",
      "['trade', 'bop'] 2443\n",
      "['lead', 'zinc'] 2476\n",
      "['crude', 'fuel', 'naphtha'] 2496\n",
      "['money-fx', 'nkr'] 2536\n",
      "['money-fx', 'nkr'] 2540\n",
      "['grain', 'wheat', 'oilseed', 'rapeseed'] 2548\n",
      "['trade', 'livestock', 'hog'] 2554\n",
      "['cocoa', 'cotton', 'coffee'] 2569\n",
      "['acq', 'oilseed', 'sunseed', 'soybean'] 2629\n",
      "['grain', 'rye', 'wheat', 'barley', 'oat', 'oilseed', 'rapeseed', 'sugar'] 2667\n",
      "['trade', 'tea', 'coffee', 'cotton', 'castor-oil'] 2671\n",
      "['ship', 'crude'] 2683\n",
      "['interest', 'money-fx'] 2688\n",
      "['interest', 'money-fx'] 2692\n",
      "['grain', 'corn', 'oilseed', 'soybean'] 2720\n",
      "['ship', 'crude'] 2755\n",
      "['gold', 'zinc', 'lead', 'silver'] 2763\n",
      "['oilseed', 'soybean', 'grain', 'wheat', 'corn'] 2820\n",
      "['grain', 'rice', 'cotton'] 2834\n",
      "['money-fx', 'crude'] 2868\n",
      "['interest', 'housing'] 2874\n",
      "['crude', 'naphtha', 'pet-chem'] 2902\n",
      "['trade', 'trade'] 2917\n",
      "['trade', 'grain', 'rice', 'cotton'] 2946\n",
      "['crude', 'ship'] 2995\n",
      "['money-fx', 'dlr'] 3009\n",
      "['money-fx', 'dlr'] 3011\n",
      "['gold', 'silver', 'platinum'] 3012\n",
      "['grain', 'barley'] 3023\n",
      "['grain', 'corn'] 3034\n",
      "['money-fx', 'interest'] 3050\n",
      "['interest', 'money-fx'] 3085\n",
      "['ship', 'sugar'] 3127\n",
      "['money-fx', 'sfr', 'dmk'] 3135\n",
      "['money-fx', 'interest', 'dlr'] 3141\n",
      "['gas', 'crude'] 3145\n",
      "['oilseed', 'soybean', 'soy-meal', 'meal-feed'] 3176\n",
      "['interest', 'money-fx'] 3184\n",
      "['ship', 'crude'] 3212\n",
      "['grain', 'barley'] 3262\n",
      "['grain', 'wheat'] 3274\n",
      "['grain', 'wheat'] 3296\n",
      "['grain', 'oilseed'] 3305\n",
      "['gas', 'crude'] 3310\n",
      "['acq', 'copper'] 3316\n",
      "['acq', 'crude', 'nat-gas'] 3324\n",
      "['ship', 'crude'] 3328\n",
      "['lead', 'zinc'] 3336\n",
      "['crude', 'ship'] 3339\n",
      "['grain', 'wheat', 'oilseed', 'rapeseed'] 3344\n",
      "['bop', 'trade'] 3346\n",
      "['money-fx', 'dlr', 'yen'] 3362\n",
      "['money-fx', 'dlr', 'yen'] 3369\n",
      "['hog', 'livestock'] 3372\n",
      "['grain', 'wheat'] 3376\n",
      "['acq', 'pet-chem'] 3380\n",
      "['oilseed', 'rapeseed'] 3381\n",
      "['pet-chem', 'rubber'] 3385\n",
      "['oilseed', 'rapeseed'] 3390\n",
      "['veg-oil', 'cocoa', 'sugar'] 3394\n",
      "['grain', 'wheat'] 3399\n",
      "['crude', 'nat-gas'] 3400\n",
      "['dlr', 'money-fx'] 3403\n",
      "['crude', 'heat', 'gas'] 3404\n",
      "['grain', 'corn', 'oilseed', 'soybean'] 3407\n",
      "['grain', 'oilseed', 'soybean', 'corn', 'meal-feed', 'soy-meal'] 3408\n",
      "['lead', 'zinc'] 3410\n",
      "['lead', 'zinc'] 3411\n",
      "['grain', 'wheat'] 3412\n",
      "['lead', 'zinc'] 3413\n",
      "['lead', 'zinc'] 3415\n",
      "['oilseed', 'soybean'] 3416\n",
      "['dlr', 'money-fx', 'trade'] 3421\n",
      "['money-supply', 'reserves'] 3423\n",
      "['oilseed', 'soybean'] 3426\n",
      "['oilseed', 'rapeseed'] 3430\n",
      "['fuel', 'ship'] 3443\n",
      "['money-fx', 'interest'] 3451\n",
      "['zinc', 'lead', 'copper'] 3456\n",
      "['grain', 'rice'] 3459\n",
      "['money-fx', 'reserves', 'trade'] 3460\n",
      "['gas', 'naphtha', 'fuel'] 3479\n",
      "['meal-feed', 'livestock', 'carcass', 'grain', 'corn', 'sorghum', 'oilseed', 'soy-meal', 'rapeseed'] 3481\n",
      "['silver', 'platinum'] 3488\n",
      "['bop', 'trade'] 3495\n",
      "['crude', 'ship'] 3520\n",
      "['oilseed', 'soybean'] 3543\n",
      "['ship', 'lead'] 3570\n",
      "['grain', 'rice', 'sugar'] 3608\n",
      "['grain', 'corn'] 3613\n",
      "['money-fx', 'nzdlr'] 3624\n",
      "['grain', 'rice', 'sugar'] 3641\n",
      "['crude', 'nat-gas'] 3650\n",
      "['interest', 'reserves', 'jobs', 'income'] 3671\n",
      "['money-fx', 'interest'] 3723\n",
      "['bop', 'trade'] 3747\n",
      "['money-fx', 'interest'] 3749\n",
      "['bop', 'trade'] 3752\n",
      "['money-fx', 'interest'] 3762\n",
      "['veg-oil', 'palm-oil', 'soy-oil', 'rape-oil', 'cotton-oil', 'coconut-oil', 'sun-oil'] 3780\n",
      "['trade', 'reserves'] 3797\n",
      "['acq', 'crude', 'nat-gas'] 3856\n",
      "['crude', 'nat-gas'] 3895\n",
      "['grain', 'wheat'] 3898\n",
      "['grain', 'barley', 'wheat'] 3907\n",
      "['gnp', 'income', 'housing'] 3910\n",
      "['grain', 'corn'] 3953\n",
      "['grain', 'corn'] 3972\n",
      "['gnp', 'bop'] 3984\n",
      "['gnp', 'jobs', 'cpi'] 3986\n",
      "['gnp', 'jobs'] 3989\n",
      "['trade', 'bop', 'gnp'] 3990\n",
      "['gnp', 'jobs', 'cpi'] 3992\n",
      "['gnp', 'jobs', 'bop'] 3995\n",
      "['gnp', 'jobs', 'cpi'] 3999\n",
      "['bop', 'trade'] 4108\n",
      "['grain', 'wheat'] 4125\n",
      "['money-fx', 'reserves'] 4206\n",
      "['ship', 'crude'] 4210\n",
      "['copper', 'nickel'] 4296\n",
      "['grain', 'ship'] 4359\n",
      "['sugar', 'livestock'] 4433\n",
      "['grain', 'corn', 'oilseed', 'livestock'] 4482\n",
      "['ship', 'grain', 'wheat'] 4490\n",
      "['grain', 'wheat', 'veg-oil'] 4508\n",
      "['grain', 'rice'] 4514\n",
      "['gold', 'silver', 'copper', 'zinc', 'lead'] 4571\n",
      "['oilseed', 'rapeseed'] 4602\n",
      "['cruzado', 'money-fx'] 4654\n",
      "['sugar', 'ship'] 4681\n",
      "['grain', 'ship'] 4687\n",
      "['crude', 'gas', 'heat'] 4697\n",
      "['grain', 'ship'] 4700\n",
      "['gas', 'crude'] 4703\n",
      "['grain', 'oilseed', 'soybean'] 4705\n",
      "['ship', 'crude'] 4708\n",
      "['grain', 'wheat'] 4717\n",
      "['grain', 'wheat'] 4720\n",
      "['grain', 'wheat'] 4721\n",
      "['gas', 'crude', 'fuel'] 4731\n",
      "['money-fx', 'dlr', 'yen', 'can', 'stg'] 4766\n",
      "['dlr', 'money-fx', 'trade', 'cpi', 'money-supply'] 4769\n",
      "['dlr', 'money-fx'] 4776\n",
      "['dlr', 'money-fx'] 4778\n",
      "['crude', 'nat-gas'] 4828\n",
      "['trade', 'grain', 'rice', 'corn', 'sugar', 'tin', 'rubber'] 4831\n",
      "['veg-oil', 'palm-oil'] 4832\n",
      "['veg-oil', 'palm-oil', 'lumber', 'coffee', 'rubber'] 4839\n",
      "['grain', 'wheat'] 4840\n",
      "['money-fx', 'interest'] 4848\n",
      "['acq', 'copper'] 4851\n",
      "['trade', 'rice', 'livestock', 'carcass', 'grain', 'corn', 'oilseed', 'soybean'] 4857\n",
      "['money-fx', 'interest'] 4860\n",
      "['trade', 'bop'] 4861\n",
      "['gas', 'lead'] 4862\n",
      "['interest', 'money-fx'] 4889\n",
      "['gnp', 'cpi'] 4890\n",
      "['veg-oil', 'palm-oil', 'soy-oil', 'oilseed', 'soybean'] 4891\n",
      "['money-fx', 'dlr', 'yen'] 4912\n",
      "['money-fx', 'interest'] 4918\n",
      "['money-fx', 'dlr'] 4930\n",
      "['money-fx', 'interest'] 4963\n",
      "['grain', 'wheat'] 5002\n",
      "['crude', 'nat-gas'] 5006\n",
      "['grain', 'wheat'] 5007\n",
      "['money-fx', 'interest'] 5021\n",
      "['grain', 'wheat', 'barley', 'corn'] 5043\n",
      "['earn', 'crude'] 5060\n",
      "['grain', 'wheat', 'copper'] 5073\n",
      "['oilseed', 'soybean'] 5086\n",
      "['grain', 'wheat'] 5094\n",
      "['grain', 'wheat'] 5168\n",
      "['grain', 'barley'] 5170\n",
      "['grain', 'barley', 'wheat', 'corn', 'oilseed', 'rapeseed'] 5171\n",
      "['money-fx', 'yen'] 5177\n",
      "['money-fx', 'dlr'] 5180\n",
      "['grain', 'corn'] 5182\n",
      "['copper', 'lead', 'zinc', 'strategic-metal'] 5185\n",
      "['crude', 'ship'] 5186\n",
      "['money-fx', 'dlr', 'yen'] 5189\n",
      "['grain', 'wheat', 'barley'] 5190\n",
      "['acq', 'earn'] 5192\n",
      "['sugar', 'acq'] 5194\n",
      "['gnp', 'jobs'] 5196\n",
      "['grain', 'wheat', 'barley', 'corn'] 5216\n",
      "['grain', 'wheat'] 5222\n",
      "['livestock', 'hog', 'carcass'] 5225\n",
      "['grain', 'barley'] 5231\n",
      "['grain', 'corn'] 5263\n",
      "['gnp', 'trade'] 5277\n",
      "['money-fx', 'yen'] 5285\n",
      "['money-fx', 'dlr'] 5326\n",
      "['trade', 'money-fx'] 5351\n",
      "['money-fx', 'dlr', 'yen'] 5353\n",
      "['trade', 'sugar', 'cotton', 'groundnut', 'oilseed'] 5358\n",
      "['grain', 'wheat'] 5366\n",
      "['grain', 'wheat', 'corn', 'soybean', 'oilseed'] 5381\n",
      "['livestock', 'l-cattle', 'carcass', 'sugar'] 5388\n",
      "['money-fx', 'can'] 5405\n",
      "['veg-oil', 'groundnut'] 5419\n",
      "['grain', 'wheat'] 5424\n",
      "['grain', 'corn'] 5435\n",
      "['livestock', 'carcass'] 5447\n",
      "['money-fx', 'dlr'] 5451\n",
      "['grain', 'corn', 'oilseed', 'soybean', 'veg-oil', 'soy-oil', 'meal-feed', 'soy-meal', 'cotton'] 5455\n",
      "['livestock', 'carcass'] 5494\n",
      "['grain', 'wheat'] 5507\n",
      "['trade', 'crude', 'nat-gas'] 5510\n",
      "['crude', 'nat-gas'] 5514\n",
      "['coffee', 'oilseed', 'soybean', 'trade', 'sugar', 'cocoa'] 5520\n",
      "['grain', 'wheat'] 5523\n",
      "['trade', 'grain', 'wheat'] 5534\n",
      "['fishmeal', 'meal-feed'] 5556\n",
      "['hog', 'livestock'] 5571\n",
      "['money-fx', 'interest'] 5575\n",
      "['grain', 'corn'] 5594\n",
      "['grain', 'corn'] 5598\n",
      "['money-fx', 'interest'] 5600\n",
      "['grain', 'corn'] 5616\n",
      "['jobs', 'ipi', 'gnp', 'income', 'trade', 'retail'] 5617\n",
      "['dlr', 'money-fx'] 5622\n",
      "['money-fx', 'interest'] 5625\n",
      "['dlr', 'money-fx'] 5632\n",
      "['money-fx', 'interest'] 5677\n",
      "['money-fx', 'interest'] 5682\n",
      "['money-supply', 'reserves'] 5685\n",
      "['interest', 'money-fx'] 5696\n",
      "['interest', 'gnp'] 5708\n",
      "['grain', 'corn'] 5726\n",
      "['grain', 'wheat', 'corn'] 5740\n",
      "['grain', 'wheat'] 5746\n",
      "['grain', 'corn'] 5748\n",
      "['sugar', 'corn', 'grain'] 5776\n",
      "['gold', 'platinum', 'palladium', 'nickel', 'copper'] 5781\n",
      "['ship', 'gas'] 5827\n",
      "['grain', 'corn'] 5847\n",
      "['grain', 'wheat'] 5856\n",
      "['grain', 'wheat'] 5863\n",
      "['gold', 'platinum', 'palladium', 'copper', 'nickel'] 5879\n",
      "['grain', 'corn', 'cornglutenfeed', 'meal-feed'] 5912\n",
      "['grain', 'corn'] 5921\n",
      "['interest', 'crude'] 5924\n",
      "['grain', 'corn'] 5946\n",
      "['crude', 'fuel', 'jet'] 5956\n",
      "['interest', 'money-fx'] 5965\n",
      "['tapioca', 'meal-feed'] 5973\n",
      "['cotton', 'sugar', 'veg-oil', 'grain'] 5974\n",
      "['carcass', 'livestock'] 5977\n",
      "['money-fx', 'interest'] 5995\n",
      "['trade', 'money-fx'] 6006\n",
      "['grain', 'rice'] 6017\n",
      "['grain', 'wheat'] 6020\n",
      "['money-fx', 'dlr'] 6021\n",
      "['earn', 'acq'] 6035\n",
      "['crude', 'gas'] 6038\n",
      "['money-fx', 'dlr'] 6053\n",
      "['money-fx', 'trade'] 6054\n",
      "['grain', 'corn', 'oilseed', 'soybean'] 6057\n",
      "['trade', 'hog', 'carcass', 'livestock'] 6059\n",
      "['money-fx', 'dlr'] 6060\n",
      "['pet-chem', 'nat-gas'] 6076\n",
      "['money-fx', 'dlr'] 6078\n",
      "['grain', 'corn'] 6092\n",
      "['grain', 'corn'] 6093\n",
      "['grain', 'wheat'] 6094\n",
      "['earn', 'acq'] 6111\n",
      "['money-fx', 'dlr'] 6117\n",
      "['money-fx', 'dlr'] 6119\n",
      "['money-fx', 'dlr'] 6127\n",
      "['money-fx', 'dlr'] 6128\n",
      "['interest', 'money-fx'] 6137\n",
      "['trade', 'bop'] 6142\n",
      "['money-fx', 'yen'] 6148\n",
      "['coffee', 'tea', 'rubber'] 6152\n",
      "['money-fx', 'dlr'] 6161\n",
      "['money-fx', 'interest'] 6163\n",
      "['money-fx', 'dlr'] 6165\n",
      "['money-fx', 'saudriyal'] 6169\n",
      "['veg-oil', 'sun-oil'] 6192\n",
      "['silver', 'copper'] 6194\n",
      "['money-fx', 'dlr', 'yen'] 6212\n",
      "['money-fx', 'dlr'] 6213\n",
      "['interest', 'money-fx'] 6215\n",
      "['money-fx', 'dlr', 'yen'] 6221\n",
      "['money-fx', 'dlr'] 6223\n",
      "['money-fx', 'interest'] 6260\n",
      "['money-fx', 'dlr'] 6281\n",
      "['money-fx', 'dlr'] 6294\n",
      "['grain', 'corn'] 6322\n",
      "['tea', 'orange'] 6326\n",
      "['interest', 'money-fx'] 6360\n",
      "['sugar', 'ship'] 6361\n",
      "['money-fx', 'dlr'] 6376\n",
      "['trade', 'grain'] 6405\n",
      "['crude', 'nat-gas'] 6435\n",
      "['sugar', 'grain', 'corn'] 6469\n",
      "['trade', 'money-fx'] 6497\n",
      "['grain', 'corn', 'oilseed', 'soybean', 'sorghum', 'sunseed'] 6520\n",
      "['crude', 'nat-gas'] 6582\n",
      "['livestock', 'hog'] 6584\n",
      "['trade', 'iron-steel'] 6591\n",
      "['crude', 'gas'] 6613\n",
      "['oilseed', 'soybean'] 6616\n",
      "['crude', 'gas'] 6633\n",
      "['crude', 'nat-gas'] 6638\n",
      "['crude', 'nat-gas'] 6649\n",
      "['money-fx', 'interest'] 6655\n",
      "['grain', 'corn'] 6666\n",
      "['money-fx', 'yen'] 6697\n",
      "['money-fx', 'yen', 'interest'] 6700\n",
      "['grain', 'rice'] 6704\n",
      "['crude', 'ship'] 6717\n",
      "['trade', 'bop'] 6728\n",
      "['money-fx', 'interest'] 6729\n",
      "['bop', 'trade'] 6748\n",
      "['jobs', 'trade'] 6750\n",
      "['saudriyal', 'money-fx'] 6752\n",
      "['livestock', 'carcass'] 6753\n",
      "['veg-oil', 'meal-feed', 'oilseed'] 6755\n",
      "['bop', 'trade'] 6767\n",
      "['trade', 'bop'] 6769\n",
      "['grain', 'wheat'] 6772\n",
      "['grain', 'wheat'] 6781\n",
      "['money-fx', 'dlr'] 6782\n",
      "['trade', 'bop', 'interest', 'money-fx'] 6783\n",
      "['grain', 'wheat'] 6792\n",
      "['crude', 'ship'] 6800\n",
      "['trade', 'bop'] 6815\n",
      "['trade', 'bop'] 6820\n",
      "['trade', 'bop'] 6835\n",
      "['trade', 'bop', 'interest', 'stg', 'money-fx'] 6847\n",
      "['trade', 'crude'] 6848\n",
      "['money-fx', 'interest'] 6854\n",
      "['money-fx', 'dlr'] 6861\n",
      "['money-fx', 'trade'] 6863\n",
      "['grain', 'corn', 'wheat', 'barley'] 6864\n",
      "['money-fx', 'dlr'] 6870\n",
      "['trade', 'jobs'] 6896\n",
      "['acq', 'crude'] 6912\n",
      "['oilseed', 'soybean'] 6918\n",
      "['money-fx', 'dlr', 'yen'] 6945\n",
      "['acq', 'crude'] 6946\n",
      "['trade', 'money-fx'] 6956\n",
      "['grain', 'corn', 'barley'] 6957\n",
      "['grain', 'corn'] 6988\n",
      "['grain', 'corn'] 7002\n",
      "['livestock', 'carcass'] 7008\n",
      "['grain', 'corn'] 7016\n",
      "['livestock', 'carcass'] 7030\n",
      "['grain', 'corn'] 7032\n",
      "['crude', 'gas', 'nat-gas', 'wpi'] 7036\n",
      "['grain', 'wheat'] 7055\n",
      "['wpi', 'gas', 'nat-gas', 'crude', 'heat'] 7060\n",
      "['grain', 'corn'] 7108\n",
      "['acq', 'crude'] 7115\n",
      "['veg-oil', 'soy-oil'] 7141\n",
      "['cpi', 'gas'] 7144\n",
      "['pet-chem', 'crude'] 7149\n",
      "['veg-oil', 'palm-oil'] 7151\n",
      "['iron-steel', 'zinc', 'lead'] 7152\n",
      "['crude', 'ship'] 7155\n",
      "['trade', 'veg-oil'] 7168\n",
      "['money-fx', 'reserves'] 7180\n",
      "['grain', 'corn'] 7184\n",
      "['bop', 'trade'] 7188\n",
      "['reserves', 'money-fx'] 7192\n",
      "['ipi', 'inventories'] 7195\n",
      "['money-fx', 'yen'] 7203\n",
      "['money-fx', 'yen', 'gnp'] 7205\n",
      "['veg-oil', 'palm-oil'] 7217\n",
      "['money-fx', 'interest'] 7231\n",
      "['money-fx', 'interest'] 7240\n",
      "['grain', 'rice'] 7265\n",
      "['money-fx', 'yen', 'gnp'] 7270\n",
      "['money-fx', 'interest'] 7276\n",
      "['money-fx', 'reserves'] 7278\n",
      "['money-fx', 'trade'] 7279\n",
      "['trade', 'veg-oil'] 7284\n",
      "['money-fx', 'dlr', 'interest'] 7289\n",
      "['veg-oil', 'palm-oil', 'ship'] 7291\n",
      "['veg-oil', 'palm-oil'] 7314\n",
      "['hog', 'livestock'] 7332\n",
      "['money-fx', 'interest'] 7335\n",
      "['money-fx', 'grain', 'corn'] 7337\n",
      "['money-fx', 'interest'] 7343\n",
      "['grain', 'wheat'] 7382\n",
      "['oilseed', 'veg-oil', 'soybean'] 7390\n",
      "['money-fx', 'interest'] 7403\n",
      "['money-fx', 'peseta'] 7411\n",
      "['acq', 'copper'] 7434\n",
      "['money-fx', 'interest'] 7438\n",
      "['carcass', 'livestock'] 7444\n",
      "['trade', 'gnp'] 7457\n",
      "['grain', 'wheat', 'corn', 'cotton', 'sorghum', 'barley', 'corn'] 7466\n",
      "['carcass', 'livestock'] 7486\n",
      "['grain', 'corn'] 7517\n",
      "['grain', 'corn', 'wheat', 'oilseed', 'soybean'] 7530\n",
      "['trade', 'ship', 'crude'] 7541\n",
      "['crude', 'ship'] 7552\n",
      "['trade', 'coffee'] 7569\n",
      "['grain', 'wheat', 'corn', 'soybean', 'oilseed'] 7605\n",
      "['grain', 'corn', 'wheat', 'soybean', 'oilseed', 'barley', 'sorghum', 'cotton', 'rice'] 7609\n",
      "['ship', 'crude', 'fuel'] 7629\n",
      "['meal-feed', 'veg-oil'] 7634\n",
      "['grain', 'wheat', 'corn', 'sorghum'] 7635\n",
      "['grain', 'corn'] 7636\n",
      "['grain', 'wheat'] 7638\n",
      "['grain', 'barley'] 7639\n",
      "['grain', 'wheat'] 7647\n",
      "['crude', 'fuel'] 7682\n",
      "['acq', 'nickel', 'strategic-metal'] 7692\n",
      "['soybean', 'oilseed'] 7701\n",
      "['oilseed', 'veg-oil'] 7760\n",
      "['money-fx', 'dlr'] 7777\n",
      "['bop', 'trade', 'austdlr', 'money-fx', 'interest'] 7778\n",
      "['trade', 'bop'] 7784\n",
      "['trade', 'bop'] 7785\n",
      "['veg-oil', 'soy-oil'] 7790\n",
      "['money-fx', 'austdlr'] 7810\n",
      "['livestock', 'carcass'] 7811\n",
      "['money-fx', 'interest'] 7813\n",
      "['interest', 'money-supply'] 7835\n",
      "['reserves', 'money-fx'] 7840\n",
      "['corn', 'grain'] 7846\n",
      "['ship', 'trade', 'crude'] 7851\n",
      "['money-fx', 'interest'] 7860\n",
      "['ship', 'crude'] 7865\n",
      "['livestock', 'l-cattle', 'carcass'] 7895\n",
      "['grain', 'corn'] 7932\n",
      "['bop', 'trade'] 7938\n",
      "['bop', 'trade'] 7940\n",
      "['bop', 'trade'] 7980\n",
      "['ship', 'crude'] 8073\n",
      "['veg-oil', 'palm-oil', 'coconut-oil'] 8079\n",
      "['wheat', 'grain'] 8093\n",
      "['wheat', 'grain'] 8096\n",
      "['barley', 'grain'] 8098\n",
      "['crude', 'nat-gas'] 8101\n",
      "['grain', 'ship'] 8119\n",
      "['grain', 'rice'] 8122\n",
      "['grain', 'rice'] 8128\n",
      "['nat-gas', 'propane'] 8129\n",
      "['livestock', 'carcass'] 8148\n",
      "['grain', 'ship'] 8161\n",
      "['grain', 'oilseed', 'soy-oil', 'corn'] 8172\n",
      "['oilseed', 'rapeseed', 'grain', 'wheat', 'corn', 'palm-oil', 'soy-oil', 'ship'] 8178\n",
      "['gnp', 'gas'] 8233\n",
      "['acq', 'ship'] 8234\n",
      "['wheat', 'grain'] 8271\n",
      "['grain', 'rice', 'wheat'] 8276\n",
      "['trade', 'gnp'] 8277\n",
      "['trade', 'gnp'] 8288\n",
      "['grain', 'rice'] 8293\n",
      "['grain', 'oilseed', 'wheat', 'rapeseed'] 8312\n",
      "['dlr', 'money-fx'] 8314\n",
      "['livestock', 'carcass'] 8379\n",
      "['livestock', 'carcass'] 8381\n",
      "['money-fx', 'dlr'] 8511\n",
      "['money-fx', 'dlr'] 8523\n",
      "['money-fx', 'dlr'] 8530\n",
      "['crude', 'ship'] 8541\n",
      "['money-fx', 'dlr', 'yen'] 8543\n",
      "['dlr', 'money-fx'] 8659\n",
      "['gold', 'reserves'] 8689\n",
      "['grain', 'wheat'] 8728\n",
      "['veg-oil', 'palm-oil'] 8737\n",
      "['wheat', 'barley'] 8743\n",
      "['gold', 'reserves'] 8790\n",
      "['grain', 'barley'] 8794\n",
      "['money-fx', 'dlr'] 8830\n",
      "['grain', 'wheat', 'corn', 'sorghum', 'barley', 'oat'] 8851\n",
      "['grain', 'wheat', 'corn', 'sorghum', 'barley'] 8855\n",
      "['money-fx', 'dlr', 'trade'] 8868\n",
      "['copper', 'zinc'] 8876\n",
      "['money-fx', 'dlr', 'trade'] 8902\n",
      "['oilseed', 'soybean', 'soy-oil'] 8914\n",
      "['dlr', 'dmk', 'money-fx'] 8918\n",
      "['money-supply', 'money-fx'] 8948\n",
      "['crude', 'ship'] 8962\n",
      "['money-fx', 'dlr'] 8987\n",
      "['money-supply', 'money-fx'] 8993\n",
      "['wheat', 'corn', 'soybean', 'grain', 'oilseed'] 9001\n",
      "['acq', 'strategic-metal'] 9006\n",
      "['wheat', 'grain'] 9008\n",
      "['corn', 'sorghum', 'grain'] 9051\n",
      "['corn', 'grain'] 9054\n",
      "['rapeseed', 'oilseed'] 9075\n",
      "['grain', 'ship'] 9080\n",
      "['stg', 'money-fx'] 9120\n",
      "['dlr', 'money-fx'] 9135\n",
      "['money-fx', 'dlr', 'yen'] 9144\n",
      "['grain', 'oilseed', 'sunseed', 'corn', 'soybean', 'sorghum'] 9159\n",
      "['grain', 'ship'] 9160\n",
      "['sugar', 'ship'] 9173\n",
      "['money-fx', 'interest'] 9182\n",
      "['grain', 'wheat', 'soybean', 'oilseed'] 9191\n",
      "['oilseed', 'cotton', 'wheat', 'grain', 'sunseed', 'linseed', 'rapeseed', 'soybean', 'groundnut'] 9253\n",
      "['carcass', 'livestock'] 9256\n",
      "['grain', 'wheat'] 9260\n",
      "['wheat', 'grain'] 9268\n",
      "['groundnut', 'oilseed'] 9274\n",
      "['corn', 'grain'] 9310\n",
      "['corn', 'grain'] 9322\n",
      "['grain', 'wheat'] 9324\n",
      "['grain', 'ship'] 9326\n",
      "['interest', 'dlr'] 9336\n",
      "['oilseed', 'soybean'] 9347\n",
      "['meal-feed', 'sun-meal', 'lin-meal', 'soy-meal'] 9360\n",
      "['grain', 'ship'] 9365\n",
      "['ship', 'crude'] 9370\n",
      "['grain', 'wheat', 'corn', 'sugar', 'carcass', 'livestock', 'groundnut', 'oilseed', 'cotton', 'veg-oil'] 9371\n",
      "['livestock', 'carcass'] 9375\n",
      "['money-fx', 'interest', 'dlr'] 9395\n",
      "['trade', 'cocoa'] 9400\n",
      "['money-fx', 'interest', 'stg'] 9405\n",
      "['money-fx', 'interest'] 9409\n",
      "['money-fx', 'reserves'] 9415\n",
      "['grain', 'corn', 'sorghum'] 9416\n",
      "['money-fx', 'interest', 'stg'] 9417\n",
      "['grain', 'wheat'] 9419\n",
      "['money-fx', 'dlr'] 9421\n",
      "['oilseed', 'soybean', 'soy-meal', 'veg-oil', 'soy-oil'] 9424\n",
      "['grain', 'wheat', 'barley'] 9427\n",
      "['money-supply', 'wpi'] 9428\n",
      "['grain', 'corn'] 9435\n",
      "['money-fx', 'dlr'] 9436\n",
      "['pet-chem', 'oilseed'] 9438\n",
      "['interest', 'money-fx', 'stg'] 9446\n",
      "['money-fx', 'interest'] 9452\n",
      "['money-fx', 'interest'] 9455\n",
      "['grain', 'wheat'] 9457\n",
      "['money-fx', 'dlr', 'yen', 'interest'] 9469\n",
      "['money-fx', 'interest'] 9470\n",
      "['copper', 'lead', 'zinc', 'silver', 'nickel', 'alum'] 9483\n",
      "['money-fx', 'interest'] 9493\n",
      "['grain', 'wheat', 'corn'] 9499\n",
      "['money-fx', 'interest'] 9500\n",
      "['money-fx', 'dlr', 'dmk'] 9521\n",
      "['austdlr', 'dmk'] 9524\n",
      "['iron-steel', 'crude'] 9532\n",
      "['grain', 'wheat'] 9542\n",
      "['money-fx', 'interest'] 9553\n",
      "['money-supply', 'gnp'] 9575\n",
      "['grain', 'corn'] 9582\n",
      "['veg-oil', 'palm-oil'] 9584\n",
      "['grain', 'corn'] 9586\n",
      "['money-fx', 'stg'] 9587\n",
      "['money-fx', 'stg'] 9592\n",
      "['crude', 'livestock', 'carcass'] 9594\n",
      "['stg', 'money-fx'] 9600\n",
      "['livestock', 'carcass', 'trade'] 9602\n",
      "['stg', 'money-fx'] 9606\n",
      "['grain', 'wheat'] 9614\n",
      "['livestock', 'carcass'] 9617\n",
      "['grain', 'wheat'] 9637\n",
      "['interest', 'money-fx'] 9649\n",
      "['interest', 'money-fx'] 9652\n",
      "['stg', 'money-fx'] 9672\n",
      "['crude', 'nat-gas'] 9685\n",
      "['dlr', 'money-fx'] 9692\n",
      "['grain', 'corn'] 9694\n",
      "['grain', 'wheat', 'corn', 'oilseed', 'soybean'] 9708\n",
      "['oilseed', 'rapeseed'] 9709\n",
      "['grain', 'corn', 'wheat', 'oilseed', 'soybean'] 9710\n",
      "['oilseed', 'rapeseed'] 9711\n",
      "['grain', 'corn'] 9712\n",
      "['grain', 'wheat', 'corn', 'oilseed', 'soybean'] 9719\n",
      "['grain', 'wheat'] 9722\n",
      "['grain', 'wheat'] 9725\n",
      "['carcass', 'livestock', 'orange'] 9736\n",
      "['money-fx', 'interest'] 9740\n",
      "['money-fx', 'interest'] 9744\n",
      "['palm-oil', 'veg-oil'] 9745\n",
      "['meal-feed', 'soy-meal'] 9752\n",
      "['soybean', 'oilseed'] 9756\n",
      "['wheat', 'grain'] 9761\n",
      "['grain', 'ship'] 9767\n",
      "['pet-chem', 'ship'] 9769\n",
      "['cpi', 'gnp', 'ipi'] 9770\n",
      "['dlr', 'money-fx'] 9779\n",
      "['veg-oil', 'soy-oil'] 9785\n",
      "['soy-meal', 'meal-feed'] 9786\n",
      "['money-fx', 'interest'] 9788\n",
      "['money-fx', 'dlr'] 9794\n",
      "['gold', 'silver'] 9795\n",
      "['money-fx', 'reserves'] 9800\n",
      "['wheat', 'grain'] 9801\n",
      "['money-fx', 'interest'] 9811\n",
      "['money-fx', 'interest'] 9818\n",
      "['money-fx', 'interest'] 9839\n",
      "['ship', 'grain'] 9848\n",
      "['corn', 'grain'] 9871\n",
      "['money-fx', 'dlr', 'dmk'] 9876\n",
      "['wheat', 'grain'] 9886\n",
      "['money-fx', 'interest'] 9922\n",
      "['plywood', 'lumber'] 9942\n",
      "['plywood', 'lumber'] 9947\n",
      "['wheat', 'grain'] 9970\n",
      "['rapeseed', 'oilseed'] 9981\n",
      "['gnp', 'bop'] 9985\n",
      "['interest', 'retail', 'ipi'] 10004\n",
      "['crude', 'nat-gas', 'iron-steel'] 10015\n",
      "['carcass', 'livestock'] 10021\n",
      "['oilseed', 'rapeseed'] 10039\n",
      "['grain', 'corn'] 10046\n",
      "['ship', 'iron-steel'] 10048\n",
      "['grain', 'wheat'] 10056\n",
      "['acq', 'gold'] 10057\n",
      "['oilseed', 'soybean'] 10075\n",
      "['grain', 'wheat', 'sugar'] 10076\n",
      "['bop', 'trade'] 10077\n",
      "['oilseed', 'rapeseed', 'soybean', 'sunseed'] 10082\n",
      "['money-fx', 'interest'] 10089\n",
      "['money-fx', 'reserves'] 10092\n",
      "['carcass', 'livestock'] 10100\n",
      "['money-fx', 'interest'] 10130\n",
      "['grain', 'corn', 'rice', 'oilseed', 'soybean', 'orange'] 10132\n",
      "['veg-oil', 'palm-oil'] 10137\n",
      "['cocoa', 'coffee'] 10146\n",
      "['acq', 'trade'] 10157\n",
      "['crude', 'nat-gas'] 10161\n",
      "['ship', 'crude'] 10170\n",
      "['money-fx', 'interest'] 10187\n",
      "['grain', 'wheat', 'ship'] 10202\n",
      "['hog', 'livestock'] 10205\n",
      "['acq', 'ship'] 10208\n",
      "['earn', 'crude', 'nat-gas'] 10231\n",
      "['money-fx', 'interest'] 10274\n",
      "['grain', 'wheat'] 10277\n",
      "['grain', 'barley'] 10279\n",
      "['grain', 'corn'] 10288\n",
      "['earn', 'copper'] 10290\n",
      "['grain', 'wheat', 'barley', 'corn'] 10295\n",
      "['money-fx', 'interest'] 10297\n",
      "['veg-oil', 'palm-oil'] 10304\n",
      "['grain', 'rice'] 10313\n",
      "['acq', 'crude'] 10314\n",
      "['grain', 'wheat'] 10355\n",
      "['crude', 'acq'] 10366\n",
      "['grain', 'corn', 'wheat'] 10381\n",
      "['oilseed', 'soybean'] 10391\n",
      "['crude', 'nat-gas'] 10466\n",
      "['grain', 'wheat'] 10472\n",
      "['grain', 'wheat'] 10477\n",
      "['grain', 'wheat', 'corn', 'oilseed', 'soybean'] 10489\n",
      "['carcass', 'livestock'] 10502\n",
      "['oilseed', 'rapeseed'] 10511\n",
      "['carcass', 'livestock'] 10513\n",
      "['gnp', 'cpi', 'reserves'] 10547\n",
      "['grain', 'wheat', 'oilseed', 'soybean', 'cotton', 'rice'] 10548\n",
      "['l-cattle', 'livestock'] 10563\n",
      "['crude', 'nat-gas'] 10568\n",
      "['gnp', 'cpi'] 10572\n",
      "['carcass', 'livestock'] 10576\n",
      "['crude', 'nat-gas'] 10589\n",
      "['grain', 'wheat', 'corn', 'oilseed', 'soybean'] 10598\n",
      "['money-supply', 'interest'] 10601\n",
      "['money-fx', 'dlr'] 10615\n",
      "['trade', 'bop'] 10628\n",
      "['livestock', 'carcass'] 10630\n",
      "['money-fx', 'yen'] 10632\n",
      "['livestock', 'carcass'] 10635\n",
      "['veg-oil', 'palm-oil'] 10649\n",
      "['grain', 'wheat'] 10670\n",
      "['money-fx', 'dlr', 'yen'] 10674\n",
      "['grain', 'rice'] 10677\n",
      "['money-fx', 'yen'] 10679\n",
      "['veg-oil', 'palm-oil'] 10680\n",
      "['money-fx', 'interest'] 10681\n",
      "['grain', 'wheat'] 10695\n",
      "['money-fx', 'yen'] 10702\n",
      "['money-fx', 'yen'] 10708\n",
      "['rice', 'grain'] 10718\n",
      "['money-fx', 'interest'] 10719\n",
      "['ship', 'grain'] 10777\n",
      "['money-fx', 'interest'] 10782\n",
      "['money-fx', 'interest'] 10821\n",
      "['grain', 'corn'] 10824\n",
      "['livestock', 'hog'] 10832\n",
      "['money-fx', 'dlr'] 10881\n",
      "['grain', 'corn'] 10904\n",
      "['grain', 'corn'] 10938\n",
      "['interest', 'gnp', 'ipi', 'wpi'] 10943\n",
      "['crude', 'nat-gas'] 10950\n",
      "['crude', 'ship'] 10952\n",
      "['nat-gas', 'crude'] 10961\n",
      "['grain', 'corn'] 10987\n",
      "['grain', 'wheat', 'oilseed', 'soybean', 'veg-oil'] 11002\n",
      "['sugar', 'grain', 'corn'] 11003\n",
      "['livestock', 'pork-belly'] 11007\n",
      "['ship', 'grain'] 11008\n",
      "['crude', 'nat-gas', 'fuel'] 11040\n",
      "['dlr', 'money-fx'] 11096\n",
      "['acq', 'crude', 'nat-gas'] 11099\n",
      "['gnp', 'ringgit'] 11110\n",
      "['oilseed', 'coconut'] 11111\n",
      "['trade', 'oilseed', 'grain'] 11131\n",
      "['interest', 'gnp', 'trade'] 11134\n",
      "['meal-feed', 'grain', 'corn', 'sorghum', 'oilseed', 'soybean'] 11139\n",
      "['money-fx', 'interest'] 11144\n",
      "['money-fx', 'interest'] 11146\n",
      "['trade', 'coffee', 'rubber', 'palm-oil'] 11148\n",
      "['gnp', 'interest', 'money-fx', 'trade'] 11152\n",
      "['trade', 'veg-oil'] 11155\n",
      "['reserves', 'trade'] 11157\n",
      "['veg-oil', 'palm-oil', 'rape-oil', 'ship'] 11158\n",
      "['grain', 'corn', 'rice'] 11160\n",
      "['gnp', 'cpi', 'reserves', 'grain'] 11163\n",
      "['acq', 'grain', 'corn'] 11165\n",
      "['money-fx', 'interest'] 11167\n",
      "['gnp', 'trade', 'jobs', 'retail'] 11172\n",
      "['trade', 'bop'] 11173\n",
      "['grain', 'wheat'] 11178\n",
      "['money-fx', 'interest'] 11181\n",
      "['crude', 'ship'] 11187\n",
      "['money-fx', 'dlr', 'trade'] 11188\n",
      "['money-fx', 'interest'] 11193\n",
      "['coffee', 'ship'] 11199\n",
      "['crude', 'nat-gas'] 11209\n",
      "['grain', 'barley', 'oilseed', 'rapeseed'] 11212\n",
      "['money-fx', 'interest'] 11246\n",
      "['grain', 'corn', 'barley'] 11256\n",
      "['trade', 'cotton', 'grain', 'corn', 'wheat', 'oilseed'] 11272\n",
      "['crude', 'acq'] 11287\n",
      "['money-fx', 'interest'] 11298\n",
      "['ship', 'grain', 'oilseed'] 11318\n",
      "['grain', 'corn'] 11399\n",
      "['grain', 'wheat', 'cotton', 'rice'] 11412\n",
      "['crude', 'ship'] 11420\n",
      "['crude', 'ship'] 11439\n",
      "['grain', 'oilseed', 'corn'] 11442\n",
      "['grain', 'corn', 'sorghum'] 11445\n",
      "['ship', 'crude'] 11515\n",
      "['oilseed', 'soybean'] 11521\n",
      "['grain', 'wheat', 'corn'] 11534\n",
      "['acq', 'earn'] 11560\n",
      "['livestock', 'carcass'] 11573\n",
      "['money-fx', 'dlr'] 11583\n",
      "['money-fx', 'dlr'] 11589\n",
      "['money-fx', 'dlr'] 11590\n",
      "['trade', 'veg-oil', 'coconut-oil'] 11595\n",
      "['reserves', 'trade', 'money-fx'] 11596\n",
      "['earn', 'crude'] 11599\n",
      "['grain', 'wheat'] 11603\n",
      "['money-fx', 'dlr'] 11620\n",
      "['earn', 'crude', 'nat-gas'] 11629\n",
      "['money-fx', 'dlr'] 11656\n",
      "['money-fx', 'dlr'] 11663\n",
      "['ipi', 'trade'] 11670\n",
      "['crude', 'ship'] 11674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cpi', 'wpi'] 11693\n",
      "['money-fx', 'dlr'] 11713\n",
      "['money-fx', 'interest', 'money-supply'] 11722\n",
      "['money-fx', 'dlr'] 11734\n",
      "['ship', 'livestock'] 11743\n",
      "['retail', 'jobs', 'gnp', 'inventories', 'trade', 'cpi'] 11745\n",
      "['ship', 'crude'] 11748\n",
      "['grain', 'rice', 'corn', 'cotton', 'wheat', 'sorghum', 'barley', 'oat'] 11758\n",
      "['acq', 'ship'] 11794\n",
      "['grain', 'sugar', 'carcass', 'livestock'] 11799\n",
      "['crude', 'nat-gas'] 11811\n",
      "['crude', 'nat-gas'] 11814\n",
      "['earn', 'crude', 'nat-gas'] 11819\n",
      "['acq', 'gold', 'silver', 'zinc', 'lead'] 11853\n",
      "['ship', 'crude'] 11855\n",
      "['acq', 'gold', 'silver', 'lead', 'zinc'] 11876\n",
      "['crude', 'gas'] 11881\n",
      "['money-fx', 'stg', 'interest'] 11883\n",
      "['earn', 'ship'] 11901\n",
      "['trade', 'money-fx'] 11921\n",
      "['grain', 'corn'] 11940\n",
      "['ship', 'coffee'] 11949\n",
      "['earn', 'crude'] 11958\n",
      "['earn', 'crude', 'gas'] 11963\n",
      "['earn', 'crude', 'pet-chem'] 11970\n",
      "['acq', 'earn'] 11973\n",
      "['grain', 'corn'] 11982\n",
      "['grain', 'corn', 'wheat'] 11992\n",
      "['grain', 'wheat', 'corn', 'oilseed', 'soybean'] 12011\n",
      "['grain', 'wheat'] 12039\n",
      "['oilseed', 'rapeseed'] 12051\n",
      "['interest', 'gnp'] 12082\n",
      "['grain', 'wheat', 'corn'] 12084\n",
      "['grain', 'wheat', 'corn', 'sorghum', 'cotton'] 12090\n",
      "['grain', 'wheat'] 12118\n",
      "['dlr', 'money-fx'] 12119\n",
      "['iron-steel', 'alum', 'earn'] 12123\n",
      "['dlr', 'money-fx'] 12134\n",
      "['money-fx', 'interest'] 12199\n",
      "['money-fx', 'yen'] 12202\n",
      "['grain', 'wheat', 'barley'] 12207\n",
      "['money-fx', 'trade'] 12208\n",
      "['money-fx', 'dlr', 'dmk'] 12211\n",
      "['acq', 'sugar', 'crude'] 12212\n",
      "['grain', 'rice'] 12215\n",
      "['tin', 'sugar', 'grain', 'wheat', 'cocoa', 'coffee', 'rubber'] 12223\n",
      "['crude', 'nat-gas', 'sugar'] 12230\n",
      "['money-fx', 'interest'] 12237\n",
      "['money-fx', 'interest'] 12243\n",
      "['trade', 'yen', 'dlr'] 12253\n",
      "['money-fx', 'interest'] 12262\n",
      "['grain', 'corn'] 12268\n",
      "['money-fx', 'trade'] 12280\n",
      "['grain', 'wheat', 'barley'] 12315\n",
      "['coffee', 'sugar', 'cocoa'] 12340\n",
      "['grain', 'wheat'] 12342\n",
      "['crude', 'nat-gas'] 12349\n",
      "['gnp', 'lei'] 12355\n",
      "['money-fx', 'interest'] 12364\n",
      "['grain', 'wheat'] 12379\n",
      "['earn', 'crude'] 12387\n",
      "['grain', 'wheat', 'corn'] 12391\n",
      "['grain', 'wheat'] 12398\n",
      "['grain', 'wheat'] 12414\n",
      "['grain', 'wheat'] 12426\n",
      "['grain', 'corn'] 12435\n",
      "['grain', 'wheat'] 12444\n",
      "['coffee', 'sugar', 'cocoa'] 12461\n",
      "['crude', 'gas', 'heat'] 12490\n",
      "['grain', 'rice'] 12535\n",
      "['grain', 'corn', 'oilseed', 'soybean'] 12606\n",
      "['grain', 'wheat'] 12607\n",
      "['cotton', 'sorghum'] 12608\n",
      "['grain', 'wheat'] 12609\n",
      "['grain', 'corn', 'oilseed', 'soybean'] 12611\n",
      "['crude', 'nat-gas'] 12631\n",
      "['grain', 'rice', 'cotton'] 12639\n",
      "['grain', 'wheat'] 12644\n",
      "['grain', 'wheat', 'rice'] 12654\n",
      "['veg-oil', 'grain', 'wheat', 'cotton'] 12670\n",
      "['ship', 'grain', 'wheat'] 12693\n",
      "['crude', 'gas'] 12698\n",
      "['grain', 'corn'] 12728\n",
      "['grain', 'corn', 'oilseed', 'soybean'] 12738\n",
      "['money-fx', 'dlr', 'yen'] 12763\n",
      "['grain', 'corn', 'cotton'] 12768\n",
      "['money-fx', 'dlr', 'yen'] 12771\n",
      "['dlr', 'money-fx'] 12773\n",
      "['interest', 'gnp', 'money-fx'] 12775\n",
      "['palm-oil', 'palmkernel', 'oilseed', 'veg-oil'] 12777\n",
      "['money-fx', 'dlr'] 12782\n",
      "['ship', 'iron-steel'] 12812\n",
      "['wheat', 'grain'] 12814\n",
      "['coffee', 'acq'] 12815\n",
      "['money-fx', 'interest'] 12819\n",
      "['wheat', 'grain'] 12833\n",
      "['coconut', 'oilseed'] 12835\n",
      "['gold', 'silver'] 12838\n",
      "['ship', 'grain', 'oilseed', 'veg-oil', 'meal-feed'] 12839\n",
      "['dlr', 'money-fx'] 12843\n",
      "['gold', 'silver'] 12851\n",
      "['heat', 'gas'] 12879\n",
      "['gnp', 'coffee', 'bop'] 12881\n",
      "['wheat', 'barley', 'corn', 'rapeseed', 'grain', 'oilseed', 'ship'] 12884\n",
      "['wheat', 'grain', 'veg-oil'] 12885\n",
      "['ship', 'grain', 'oilseed'] 12910\n",
      "['hog', 'livestock'] 12913\n",
      "['earn', 'iron-steel'] 12917\n",
      "['grain', 'oilseed', 'corn', 'soybean'] 12935\n",
      "['grain', 'oilseed', 'corn', 'soybean'] 12938\n",
      "['money-fx', 'dlr', 'dmk'] 12943\n",
      "['gnp', 'coffee'] 12948\n",
      "['corn', 'sunseed', 'soybean', 'grain', 'oilseed'] 12963\n",
      "['money-fx', 'dlr', 'stg', 'skr', 'nkr', 'dkr', 'dmk'] 12971\n",
      "['soybean', 'oilseed'] 12983\n",
      "['acq', 'strategic-metal'] 12998\n",
      "['money-fx', 'income', 'money-supply'] 13035\n",
      "['veg-oil', 'oilseed', 'soybean'] 13036\n",
      "['money-fx', 'rand'] 13042\n",
      "['grain', 'wheat', 'corn'] 13061\n",
      "['hog', 'livestock'] 13100\n",
      "['grain', 'ship'] 13102\n",
      "['gas', 'crude'] 13149\n",
      "['gas', 'crude'] 13151\n",
      "['money-fx', 'interest'] 13158\n",
      "['grain', 'rice'] 13159\n",
      "['crude', 'earn', 'nat-gas'] 13173\n",
      "['grain', 'corn', 'wheat', 'barley'] 13204\n",
      "['interest', 'money-fx'] 13206\n",
      "['grain', 'wheat', 'corn'] 13214\n",
      "['money-supply', 'money-fx', 'interest'] 13312\n",
      "['grain', 'wheat'] 13325\n",
      "['grain', 'corn'] 13335\n",
      "['oilseed', 'soybean'] 13355\n",
      "['trade', 'money-fx'] 13374\n",
      "['grain', 'corn'] 13386\n",
      "['grain', 'corn'] 13388\n",
      "['grain', 'corn'] 13389\n",
      "['grain', 'corn'] 13394\n",
      "['heat', 'naphtha', 'jet', 'fuel'] 13396\n",
      "['crude', 'nat-gas'] 13422\n",
      "['money-fx', 'stg'] 13428\n",
      "['money-fx', 'interest'] 13459\n",
      "['grain', 'wheat'] 13470\n",
      "['money-supply', 'interest'] 13498\n",
      "['veg-oil', 'oilseed', 'soybean'] 13514\n",
      "['trade', 'bop'] 13536\n",
      "['money-fx', 'interest'] 13537\n",
      "['bop', 'trade'] 13542\n",
      "['grain', 'rice', 'wheat', 'tea', 'sugar'] 13544\n",
      "['money-fx', 'interest'] 13558\n",
      "['money-fx', 'interest'] 13561\n",
      "['grain', 'meal-feed'] 13564\n",
      "['money-fx', 'interest'] 13570\n",
      "['grain', 'barley'] 13578\n",
      "['money-fx', 'interest', 'money-supply'] 13586\n",
      "['money-fx', 'interest'] 13598\n",
      "['money-fx', 'interest'] 13613\n",
      "['oilseed', 'soybean', 'veg-oil'] 13624\n",
      "['trade', 'money-fx'] 13627\n",
      "['trade', 'bop'] 13632\n",
      "['trade', 'iron-steel', 'cotton'] 13639\n",
      "['gold', 'silver'] 13644\n",
      "['money-fx', 'interest'] 13651\n",
      "['trade', 'bop'] 13661\n",
      "['grain', 'corn', 'oilseed', 'soybean'] 13699\n",
      "['interest', 'money-fx'] 13715\n",
      "['earn', 'crude'] 13741\n",
      "['money-fx', 'interest'] 13763\n",
      "['money-fx', 'interest'] 13768\n",
      "['silver', 'copper', 'lead', 'zinc', 'gold', 'strategic-metal'] 13774\n",
      "['grain', 'corn', 'ship'] 13791\n",
      "['trade', 'money-fx'] 13803\n",
      "['lead', 'zinc'] 13841\n",
      "['gas', 'crude'] 13853\n",
      "['earn', 'acq'] 13858\n",
      "['earn', 'acq'] 13870\n",
      "['earn', 'acq'] 13903\n",
      "['grain', 'rice', 'corn', 'cotton'] 13916\n",
      "['livestock', 'pork-belly'] 13920\n",
      "['livestock', 'pork-belly'] 13923\n",
      "['earn', 'acq'] 13926\n",
      "['grain', 'wheat', 'corn'] 13933\n",
      "['grain', 'corn'] 13942\n",
      "['oilseed', 'meal-feed'] 13950\n",
      "['grain', 'wheat'] 13956\n",
      "['acq', 'ship'] 13958\n",
      "['grain', 'wheat'] 14005\n",
      "['gnp', 'bop'] 14036\n",
      "['money-fx', 'interest'] 14043\n",
      "['money-fx', 'interest'] 14045\n",
      "['veg-oil', 'soybean'] 14061\n",
      "['grain', 'wheat'] 14078\n",
      "['grain', 'wheat'] 14080\n",
      "['dlr', 'money-fx'] 14107\n",
      "['grain', 'wheat', 'rice'] 14113\n",
      "['oilseed', 'soybean'] 14115\n",
      "['grain', 'wheat'] 14126\n",
      "['grain', 'corn'] 14141\n",
      "['grain', 'wheat', 'rice'] 14152\n",
      "['interest', 'bop', 'money-supply'] 14155\n",
      "['ipi', 'jobs'] 14157\n",
      "['housing', 'interest', 'gnp'] 14196\n",
      "['grain', 'wheat'] 14208\n",
      "['grain', 'wheat', 'corn'] 14220\n",
      "['grain', 'corn'] 14235\n",
      "['wheat', 'corn'] 14238\n",
      "['trade', 'grain'] 14252\n",
      "['grain', 'wheat', 'corn'] 14258\n",
      "['grain', 'oilseed', 'soybean'] 14264\n",
      "['grain', 'oilseed', 'soybean', 'carcass', 'corn', 'cotton', 'rice'] 14268\n",
      "['grain', 'wheat'] 14295\n",
      "['grain', 'wheat'] 14325\n",
      "['money-fx', 'yen'] 14337\n",
      "['grain', 'wheat'] 14338\n",
      "['veg-oil', 'palm-oil'] 14341\n",
      "['veg-oil', 'palm-oil'] 14343\n",
      "['veg-oil', 'palm-oil'] 14353\n",
      "['money-fx', 'yen'] 14356\n",
      "['money-fx', 'interest'] 14358\n",
      "['grain', 'corn'] 14385\n",
      "['money-fx', 'stg'] 14393\n",
      "['money-fx', 'interest'] 14398\n",
      "['money-fx', 'interest'] 14399\n",
      "['ship', 'crude'] 14403\n",
      "['interest', 'trade', 'gnp', 'bop', 'cpi'] 14405\n",
      "['veg-oil', 'sun-oil', 'cotton-oil'] 14411\n",
      "['veg-oil', 'coconut-oil'] 14420\n",
      "['money-fx', 'interest'] 14425\n",
      "['zinc', 'lead'] 14450\n",
      "['money-fx', 'interest'] 14451\n",
      "['trade', 'bop'] 14463\n",
      "['interest', 'money-fx'] 14530\n",
      "['trade', 'cotton', 'iron-steel', 'naphtha', 'veg-oil', 'palm-oil'] 14534\n",
      "['money-fx', 'interest'] 14542\n",
      "['grain', 'corn', 'veg-oil'] 14584\n",
      "['grain', 'corn', 'ship'] 14587\n",
      "['gnp', 'trade'] 14592\n",
      "['trade', 'bop'] 14595\n",
      "['crude', 'nat-gas'] 14605\n",
      "['grain', 'barley'] 14625\n",
      "['trade', 'bop'] 14636\n",
      "['crude', 'ship'] 14651\n",
      "['crude', 'nat-gas'] 14655\n",
      "['grain', 'wheat'] 14719\n",
      "['crude', 'nat-gas'] 14721\n",
      "['grain', 'corn'] 14734\n",
      "['crude', 'nat-gas', 'earn'] 14741\n",
      "['grain', 'wheat'] 14743\n",
      "['grain', 'wheat'] 14750\n",
      "['crude', 'nat-gas'] 14759\n",
      "['crude', 'gas'] 14870\n",
      "['crude', 'nat-gas'] 14875\n",
      "['grain', 'wheat'] 14881\n",
      "['grain', 'corn', 'sorghum', 'sunseed', 'oilseed', 'soybean'] 14889\n",
      "['crude', 'gas'] 14892\n",
      "['grain', 'corn'] 14896\n",
      "['grain', 'wheat'] 14897\n",
      "['grain', 'wheat'] 14902\n",
      "['crude', 'nat-gas'] 14904\n",
      "['oilseed', 'soybean'] 14905\n",
      "['grain', 'wheat'] 14908\n",
      "['money-fx', 'nzdlr'] 14944\n",
      "['grain', 'wheat'] 14945\n",
      "['trade', 'bop', 'rubber', 'veg-oil', 'palm-oil'] 14953\n",
      "['trade', 'bop', 'gnp'] 14958\n",
      "['grain', 'wheat'] 14959\n",
      "['veg-oil', 'soy-oil'] 14993\n",
      "['trade', 'acq'] 15004\n",
      "['crude', 'nat-gas'] 15010\n",
      "['coffee', 'cocoa', 'sugar'] 15013\n",
      "['iron-steel', 'ship'] 15042\n",
      "['acq', 'earn'] 15072\n",
      "['money-fx', 'dlr'] 15074\n",
      "['acq', 'crude'] 15077\n",
      "['money-fx', 'dlr'] 15080\n",
      "['money-fx', 'interest'] 15090\n",
      "['acq', 'crude'] 15105\n",
      "['grain', 'wheat', 'corn'] 15119\n",
      "['grain', 'sugar', 'livestock', 'carcass'] 15123\n",
      "['gnp', 'jobs'] 15134\n",
      "['acq', 'grain', 'corn'] 15138\n",
      "['acq', 'crude'] 15167\n",
      "['grain', 'corn', 'wheat', 'oilseed', 'soybean'] 15171\n",
      "['grain', 'corn', 'wheat', 'oilseed', 'soybean', 'meal-feed', 'veg-oil', 'soy-oil', 'sorghum', 'barley'] 15174\n",
      "['acq', 'crude', 'nat-gas'] 15189\n",
      "['acq', 'earn'] 15217\n",
      "['crude', 'nat-gas'] 15227\n",
      "['money-supply', 'interest'] 15245\n",
      "['money-fx', 'dlr'] 15262\n",
      "['trade', 'grain', 'wheat', 'tea', 'coffee', 'iron-steel', 'crude'] 15267\n",
      "['iron-steel', 'trade'] 15274\n",
      "['bop', 'trade'] 15296\n",
      "['oilseed', 'veg-oil', 'castorseed', 'castor-oil'] 15299\n",
      "['grain', 'wheat'] 15304\n",
      "['money-fx', 'dlr'] 15307\n",
      "['grain', 'corn'] 15318\n",
      "['money-fx', 'dlr'] 15322\n",
      "['veg-oil', 'rape-oil'] 15329\n",
      "['money-fx', 'dlr'] 15336\n",
      "['grain', 'corn'] 15338\n",
      "['gnp', 'money-fx'] 15339\n",
      "['trade', 'bop'] 15340\n",
      "['money-fx', 'dfl'] 15343\n",
      "['money-fx', 'dlr'] 15356\n",
      "['bop', 'trade'] 15361\n",
      "['money-fx', 'dlr', 'yen'] 15363\n",
      "['money-fx', 'dlr'] 15369\n",
      "['trade', 'bop'] 15371\n",
      "['carcass', 'sugar'] 15372\n",
      "['trade', 'bop'] 15375\n",
      "['money-fx', 'dlr'] 15381\n",
      "['crude', 'ship'] 15394\n",
      "['trade', 'grain', 'wheat', 'coffee', 'tea', 'iron-steel', 'crude'] 15405\n",
      "['grain', 'wheat'] 15443\n",
      "['crude', 'ship'] 15451\n",
      "['money-fx', 'dlr'] 15474\n",
      "['gold', 'silver', 'zinc', 'lead'] 15484\n",
      "['grain', 'corn'] 15486\n",
      "['corn', 'grain'] 15488\n",
      "['grain', 'wheat'] 15493\n",
      "['interest', 'money-fx'] 15502\n",
      "['grain', 'corn', 'wheat', 'rice'] 15518\n",
      "['ipi', 'trade'] 15519\n",
      "['gnp', 'reserves'] 15530\n",
      "['crude', 'ship'] 15538\n",
      "['gold', 'money-fx'] 15545\n",
      "['cpi', 'crude', 'nat-gas', 'heat', 'propane'] 15566\n",
      "['wheat', 'grain'] 15568\n",
      "['ship', 'acq'] 15581\n",
      "['crude', 'ship'] 15587\n",
      "['livestock', 'carcass'] 15615\n",
      "['money-fx', 'dlr'] 15616\n",
      "['ship', 'crude'] 15619\n",
      "['crude', 'ship'] 15620\n",
      "['ship', 'crude'] 15626\n",
      "['money-fx', 'lit'] 15635\n",
      "['ship', 'crude'] 15640\n",
      "['trade', 'grain'] 15642\n",
      "['money-fx', 'dlr'] 15649\n",
      "['money-fx', 'dlr'] 15650\n",
      "['money-fx', 'dlr'] 15651\n",
      "['money-fx', 'dlr'] 15652\n",
      "['money-fx', 'dlr'] 15653\n",
      "['money-fx', 'dlr'] 15656\n",
      "['money-fx', 'dlr'] 15657\n",
      "['money-fx', 'dlr'] 15658\n",
      "['money-fx', 'dlr'] 15659\n",
      "['money-fx', 'dlr', 'yen'] 15678\n",
      "['money-fx', 'dlr', 'yen'] 15680\n",
      "['money-fx', 'dlr', 'yen'] 15683\n",
      "['money-fx', 'yen', 'dlr'] 15688\n",
      "['money-fx', 'dlr', 'yen'] 15695\n",
      "['grain', 'corn'] 15700\n",
      "['oilseed', 'soybean'] 15704\n",
      "['oilseed', 'coconut'] 15711\n",
      "['money-fx', 'rupiah', 'dmk', 'yen'] 15717\n",
      "['oilseed', 'coconut'] 15719\n",
      "['money-fx', 'dlr'] 15730\n",
      "['money-fx', 'dlr'] 15735\n",
      "['money-fx', 'dlr', 'dmk'] 15750\n",
      "['oilseed', 'sunseed', 'rapeseed', 'veg-oil', 'sun-oil', 'rape-oil'] 15757\n",
      "['money-fx', 'dlr', 'yen'] 15761\n",
      "['money-fx', 'dlr', 'yen'] 15765\n",
      "['money-fx', 'dlr', 'yen'] 15768\n",
      "['money-fx', 'dlr', 'yen'] 15769\n",
      "['trade', 'money-fx'] 15770\n",
      "['money-fx', 'trade'] 15779\n",
      "['money-fx', 'dlr'] 15781\n",
      "['crude', 'ship'] 15796\n",
      "['sugar', 'ship'] 15802\n",
      "['money-fx', 'yen'] 15803\n",
      "['money-fx', 'trade'] 15806\n",
      "['grain', 'wheat', 'rice'] 15829\n",
      "['hog', 'livestock'] 15856\n",
      "['grain', 'wheat', 'corn', 'oilseed', 'soybean'] 15881\n",
      "['rubber', 'pet-chem'] 15885\n",
      "['nzdlr', 'austdlr'] 15930\n",
      "['grain', 'wheat', 'corn'] 15955\n",
      "['acq', 'gold'] 15968\n",
      "['acq', 'gold'] 15993\n",
      "['money-fx', 'stg'] 15999\n",
      "['grain', 'wheat', 'barley', 'oilseed', 'rapeseed'] 16009\n",
      "['interest', 'money-fx', 'gnp'] 16017\n",
      "['oilseed', 'rapeseed'] 16020\n",
      "['grain', 'wheat'] 16021\n",
      "['money-fx', 'dlr'] 16040\n",
      "['money-fx', 'dlr'] 16043\n",
      "['money-fx', 'dlr'] 16046\n",
      "['money-supply', 'interest'] 16050\n",
      "['grain', 'corn'] 16056\n",
      "['interest', 'money-fx', 'money-supply'] 16062\n",
      "['money-fx', 'dlr', 'yen'] 16063\n",
      "['money-fx', 'dlr', 'yen'] 16064\n",
      "['money-fx', 'dlr'] 16065\n",
      "['trade', 'money-fx', 'yen'] 16067\n",
      "['money-fx', 'yen'] 16068\n",
      "['money-fx', 'dlr'] 16071\n",
      "['money-fx', 'yen'] 16077\n",
      "['crude', 'nat-gas', 'pet-chem', 'acq'] 16078\n",
      "['gnp', 'trade', 'cpi', 'jobs'] 16084\n",
      "['money-fx', 'dlr', 'yen'] 16087\n",
      "['hog', 'livestock'] 16089\n",
      "['grain', 'corn', 'sorghum'] 16091\n",
      "['crude', 'nat-gas'] 16092\n",
      "['crude', 'nat-gas'] 16095\n",
      "['crude', 'nat-gas'] 16099\n",
      "['crude', 'fuel', 'gas', 'naphtha', 'jet', 'nat-gas'] 16100\n",
      "['palm-oil', 'veg-oil'] 16104\n",
      "['bop', 'ipi', 'trade'] 16105\n",
      "['crude', 'nat-gas'] 16107\n",
      "['lead', 'zinc'] 16108\n",
      "['acq', 'crude'] 16109\n",
      "['copper', 'nickel'] 16117\n",
      "['bop', 'gnp'] 16118\n",
      "['acq', 'gold'] 16121\n",
      "['money-fx', 'dlr', 'trade'] 16125\n",
      "['oilseed', 'sunseed', 'veg-oil', 'sun-oil'] 16130\n",
      "['oilseed', 'rapeseed'] 16131\n",
      "['crude', 'nat-gas', 'gas', 'pet-chem'] 16134\n",
      "['money-fx', 'dlr', 'yen'] 16137\n",
      "['money-fx', 'bop', 'coffee'] 16140\n",
      "['gnp', 'jobs', 'cpi'] 16142\n",
      "['gnp', 'bop'] 16143\n",
      "['ship', 'grain', 'corn'] 16144\n",
      "['interest', 'money-fx'] 16146\n",
      "['crude', 'nat-gas', 'gas', 'fuel', 'cpi'] 16160\n",
      "['f-cattle', 'livestock'] 16164\n",
      "['grain', 'wheat'] 16166\n",
      "['ipi', 'trade'] 16169\n",
      "['gnp', 'interest'] 16171\n",
      "['livestock', 'f-cattle', 'pork-belly', 'l-cattle', 'carcass'] 16175\n",
      "['grain', 'wheat', 'rice', 'cotton'] 16178\n",
      "['grain', 'corn'] 16182\n",
      "['gnp', 'cpi', 'jobs'] 16184\n",
      "['gnp', 'crude', 'trade', 'bop'] 16189\n",
      "['money-supply', 'cpi'] 16192\n",
      "['trade', 'grain', 'wheat'] 16197\n",
      "['money-fx', 'dlr', 'interest'] 16199\n",
      "['trade', 'money-fx', 'dlr'] 16201\n",
      "['money-fx', 'interest'] 16203\n",
      "['trade', 'money-fx', 'dlr'] 16204\n",
      "['money-fx', 'dlr'] 16207\n",
      "['money-fx', 'dlr', 'yen'] 16208\n",
      "['money-fx', 'dlr'] 16209\n",
      "['money-fx', 'dlr'] 16210\n",
      "['money-fx', 'dlr'] 16212\n",
      "['interest', 'gnp'] 16221\n",
      "['alum', 'iron-steel', 'pet-chem'] 16227\n",
      "['ipi', 'inventories'] 16228\n",
      "['money-fx', 'dlr'] 16229\n",
      "['money-fx', 'dlr'] 16230\n",
      "['bop', 'trade'] 16236\n",
      "['money-fx', 'dlr', 'interest'] 16239\n",
      "['bop', 'trade'] 16242\n",
      "['money-fx', 'interest'] 16243\n",
      "['grain', 'rice'] 16256\n",
      "['money-fx', 'dlr'] 16264\n",
      "['money-fx', 'dlr', 'interest'] 16265\n",
      "['money-fx', 'interest'] 16266\n",
      "['money-fx', 'dlr', 'interest'] 16267\n",
      "['money-fx', 'dlr'] 16269\n",
      "['grain', 'rice'] 16279\n",
      "['trade', 'money-fx', 'dlr'] 16282\n",
      "['alum', 'iron-steel', 'pet-chem'] 16286\n",
      "['money-fx', 'dlr', 'lit'] 16292\n",
      "['money-fx', 'trade'] 16295\n",
      "['money-fx', 'dlr', 'lit'] 16299\n",
      "['ipi', 'inventories'] 16302\n",
      "['trade', 'money-fx'] 16306\n",
      "['money-fx', 'dlr'] 16307\n",
      "['trade', 'alum', 'zinc', 'pet-chem', 'iron-steel', 'grain', 'wheat', 'corn', 'cotton', 'oilseed', 'soybean'] 16311\n",
      "['money-fx', 'dlr'] 16312\n",
      "['hog', 'livestock'] 16318\n",
      "['dlr', 'money-fx'] 16319\n",
      "['money-fx', 'trade'] 16321\n",
      "['grain', 'acq'] 16322\n",
      "['dlr', 'money-fx', 'interest'] 16324\n",
      "['grain', 'corn'] 16331\n",
      "['oilseed', 'soybean', 'strategic-metal'] 16336\n",
      "['grain', 'wheat', 'barley'] 16350\n",
      "['crude', 'nat-gas'] 16352\n",
      "['crude', 'nat-gas'] 16353\n",
      "['crude', 'nat-gas'] 16354\n",
      "['grain', 'wheat'] 16355\n",
      "['carcass', 'livestock', 'orange'] 16357\n",
      "['dlr', 'money-fx'] 16362\n",
      "['grain', 'oilseed'] 16365\n",
      "['money-fx', 'dlr', 'stg'] 16366\n",
      "['crude', 'nat-gas'] 16368\n",
      "['hk', 'dlr', 'money-fx'] 16369\n",
      "['reserves', 'trade'] 16373\n",
      "['bop', 'trade'] 16374\n",
      "['money-supply', 'reserves'] 16376\n",
      "['grain', 'corn'] 16377\n",
      "['income', 'ipi'] 16378\n",
      "['meal-feed', 'tapioca', 'grain', 'barley'] 16379\n",
      "['reserves', 'dlr', 'money-fx'] 16381\n",
      "['grain', 'wheat'] 16382\n",
      "['gnp', 'trade', 'cpi'] 16384\n",
      "['oilseed', 'grain', 'veg-oil'] 16385\n",
      "['ship', 'iron-steel'] 16386\n",
      "['acq', 'alum'] 16387\n",
      "['hog', 'livestock'] 16389\n",
      "['lei', 'gnp'] 16390\n",
      "['tea', 'coffee'] 16391\n",
      "['grain', 'corn'] 16392\n",
      "['money-fx', 'sfr', 'money-supply'] 16394\n",
      "['money-fx', 'dmk', 'interest'] 16395\n",
      "['money-fx', 'sfr', 'money-supply'] 16396\n",
      "['grain', 'wheat'] 16397\n",
      "['lei', 'gnp'] 16400\n",
      "['gnp', 'cpi', 'bop'] 16401\n",
      "['fuel', 'heat', 'jet', 'gas', 'money-fx'] 16408\n",
      "['crude', 'nat-gas'] 16414\n",
      "['dlr', 'money-fx'] 16419\n",
      "['carcass', 'livestock'] 16423\n",
      "['grain', 'wheat'] 16425\n",
      "['crude', 'gas', 'fuel'] 16426\n",
      "['dlr', 'money-fx'] 16427\n",
      "['crude', 'nat-gas'] 16429\n",
      "['gas', 'fuel'] 16440\n",
      "['grain', 'orange', 'sugar'] 16442\n",
      "['veg-oil', 'coconut', 'copra-cake', 'meal-feed', 'palm-oil', 'coconut-oil'] 16476\n",
      "['zinc', 'lead', 'strategic-metal'] 16479\n",
      "['lead', 'zinc', 'strategic-metal'] 16485\n",
      "['nat-gas', 'ship'] 16491\n",
      "['grain', 'wheat', 'corn'] 16502\n",
      "['copper', 'sugar', 'grain', 'corn'] 16508\n",
      "['crude', 'nat-gas'] 16515\n",
      "['grain', 'wheat'] 16520\n",
      "['money-fx', 'interest'] 16576\n",
      "['pet-chem', 'acq'] 16579\n",
      "['acq', 'pet-chem'] 16584\n",
      "['interest', 'money-fx', 'dfl', 'dmk'] 16619\n",
      "['gold', 'silver'] 16653\n",
      "['nat-gas', 'crude'] 16657\n",
      "['grain', 'wheat'] 16661\n",
      "['coffee', 'cocoa'] 16663\n",
      "['crude', 'nat-gas'] 16668\n",
      "['trade', 'lumber'] 16669\n",
      "['gold', 'silver', 'copper', 'alum'] 16713\n",
      "['soybean', 'grain', 'wheat', 'corn'] 16721\n",
      "['acq', 'pet-chem'] 16742\n",
      "['ship', 'crude'] 16749\n",
      "['grain', 'wheat', 'oilseed'] 16754\n",
      "['grain', 'barley'] 16766\n",
      "['grain', 'barley'] 16768\n",
      "['lead', 'zinc', 'strategic-metal'] 16782\n",
      "['lead', 'zinc', 'strategic-metal'] 16804\n",
      "['acq', 'hog'] 16826\n",
      "['money-fx', 'dlr', 'trade'] 16870\n",
      "['interest', 'gnp'] 16882\n",
      "['crude', 'acq'] 16885\n",
      "['ship', 'crude'] 16887\n",
      "['acq', 'crude', 'nat-gas'] 16912\n",
      "['trade', 'bop'] 16923\n",
      "['trade', 'bop'] 16925\n",
      "['grain', 'wheat', 'ship'] 16954\n",
      "['grain', 'wheat', 'rice'] 16961\n",
      "['reserves', 'interest'] 16965\n",
      "['cpi', 'gnp'] 16969\n",
      "['cocoa', 'acq'] 16983\n",
      "['money-fx', 'interest'] 17007\n",
      "['coffee', 'crude'] 17025\n",
      "['grain', 'wheat'] 17056\n",
      "['grain', 'wheat', 'barley'] 17066\n",
      "['grain', 'wheat'] 17068\n",
      "['grain', 'wheat'] 17093\n",
      "['veg-oil', 'livestock', 'carcass'] 17109\n",
      "['money-fx', 'interest'] 17111\n",
      "['grain', 'corn', 'sorghum'] 17130\n",
      "['oilseed', 'rapeseed'] 17150\n",
      "['money-fx', 'interest'] 17153\n",
      "['grain', 'wheat'] 17184\n",
      "['meal-feed', 'soy-meal', 'grain', 'corn'] 17214\n",
      "['grain', 'wheat', 'ship'] 17256\n",
      "['grain', 'corn'] 17267\n",
      "['grain', 'corn'] 17272\n",
      "['grain', 'wheat'] 17294\n",
      "['grain', 'corn', 'sorghum'] 17368\n",
      "['livestock', 'carcass'] 17371\n",
      "['grain', 'wheat'] 17376\n",
      "['wheat', 'corn'] 17384\n",
      "['grain', 'wheat'] 17387\n",
      "['livestock', 'carcass'] 17392\n",
      "['oilseed', 'soybean'] 17393\n",
      "['grain', 'corn'] 17394\n",
      "['grain', 'wheat'] 17395\n",
      "['livestock', 'carcass'] 17397\n",
      "['grain', 'corn'] 17398\n",
      "['grain', 'cotton', 'wheat', 'oat', 'oilseed', 'soybean'] 17404\n",
      "['money-fx', 'interest'] 17420\n",
      "['money-fx', 'interest'] 17502\n",
      "['dlr', 'money-fx'] 17513\n",
      "['money-fx', 'dlr'] 17532\n",
      "['interest', 'money-fx'] 17552\n",
      "['crude', 'ship'] 17555\n",
      "['livestock', 'carcass', 'grain'] 17556\n",
      "['money-fx', 'interest'] 17559\n",
      "['grain', 'wheat'] 17569\n",
      "['grain', 'corn', 'sorghum', 'oilseed', 'sunseed', 'soybean'] 17581\n",
      "['grain', 'wheat', 'cotton', 'rice'] 17589\n",
      "['gold', 'copper'] 17606\n",
      "['bop', 'trade', 'gnp'] 17610\n",
      "['grain', 'wheat'] 17639\n",
      "['grain', 'barley', 'corn'] 17651\n",
      "['gas', 'fuel'] 17659\n",
      "['nat-gas', 'crude'] 17660\n",
      "['grain', 'wheat'] 17673\n",
      "['crude', 'nat-gas'] 17708\n",
      "['interest', 'money-fx'] 17723\n",
      "['livestock', 'carcass', 'trade'] 17771\n",
      "['grain', 'corn', 'wheat'] 17776\n",
      "['grain', 'wheat', 'oilseed', 'soybean'] 17791\n",
      "['money-fx', 'trade'] 17810\n",
      "['grain', 'corn', 'sorghum'] 17842\n",
      "['gas', 'crude'] 17850\n",
      "['crude', 'gas', 'fuel'] 17855\n",
      "['acq', 'earn'] 17859\n",
      "['crude', 'gas'] 17877\n",
      "['grain', 'cotton', 'rice', 'oilseed', 'soybean'] 17881\n",
      "['bop', 'trade'] 17889\n",
      "['grain', 'wheat', 'ship'] 17900\n",
      "['ship', 'crude'] 17903\n",
      "['grain', 'wheat'] 17906\n",
      "['grain', 'rice'] 17914\n",
      "['money-fx', 'dlr', 'yen'] 17925\n",
      "['money-fx', 'interest'] 17930\n",
      "['reserves', 'trade'] 17939\n",
      "['silver', 'gold'] 17941\n",
      "['money-fx', 'interest'] 17942\n",
      "['grain', 'corn'] 17951\n",
      "['trade', 'bop'] 17960\n",
      "['trade', 'bop'] 17963\n",
      "['money-fx', 'interest'] 17966\n",
      "['grain', 'potato', 'wheat', 'barley', 'meal-feed', 'soy-meal', 'hog', 'carcass', 'livestock'] 17969\n",
      "['money-fx', 'interest'] 17975\n",
      "['crude', 'ship'] 17979\n",
      "['money-fx', 'interest'] 17981\n",
      "['crude', 'ship'] 18001\n",
      "['crude', 'ship'] 18005\n",
      "['crude', 'ship'] 18012\n",
      "['oilseed', 'soybean'] 18079\n",
      "['oilseed', 'soybean', 'grain', 'wheat', 'corn'] 18090\n",
      "['crude', 'ship'] 18148\n",
      "['grain', 'veg-oil'] 18151\n",
      "['money-fx', 'dlr'] 18156\n",
      "['money-fx', 'dlr'] 18171\n",
      "['ship', 'crude'] 18215\n",
      "['grain', 'wheat', 'corn'] 18242\n",
      "['silver', 'gold'] 18313\n",
      "['livestock', 'carcass', 'hog'] 18366\n",
      "['ipi', 'gnp', 'grain'] 18367\n",
      "['bop', 'trade'] 18391\n",
      "['acq', 'crude', 'nat-gas'] 18416\n",
      "['money-fx', 'interest'] 18421\n",
      "['ship', 'crude'] 18442\n",
      "['ship', 'crude'] 18458\n",
      "['money-fx', 'interest'] 18467\n",
      "['ship', 'crude'] 18474\n",
      "['ship', 'crude'] 18481\n",
      "['crude', 'ship'] 18484\n",
      "['propane', 'ship'] 18485\n",
      "['crude', 'ship'] 18491\n",
      "['grain', 'corn', 'sugar', 'rubber'] 18492\n",
      "['money-fx', 'dlr', 'dmk'] 18495\n",
      "['oilseed', 'veg-oil'] 18496\n",
      "['crude', 'ship'] 18505\n",
      "['money-fx', 'interest'] 18507\n",
      "['money-fx', 'interest'] 18509\n",
      "['interest', 'money-fx'] 18510\n",
      "['gnp', 'jobs', 'bop'] 18524\n",
      "['alum', 'ship'] 18525\n",
      "['grain', 'cotton'] 18529\n",
      "['money-fx', 'rand'] 18534\n",
      "['money-fx', 'dlr', 'yen', 'dmk'] 18541\n",
      "['money-fx', 'nzdlr'] 18560\n",
      "['grain', 'rice'] 18569\n",
      "['money-fx', 'dlr', 'yen'] 18572\n",
      "['grain', 'corn'] 18595\n",
      "['crude', 'ship'] 18607\n",
      "['grain', 'rice'] 18629\n",
      "['crude', 'ship'] 18669\n",
      "['crude', 'nat-gas'] 18670\n",
      "['gold', 'copper'] 18673\n",
      "['crude', 'ship'] 18678\n",
      "['crude', 'ship'] 18680\n",
      "['meal-feed', 'soy-meal', 'oilseed', 'soybean', 'sunseed', 'rapeseed'] 18785\n",
      "['grain', 'wheat'] 18808\n",
      "['grain', 'wheat'] 18816\n",
      "['trade', 'jobs'] 18825\n",
      "['grain', 'wheat'] 18835\n",
      "['money-fx', 'interest'] 18840\n",
      "['crude', 'ship'] 18910\n",
      "['trade', 'soybean', 'veg-oil'] 18912\n",
      "['money-fx', 'interest'] 18920\n",
      "['grain', 'corn'] 18943\n",
      "['trade', 'carcass'] 19018\n",
      "['oilseed', 'soybean', 'veg-oil', 'trade'] 19038\n",
      "['trade', 'livestock', 'carcass', 'sugar'] 19039\n",
      "['ship', 'crude'] 19041\n",
      "['money-fx', 'interest'] 19077\n",
      "['trade', 'livestock', 'carcass', 'grain', 'wheat'] 19088\n",
      "['grain', 'wheat', 'oilseed', 'sunseed'] 19127\n",
      "['grain', 'wheat'] 19188\n",
      "['livestock', 'l-cattle'] 19197\n",
      "['interest', 'money-fx'] 19208\n",
      "['grain', 'corn'] 19214\n",
      "['grain', 'corn', 'wheat', 'oilseed', 'soybean'] 19222\n",
      "['trade', 'grain', 'corn'] 19226\n",
      "['money-fx', 'interest'] 19255\n",
      "['meal-feed', 'soy-meal', 'grain', 'corn'] 19300\n",
      "['crude', 'gas'] 19307\n",
      "['grain', 'wheat'] 19315\n",
      "['crude', 'ship'] 19333\n",
      "['grain', 'corn'] 19340\n",
      "['money-fx', 'interest'] 19341\n",
      "['ship', 'crude'] 19351\n",
      "['crude', 'ship'] 19405\n",
      "['money-fx', 'dlr', 'yen'] 19439\n",
      "['money-fx', 'dlr'] 19445\n",
      "['crude', 'ship'] 19458\n",
      "['crude', 'ship'] 19459\n",
      "['ship', 'crude'] 19467\n",
      "['oilseed', 'soybean', 'veg-oil', 'palm-oil', 'palmkernel', 'coconut-oil'] 19488\n",
      "['crude', 'ship'] 19558\n",
      "['crude', 'ship'] 19568\n",
      "['grain', 'wheat', 'corn', 'barley', 'oat', 'sorghum'] 19582\n",
      "['veg-oil', 'linseed', 'lin-oil', 'soy-oil', 'sun-oil', 'soybean', 'oilseed', 'corn', 'sunseed', 'grain', 'sorghum', 'wheat'] 19583\n",
      "['earn', 'acq'] 19589\n",
      "['wheat', 'grain'] 19596\n",
      "['acq', 'ship'] 19621\n",
      "['grain', 'corn'] 19634\n",
      "['veg-oil', 'soybean', 'oilseed', 'meal-feed', 'soy-meal'] 19646\n",
      "['grain', 'wheat', 'corn', 'oat', 'rye', 'sorghum', 'soybean', 'oilseed'] 19674\n",
      "['grain', 'ship'] 19683\n",
      "['carcass', 'livestock'] 19698\n",
      "['cpi', 'gnp'] 19756\n",
      "['grain', 'wheat'] 19757\n",
      "['grain', 'corn'] 19770\n",
      "['grain', 'corn', 'oat'] 19774\n",
      "['veg-oil', 'oilseed', 'meal-feed', 'soybean', 'soy-oil', 'soy-meal'] 19777\n",
      "['cpi', 'gnp'] 19786\n",
      "['money-fx', 'interest'] 19798\n",
      "['gnp', 'bop'] 19804\n",
      "['grain', 'rice'] 19805\n",
      "['soybean', 'red-bean', 'oilseed'] 19806\n",
      "['grain', 'wheat', 'rice', 'veg-oil', 'soybean', 'sugar', 'rubber', 'copra-cake', 'corn', 'palm-oil', 'palmkernel', 'coffee', 'tea', 'plywood', 'soy-meal', 'cotton'] 19812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['grain', 'wheat'] 19818\n",
      "['grain', 'wheat'] 19830\n",
      "['grain', 'wheat'] 19831\n",
      "['meal-feed', 'copra-cake'] 19844\n",
      "['veg-oil', 'palm-oil'] 19851\n",
      "['tea', 'cocoa', 'coffee'] 19852\n",
      "['money-fx', 'interest'] 19873\n",
      "['oilseed', 'soybean'] 19874\n",
      "['oilseed', 'soybean', 'meal-feed', 'soy-meal'] 19880\n",
      "['money-fx', 'interest'] 19884\n",
      "['gold', 'platinum', 'strategic-metal'] 19886\n",
      "['meal-feed', 'tapioca'] 19887\n",
      "['trade', 'bop'] 19889\n",
      "['oilseed', 'sunseed', 'soybean', 'rapeseed', 'veg-oil', 'soy-oil', 'palm-oil', 'groundnut-oil'] 19890\n",
      "['veg-oil', 'rape-oil', 'palm-oil'] 19897\n",
      "['meal-feed', 'soy-meal', 'tapioca', 'grain', 'corn', 'cornglutenfeed', 'citruspulp', 'oilseed', 'rapeseed', 'rape-meal'] 19904\n",
      "['veg-oil', 'palm-oil'] 19909\n",
      "['money-fx', 'interest'] 19913\n",
      "['money-fx', 'interest'] 19918\n",
      "['crude', 'ship'] 19945\n",
      "['grain', 'wheat', 'corn', 'barley'] 19972\n",
      "['money-fx', 'interest'] 19988\n",
      "['grain', 'oat'] 19994\n",
      "['grain', 'wheat', 'wool', 'dlr'] 20002\n",
      "['livestock', 'l-cattle'] 20020\n",
      "['gold', 'acq', 'platinum'] 20025\n",
      "['earn', 'acq'] 20050\n",
      "['money-fx', 'interest'] 20052\n",
      "['gold', 'silver'] 20065\n",
      "['grain', 'corn', 'wheat', 'barley'] 20078\n",
      "['grain', 'corn'] 20093\n",
      "['money-fx', 'interest'] 20096\n",
      "['money-fx', 'interest'] 20099\n",
      "['oilseed', 'grain', 'soybean', 'wheat', 'corn'] 20271\n",
      "['crude', 'nat-gas'] 20285\n",
      "['earn', 'acq'] 20307\n",
      "['grain', 'wheat'] 20319\n",
      "['livestock', 'hog'] 20375\n",
      "['propane', 'heat', 'gas'] 20406\n",
      "['veg-oil', 'soy-oil', 'oilseed', 'soybean'] 20410\n",
      "['gnp', 'trade'] 20420\n",
      "['grain', 'oat', 'corn', 'oilseed', 'soybean'] 20432\n",
      "['grain', 'wheat'] 20433\n",
      "['money-fx', 'yen', 'dlr'] 20449\n",
      "['grain', 'wheat'] 20451\n",
      "['veg-oil', 'palm-oil'] 20462\n",
      "['money-fx', 'interest'] 20490\n",
      "['money-fx', 'saudriyal'] 20492\n",
      "['earn', 'alum'] 20498\n",
      "['interest', 'money-fx'] 20503\n",
      "['grain', 'corn'] 20511\n",
      "['earn', 'alum'] 20515\n",
      "['interest', 'money-fx'] 20519\n",
      "['money-fx', 'interest'] 20520\n",
      "['veg-oil', 'palm-oil'] 20521\n",
      "['money-fx', 'interest'] 20530\n",
      "['earn', 'crude'] 20565\n",
      "['money-fx', 'interest'] 20576\n",
      "['acq', 'crude', 'nat-gas'] 20584\n",
      "['money-fx', 'grain', 'cotton', 'livestock', 'gold', 'silver'] 20586\n",
      "['grain', 'corn'] 20589\n",
      "['grain', 'ship'] 20591\n",
      "['ship', 'crude'] 20617\n",
      "['interest', 'money-fx', 'dlr'] 20630\n",
      "['money-fx', 'dlr'] 20643\n",
      "['money-fx', 'dlr'] 20644\n",
      "['money-fx', 'dlr'] 20645\n",
      "['money-fx', 'dlr'] 20646\n",
      "['grain', 'wheat', 'corn', 'sorghum', 'oat'] 20648\n",
      "['money-fx', 'interest'] 20649\n",
      "['grain', 'rice'] 20656\n",
      "['veg-oil', 'soy-oil', 'rape-oil'] 20657\n",
      "['interest', 'money-supply'] 20660\n",
      "['grain', 'corn', 'rice'] 20676\n",
      "['dlr', 'money-fx'] 20683\n",
      "['bop', 'gnp', 'cpi'] 20685\n",
      "['dlr', 'money-fx'] 20688\n",
      "['trade', 'wpi', 'cpi', 'income', 'retail'] 20695\n",
      "['grain', 'wheat'] 20721\n",
      "['grain', 'corn', 'rice', 'oilseed', 'cottonseed', 'groundnut'] 20724\n",
      "['gnp', 'jobs', 'bop', 'cpi'] 20735\n",
      "['interest', 'money-fx'] 20738\n",
      "['gold', 'platinum'] 20739\n",
      "['money-fx', 'interest'] 20757\n",
      "['dlr', 'money-fx'] 20766\n",
      "['money-fx', 'trade'] 20767\n",
      "['veg-oil', 'palm-oil'] 20770\n",
      "['gnp', 'bop', 'cpi'] 20803\n",
      "['f-cattle', 'livestock'] 20813\n",
      "['gold', 'silver', 'platinum'] 20825\n",
      "['reserves', 'money-supply'] 20827\n",
      "['hog', 'livestock'] 20832\n",
      "['grain', 'oilseed', 'meal-feed'] 20842\n",
      "['money-supply', 'cpi', 'gnp'] 20845\n",
      "['grain', 'wheat'] 20848\n",
      "['acq', 'alum'] 20897\n",
      "['veg-oil', 'palm-oil'] 20939\n",
      "['crude', 'ship'] 20943\n",
      "['acq', 'livestock', 'carcass'] 20956\n",
      "['money-fx', 'interest'] 20960\n",
      "['acq', 'earn'] 20979\n",
      "['oilseed', 'rapeseed'] 21010\n",
      "['crude', 'nat-gas'] 21015\n",
      "['acq', 'earn'] 21060\n",
      "['acq', 'livestock'] 21096\n",
      "['grain', 'corn', 'wheat', 'oilseed', 'soybean'] 21102\n",
      "['carcass', 'livestock'] 21141\n",
      "['interest', 'money-fx'] 21142\n",
      "['crude', 'nat-gas'] 21170\n",
      "['grain', 'rice'] 21178\n",
      "['grain', 'corn'] 21201\n",
      "['dlr', 'money-fx'] 21320\n",
      "['dlr', 'money-fx'] 21321\n",
      "['grain', 'corn'] 21328\n",
      "['veg-oil', 'soybean'] 21329\n",
      "['grain', 'sorghum'] 21330\n",
      "['grain', 'trade'] 21340\n",
      "['grain', 'corn'] 21342\n",
      "['bop', 'trade'] 21343\n",
      "['trade', 'reserves'] 21352\n",
      "['trade', 'carcass', 'orange', 'rice'] 21361\n",
      "['trade', 'grain'] 21367\n",
      "['grain', 'rice'] 21513\n",
      "['money-fx', 'interest'] 21519\n",
      "['grain', 'rice', 'trade'] 21520\n",
      "['earn', 'alum'] 21521\n",
      "['veg-oil', 'palm-oil'] 21522\n",
      "['trade', 'grain', 'rice', 'carcass', 'livestock', 'orange'] 21524\n",
      "['trade', 'gnp', 'bop', 'reserves', 'money-fx'] 21525\n",
      "['interest', 'money-fx', 'bfr', 'reserves'] 21528\n",
      "['dlr', 'money-fx'] 21531\n",
      "['veg-oil', 'palm-oil'] 21533\n",
      "['trade', 'ipi'] 21536\n",
      "['trade', 'ipi', 'grain'] 21537\n",
      "['acq', 'gold', 'silver', 'copper'] 21548\n",
      "['trade', 'oilseed', 'groundnut'] 21549\n",
      "['grain', 'wheat'] 21551\n",
      "['money-fx', 'dlr', 'yen'] 21553\n",
      "['money-fx', 'dlr', 'yen'] 21554\n",
      "['hog', 'livestock'] 21557\n",
      "['dlr', 'interest', 'money-fx'] 21559\n",
      "['nickel', 'acq'] 21575\n",
      "1873\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for ids in all_files:\n",
    "    if len(all_files[ids]['topics']) > 1:\n",
    "        print(all_files[ids]['topics'], ids)\n",
    "        count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_jsons(jsons_dictionary):\n",
    "    with_topics_body, with_topics_topics, no_topics_body, no_topics_topic = list(), list(), list(), list()\n",
    "    for key in jsons_dictionary:\n",
    "        if jsons_dictionary[key]['attrs']['topics'] == 'YES':\n",
    "            with_topics_body.append(jsons_dictionary[key]['body'])\n",
    "            with_topics_topics.append(jsons_dictionary[key]['topics'])\n",
    "        else:\n",
    "            no_topics_body.append(jsons_dictionary[key]['body'])\n",
    "            no_topics_topic.append(jsons_dictionary[key]['topics'])\n",
    "    return with_topics_body, with_topics_topics, no_topics_body, no_topics_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters_with_topics_b, reuters_with_topics_t, reuters_no_topics_b, no_topics_topic = split_jsons(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8102, 13476, str)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reuters_no_topics_b), len(reuters_with_topics_b), type(reuters_no_topics_b[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed in: 0.3280580329999996\n"
     ]
    }
   ],
   "source": [
    "reut_train = list()\n",
    "start = timer()\n",
    "for body in reuters_with_topics_b:\n",
    "    body_list = list()\n",
    "    body = body.split(' ')\n",
    "    for token in body:\n",
    "        body_list.append(token)\n",
    "    reut_train.append(body_list)\n",
    "end = timer()\n",
    "\n",
    "print('Executed in:', end-start)\n",
    "\n",
    "# len(reut_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 2 sgm version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def from_sgm(path_name):\n",
    "    start = timer()\n",
    "    count, count2 = 0, 0\n",
    "    corpus, raw_labels = list(), list()\n",
    "    title_list = [title for title in os.listdir(path_name) if title.endswith('.sgm')]\n",
    "    for title in title_list:\n",
    "        with open(os.path.join(path_name, title), encoding='utf-8', errors='ignore') as sgm_file:\n",
    "            soup = BeautifulSoup(sgm_file)\n",
    "            all_snippets = soup.findAll('text')\n",
    "            all_topics = soup.findAll('topics') \n",
    "            for topics in all_topics:\n",
    "                per_snippet = list()\n",
    "                if topics != None:\n",
    "                    ds = topics.findAll('d')\n",
    "                    for d in ds:\n",
    "                        per_snippet.append(d.text)\n",
    "                else:\n",
    "                    per_snippet.append('')\n",
    "                raw_labels.append(per_snippet)\n",
    "            for snippet in all_snippets:\n",
    "                snip = snippet.text\n",
    "                # some snippets still have some\n",
    "                # title or dateline or both\n",
    "                # for the function not to crash - try and except\n",
    "                try:\n",
    "                    snip = snip.replace(snippet.title.text, '')\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    snip = snip.replace(snippet.dateline.text, '')\n",
    "                except:\n",
    "                    pass\n",
    "                corpus.append(snip) \n",
    "    end = timer()\n",
    "    print('Executed in:', end-start)\n",
    "    return corpus, raw_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed in: 12.635761907000001\n",
      "Executed in: 12.182174971999999\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    reut_data, raw_reut_labels = from_sgm('./json-reuters-21578/sgm-data')\n",
    "except:\n",
    "    !git clone https://github.com/mihaibogdan10/json-reuters-21578.git\n",
    "finally:\n",
    "    reut_data, raw_reut_labels = from_sgm('./json-reuters-21578/sgm-data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update: removing NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MULTILABEL OPTION ---\n",
    "\n",
    "# reut_labels = raw_reut_labels \n",
    "\n",
    "# --- ONE-LABEL OPTION WITH NANS ---\n",
    "\n",
    "def one_label_with_nans(raw_data, raw_labels):\n",
    "    labels = list()\n",
    "    for i in raw_labels:\n",
    "        if len(i) >= 1:\n",
    "            labels.append(i[0])\n",
    "        else:\n",
    "            labels.append('')\n",
    "    return raw_data, labels\n",
    "\n",
    "# --- ONE-LABEL OPTION WITHOUT NANS ---\n",
    "\n",
    "def one_label_no_nans(raw_data, raw_labels):\n",
    "    data = list()\n",
    "    labels = list()\n",
    "    for i, label in enumerate(raw_labels):\n",
    "        if len(label) >= 1:\n",
    "            labels.append(label[0])\n",
    "            data.append(raw_data[i])\n",
    "    return data, labels\n",
    "\n",
    "# --- ONE-LABEL OPTION WITHOUT NANS AND SPARSE CATEGORIES ---\n",
    "\n",
    "# the names are getting out of hand\n",
    "def one_label_no_nans_no_cats(alt_data, alt_labels, r=20):  \n",
    "    label_dict = dict()\n",
    "    data = list()\n",
    "    labels = list()\n",
    "    for label in alt_labels:\n",
    "        if label in label_dict:\n",
    "            label_dict[label] += 1\n",
    "        else:\n",
    "            label_dict[label] = 1\n",
    "    for i, label in enumerate(alt_labels):\n",
    "        if label_dict[label] > r:\n",
    "            labels.append(label)\n",
    "            data.append(alt_data[i]) \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with NaNs: 21578 21578\n",
      "Dataset without NaNs: 11367 11367\n",
      "Dataset A without NaNs and sparse categories: 11106 11106\n",
      "Dataset B without NaNs and sparse categories: 10725 10725\n"
     ]
    }
   ],
   "source": [
    "reut_data, reut_labels = one_label_with_nans(reut_data, raw_reut_labels)\n",
    "# # reut_data, reut_labels = reut_data0, reut_labels0\n",
    "\n",
    "alt_data, alt_labels = one_label_no_nans(reut_data, raw_reut_labels)\n",
    "\n",
    "alt_data_a, alt_labels_a = one_label_no_nans_no_cats(alt_data, alt_labels, r=20)\n",
    "\n",
    "alt_data_b, alt_labels_b = one_label_no_nans_no_cats(alt_data, alt_labels, r=50)\n",
    "\n",
    "print('Dataset with NaNs:', len(reut_data), len(reut_labels))\n",
    "print('Dataset without NaNs:', len(alt_data), len(alt_labels))\n",
    "print('Dataset A without NaNs and sparse categories:', len(alt_data_a), len(alt_labels_a))\n",
    "print('Dataset B without NaNs and sparse categories:', len(alt_data_b), len(alt_labels_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snippets retrieved in the chosen data set: 21578\n",
      "Labels retrieved in the chosen data set: 21578\n"
     ]
    }
   ],
   "source": [
    "print('Snippets retrieved in the chosen data set:', len(reut_data))\n",
    "print('Labels retrieved in the chosen data set:', len(reut_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = dict()\n",
    "for label in reut_labels:\n",
    "        if label in label_dict:\n",
    "            label_dict[label] += 1\n",
    "        else:\n",
    "            label_dict[label] = 1\n",
    "            \n",
    "len(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_list(file):\n",
    "    txt = list()\n",
    "    with open(file, mode='r') as f:\n",
    "        for line in f:\n",
    "            txt.append(line.strip())\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_vocabulary = txt_to_list('json-reuters-21578/other-data/all-topics-strings.lc.txt')\n",
    "len(label_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to look at the results, uncomment below\n",
    "\n",
    "# a, b, c = random.randint(0, len(reut_data)), random.randint(0, len(reut_data)), random.randint(0, len(reut_data))\n",
    "\n",
    "# print(reut_data[a], reut_data[b], reut_data[c])\n",
    "# print(reut_labels[a], reut_labels[b], reut_labels[c])\n",
    "\n",
    "# print('\\nIndexes:', a, b, c, '\\n')\n",
    "\n",
    "# print('100 labels:\\n')\n",
    "# print(reut_labels[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(reut_data) == len(reut_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Loading data: NEWSGROUPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "ng = fetch_20newsgroups(remove=('headers', 'footers'), subset='all', shuffle=True)\n",
    "ng1 = fetch_20newsgroups(subset='all', shuffle=True)\n",
    "ng2 = fetch_20newsgroups(subset='all')\n",
    "\n",
    "# For data description uncomment below\n",
    "# print(ng_train.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers\n",
    "\n",
    "\n",
    "**K-nearest neighbours**\n",
    "The inductive bias of KNN algorithm: a unit is most similar to those units, which are the closest. \n",
    "Two most important parameters for the algorithm are k and distance function. Choosing k can be challenging as the smaller the k chosen, the more noise would affect the output, however, a high k would result in high computational load. As there are 132 original labels in reuters data, a simple approach of using square root of sum all labels was applied. Interestingly enough, this yielded higher accuracy when applied to newsgroup data as well (instead of default 5, which would be approximately the same as square root of newsgroup labels). As for distance, for the initial implementation the dafault parameter, Manhattan distance, was chosen. Limitations: KNN is by far not optimal for Reuters data set as it is noisy and has many missing values. However, for newsgroups, it shows promise, as it has (in comparison with reuters) low dimesnionality. No normalization was implemented, although it is recommended. The algorithm parameter was not explored, as sparse data was used and the parameter would be automatically overridden to brute force. This was also the reason why leaf size was not adjusted.\n",
    "\n",
    "**Multinomial Naive Bayes**\n",
    "From the Naive Bayes models, Multinomial was chosen because of categorical nature of the task (Binomial - for binary, Gaussian - numerical).\n",
    "The inductive bias for Multinomial Naive Bayes: the underlying assumption that the variables are independent has to be established as true.  A small Laplace smoothing was chosen, for unrepresented features to have least impact as possible. As is the case with KNN, Multinomial Naive Bayes also requires low computational resources and is proven to be accurate on small data sets.\n",
    "\n",
    "\n",
    "**Random Forest**\n",
    "The inductive bias for Random Forest: the tree, which has the most important information close to root, is the most acceptable and the shorter the leaves are, the better. Default settings were used, which means that the number of trees was set to 100, splits were achieved using gini criterion, the minimum for a sample split was 2, whereas minimum of samples for a leaf was 1. Neither impurity, nor bootsrapping ere explored at this stage as it is more advanced features. Also, as bootstraping would consider the whole sata set for every tree, the computational cost would rise dramatically and in turn, training time as well, which was not a favourable feature of this design as reruns of code is a very typical part of the educational process. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe(data, target, categories='newsgroups', t=0.10):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=t)\n",
    "    print('Train data:', len(x_train), 'Test data:', len(x_test))\n",
    "\n",
    "    \n",
    "    # ---- KNN ----\n",
    "    \n",
    "    model_kn = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words='english',token_pattern=r\"(?u)\\b\\w\\w+\\b|!|\\?|\\\"|\\'\", ngram_range=(1, 1))),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "    ('clf', KNeighborsClassifier(n_neighbors=7, p=2))\n",
    "    ], verbose=True)\n",
    "    \n",
    "    # ---- MULTINOMIAL NAIVE BAYES ----\n",
    "\n",
    "    model_nb = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words='english', token_pattern=r\"(?u)\\b\\w\\w+\\b|!|\\?|\\\"|\\'\", ngram_range=(1, 1))),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "    ('clf', MultinomialNB()),\n",
    "    ], verbose=True)\n",
    "    \n",
    "    # ---- RANDOM FOREST ----\n",
    "    \n",
    "    model_rf = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words='english', token_pattern=r\"(?u)\\b\\w\\w+\\b|!|\\?|\\\"|\\'\", ngram_range=(1, 1))),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "    ('clf', RandomForestClassifier()),\n",
    "    ], verbose=True)\n",
    "    \n",
    "    # --- TRAINING KNN ---\n",
    "    \n",
    "    print('\\nKNN \\n')\n",
    "    start = timer()\n",
    "    model_kn.fit(x_train, y_train)\n",
    "    end = timer()\n",
    "    print('Total time:', end-start)\n",
    "    \n",
    "    # ---- CREATING PREDICTIONS ----\n",
    "    \n",
    "    y_hat_kn = model_kn.predict(x_test)\n",
    "    \n",
    "    # --- TRAINING MULTINOMIAL NAIVE BAYES ---\n",
    "    \n",
    "    print('\\nMutlinomial Naive Bayes Classifier \\n')\n",
    "    start = timer()\n",
    "    model_nb.fit(x_train, y_train)\n",
    "    end = timer()\n",
    "    print('Total time:', end-start)    \n",
    "    \n",
    "    # ---- CREATING PREDICTIONS ----\n",
    "\n",
    "    y_hat_nb = model_nb.predict(x_test)\n",
    "    \n",
    "    # --- TRAINING RANDOM FOREST ---\n",
    "    \n",
    "    print('\\nRandom Forest \\n')\n",
    "    start = timer()\n",
    "    model_rf.fit(x_train, y_train)\n",
    "    end = timer()\n",
    "    print('Total time:', end-start)    \n",
    "    \n",
    "    # ---- CREATING PREDICTIONS ----\n",
    "\n",
    "    y_hat_rf = model_rf.predict(x_test)\n",
    "    \n",
    "    # ---- CATEGORIES: REUTERS ----\n",
    "    \n",
    "    if categories == 'reuters':\n",
    "        print('\\nOverall categories:', len(label_vocabulary), '\\n')\n",
    "        categories = list(set(y_test))\n",
    "                \n",
    "    # ---- CATEGORIES: NEWSGROUPS ----\n",
    "\n",
    "    elif categories == 'newsgroups':\n",
    "        print('\\nOverall categories:', len(ng.target_names), '\\n')\n",
    "        categories = ng.target_names\n",
    "    \n",
    "    # ---- CATEGORY REPRESENTATION ----\n",
    "    print('Categories represented in test set:', len(set(y_test)), '\\n')\n",
    "    alt_categories = categories.append('ERROR')\n",
    "    \n",
    "    \n",
    "    # ---- METRICS: KNN  ----\n",
    "    try:\n",
    "        cr_kn = metrics.classification_report(y_test, y_hat_kn, target_names=categories, zero_division=0)\n",
    "        cm_kn = metrics.confusion_matrix(y_test, y_hat_kn)\n",
    "    except:\n",
    "        cr_kn = metrics.classification_report(y_test, y_hat_kn, target_names=alt_categories, zero_division=0)\n",
    "        cm_kn = metrics.confusion_matrix(y_test, y_hat_kn)\n",
    "        print('Resolved diffferences in labels for KNN')\n",
    "    \n",
    "    # ---- METRICS: MULTINOMIAL NAIVE BAYES ----\n",
    "    try:\n",
    "        cr_nb = metrics.classification_report(y_test, y_hat_nb, target_names=categories, zero_division=0)\n",
    "        cm_nb = metrics.confusion_matrix(y_test, y_hat_nb)\n",
    "    except:  \n",
    "        cr_nb = metrics.classification_report(y_test, y_hat_nb, target_names=alt_categories, zero_division=0)\n",
    "        cm_nb = metrics.confusion_matrix(y_test, y_hat_nb)\n",
    "        print('Resolved diffferences in labels for Multinomial NB')\n",
    "    \n",
    "    # ---- METRICS: RANDOM FOREST ----\n",
    "    \n",
    "    try:\n",
    "        cr_rf = metrics.classification_report(y_test, y_hat_rf, target_names=categories, zero_division=0)\n",
    "        cm_rf = metrics.confusion_matrix(y_test, y_hat_rf)\n",
    "    except:\n",
    "        categories = set(y_test)\n",
    "        cr_rf = metrics.classification_report(y_test, y_hat_rf, target_names=alt_categories, zero_division=0)\n",
    "        cm_rf = metrics.confusion_matrix(y_test, y_hat_rf)\n",
    "        print('Resolved diffferences in labels for Random Forest')\n",
    "\n",
    "    \n",
    "    return cr_kn, cm_kn, cr_nb, cm_nb, x_train, y_train, model_kn, model_nb, y_hat_kn, y_hat_nb, cr_rf, cm_rf, model_rf, y_hat_rf, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep track of variables.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cr_kn': 0,\n",
       " 'cm_kn': 1,\n",
       " 'cr_nb': 2,\n",
       " 'cm_nb': 3,\n",
       " 'x_train': 4,\n",
       " 'y_train': 5,\n",
       " 'model_kn': 6,\n",
       " 'model_nb': 7,\n",
       " 'y_hat_kn': 8,\n",
       " 'y_hat_nb': 9,\n",
       " 'cr_rf': 10,\n",
       " 'cm_rf': 11,\n",
       " 'model_rf': 12,\n",
       " 'y_hat_rf': 13,\n",
       " 'x_test': 14,\n",
       " 'y_test': 15}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = 'cr_kn, cm_kn, cr_nb, cm_nb, x_train, y_train, model_kn, model_nb, y_hat_kn, y_hat_nb, cr_rf, cm_rf, model_rf, y_hat_rf, x_test, y_test'\n",
    "ret = ret.split(', ')\n",
    "\n",
    "lazy=dict()\n",
    "for i, name in enumerate(ret):\n",
    "    lazy[name] = i\n",
    "    \n",
    "lazy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 16961 Test data: 1885\n",
      "\n",
      "KNN \n",
      "\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   3.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.2s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.0s\n",
      "Total time: 3.293972136000008\n",
      "\n",
      "Mutlinomial Naive Bayes Classifier \n",
      "\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   3.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.1s\n",
      "Total time: 3.342255776000002\n",
      "\n",
      "Random Forest \n",
      "\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   2.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 1.1min\n",
      "Total time: 69.84336445699998\n",
      "\n",
      "Overall categories: 20 \n",
      "\n",
      "Categories represented in test set: 20 \n",
      "\n",
      "Resolved diffferences in labels for KNN\n",
      "Resolved diffferences in labels for Multinomial NB\n",
      "Resolved diffferences in labels for Random Forest\n"
     ]
    }
   ],
   "source": [
    "newsgroups = pipe(ng.data, ng.target, categories='newsgroups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 15076 Test data: 3770\n",
      "\n",
      "KNN \n",
      "\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   2.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.0s\n",
      "Total time: 2.7958977339999933\n",
      "\n",
      "Mutlinomial Naive Bayes Classifier \n",
      "\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   2.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.1s\n",
      "Total time: 2.9371805040000254\n",
      "\n",
      "Random Forest \n",
      "\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   2.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 1.0min\n",
      "Total time: 63.35609672700002\n",
      "\n",
      "Overall categories: 21 \n",
      "\n",
      "Categories represented in test set: 20 \n",
      "\n",
      "Resolved diffferences in labels for KNN\n",
      "Resolved diffferences in labels for Multinomial NB\n",
      "Resolved diffferences in labels for Random Forest\n"
     ]
    }
   ],
   "source": [
    "newsgroups_t20 = pipe(ng.data, ng.target, categories='newsgroups', t=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 16961 Test data: 1885\n",
      "\n",
      "KNN \n",
      "\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   3.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.2s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.0s\n",
      "Total time: 3.948120301000017\n",
      "\n",
      "Mutlinomial Naive Bayes Classifier \n",
      "\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   3.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.2s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.2s\n",
      "Total time: 4.067693521999956\n",
      "\n",
      "Random Forest \n",
      "\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   3.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.2s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 1.0min\n",
      "Total time: 64.860000184\n",
      "\n",
      "Overall categories: 22 \n",
      "\n",
      "Categories represented in test set: 20 \n",
      "\n",
      "Resolved diffferences in labels for KNN\n",
      "Resolved diffferences in labels for Multinomial NB\n",
      "Resolved diffferences in labels for Random Forest\n"
     ]
    }
   ],
   "source": [
    "newsgroups1 = pipe(ng1.data, ng1.target, categories='newsgroups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 16961 Test data: 1885\n",
      "\n",
      "KNN \n",
      "\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   3.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.2s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.0s\n",
      "Total time: 3.969961506000004\n",
      "\n",
      "Mutlinomial Naive Bayes Classifier \n",
      "\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   3.6s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.2s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.2s\n",
      "Total time: 3.9521508770000082\n",
      "\n",
      "Random Forest \n",
      "\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   3.5s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.2s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  59.3s\n",
      "Total time: 62.98186311400002\n",
      "\n",
      "Overall categories: 23 \n",
      "\n",
      "Categories represented in test set: 20 \n",
      "\n",
      "Resolved diffferences in labels for KNN\n",
      "Resolved diffferences in labels for Multinomial NB\n",
      "Resolved diffferences in labels for Random Forest\n"
     ]
    }
   ],
   "source": [
    "newsgroups2 = pipe(ng2.data, ng2.target, categories='newsgroups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 19420 Test data: 2158\n",
      "\n",
      "KNN \n",
      "\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.6s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.0s\n",
      "Total time: 1.6953826440000057\n",
      "\n",
      "Mutlinomial Naive Bayes Classifier \n",
      "\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.6s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.2s\n",
      "Total time: 1.92336414600004\n",
      "\n",
      "Random Forest \n",
      "\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.5s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  31.1s\n",
      "Total time: 32.65370648800001\n",
      "\n",
      "Overall categories: 135 \n",
      "\n",
      "Categories represented in test set: 57 \n",
      "\n",
      "Resolved diffferences in labels for KNN\n",
      "Resolved diffferences in labels for Multinomial NB\n",
      "Resolved diffferences in labels for Random Forest\n"
     ]
    }
   ],
   "source": [
    "reuters = pipe(reut_data, reut_labels, categories='reuters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 17262 Test data: 4316\n",
      "\n",
      "KNN \n",
      "\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.4s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.0s\n",
      "Total time: 1.5277836469999784\n",
      "\n",
      "Mutlinomial Naive Bayes Classifier \n",
      "\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.4s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.2s\n",
      "Total time: 1.6346554049999895\n",
      "\n",
      "Random Forest \n",
      "\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  24.8s\n",
      "Total time: 26.229727502999935\n",
      "\n",
      "Overall categories: 135 \n",
      "\n",
      "Categories represented in test set: 66 \n",
      "\n",
      "Resolved diffferences in labels for Multinomial NB\n",
      "Resolved diffferences in labels for Random Forest\n"
     ]
    }
   ],
   "source": [
    "reuters_t20 = pipe(reut_data, reut_labels, categories='reuters', t=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 10230 Test data: 1137\n",
      "\n",
      "KNN \n",
      "\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.0s\n",
      "Total time: 0.9005920500000002\n",
      "\n",
      "Mutlinomial Naive Bayes Classifier \n",
      "\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.1s\n",
      "Total time: 1.0469106680000095\n",
      "\n",
      "Random Forest \n",
      "\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.3s\n",
      "Total time: 11.208584803999997\n",
      "\n",
      "Overall categories: 135 \n",
      "\n",
      "Categories represented in test set: 56 \n",
      "\n",
      "Resolved diffferences in labels for KNN\n",
      "Resolved diffferences in labels for Multinomial NB\n",
      "Resolved diffferences in labels for Random Forest\n"
     ]
    }
   ],
   "source": [
    "alt_reuters = pipe(alt_data, alt_labels, categories='reuters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 9995 Test data: 1111\n",
      "\n",
      "KNN \n",
      "\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.0s\n",
      "Total time: 0.9317146240000511\n",
      "\n",
      "Mutlinomial Naive Bayes Classifier \n",
      "\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.1s\n",
      "Total time: 0.9998160870001129\n",
      "\n",
      "Random Forest \n",
      "\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   9.1s\n",
      "Total time: 9.97545810600002\n",
      "\n",
      "Overall categories: 135 \n",
      "\n",
      "Categories represented in test set: 39 \n",
      "\n",
      "Resolved diffferences in labels for KNN\n",
      "Resolved diffferences in labels for Multinomial NB\n",
      "Resolved diffferences in labels for Random Forest\n"
     ]
    }
   ],
   "source": [
    "alt_reuters_a = pipe(alt_data_a, alt_labels_a, categories='reuters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 9652 Test data: 1073\n",
      "\n",
      "KNN \n",
      "\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.0s\n",
      "Total time: 0.8554405720000204\n",
      "\n",
      "Mutlinomial Naive Bayes Classifier \n",
      "\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.0s\n",
      "Total time: 0.8650460209998982\n",
      "\n",
      "Random Forest \n",
      "\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.6s\n",
      "Total time: 8.375103979999949\n",
      "\n",
      "Overall categories: 135 \n",
      "\n",
      "Categories represented in test set: 26 \n",
      "\n",
      "Resolved diffferences in labels for KNN\n",
      "Resolved diffferences in labels for Multinomial NB\n",
      "Resolved diffferences in labels for Random Forest\n"
     ]
    }
   ],
   "source": [
    "alt_reuters_b = pipe(alt_data_b, alt_labels_b, categories='reuters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "**Newsgroups**\n",
    "Non-surprisingly, KNN performed the worst when considering non-weighted accuracy (true positives and true negatives count compared to overall count), when given data without headers and footers, shuffled, because in that case it cannot find which data is close originally. The best result was achieved with Random Forest Trees (95.91\\%) when 80/20 split, shuffled and cleaned data was used. However, such high accuracy indicates possible overfitting: unfortunately, the data was split only to train and test sets, without validation, which would help investigate this assumption. A more detailed inspection reveals that, considering other metrics, in actuality Multinomial NB fits Newsgroups the best: the precision of the model goes as high as 95\\% for some of the classes, with 90\\% overall.\n",
    "\n",
    "**Reuters**\n",
    "The idea to remove NaNs completely from the data set has proven to be faulty: data without NaNs or with cleaned categories yielded much worse results. However, because working with NaNs is bad practice, for future designs it would be more acceptable to fill NaNs with a label 'no label'. As for the accuracy, KNN with Multinomial NB performed similarly, whereas Random Forest returned the best result (91.89\\%), with 80/20 data with NaNs. As compared to Newsgroups, heatmap inspection is not informative as the classes in Reuters data are skewed. This could also explain why for some of the categories the precision and recall were both either 0.00 or precision 100\\%, yet with very low recall in both KNN and Random Forest. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_compare(model_to_check, dataset):\n",
    "    if dataset == 'reuters':\n",
    "        og_x_test, og_y_test = reuters[14], reuters[15]\n",
    "    else:\n",
    "        og_x_test, og_y_test = newsgroups[14], newsgroups[15]\n",
    "        \n",
    "    to_check_y_hat = model_to_check.predict(og_x_test)\n",
    "    \n",
    "    count=0\n",
    "    for i, label in enumerate(to_check_y_hat):\n",
    "        if og_y_test[i] == label:\n",
    "            count += 1\n",
    "    print('Accuracy:', round(count/len(og_y_test)*100, 3), '%')\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_metrics(data):\n",
    "    cm = data\n",
    "    fig, ax = plt.subplots(figsize=(11, 9))\n",
    "    sns.heatmap(cm, cmap=\"Blues\", vmax=100, linewidth=0.001)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_comparisons(comparisons, dataset):\n",
    "    for model_type in comparisons:\n",
    "        print(model_type)\n",
    "        print()\n",
    "        for modification in comparisons[model_type]:\n",
    "            print(modification)\n",
    "            simple_compare(comparisons[model_type][modification], dataset)\n",
    "            print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---NEWSGROUPS---\n",
      "\n",
      "KNN\n",
      "\n",
      "without headers, footers, shuffled 90/10\n",
      "Accuracy: 24.297 %\n",
      "\n",
      "without headers, footers, shuffled 80/20\n",
      "Accuracy: 35.491 %\n",
      "\n",
      "with headers, footers, non-shuffled\n",
      "Accuracy: 84.191 %\n",
      "\n",
      "default\n",
      "Accuracy: 84.456 %\n",
      "\n",
      "\n",
      "MNB\n",
      "\n",
      "without headers, footers, shuffled 90/10\n",
      "Accuracy: 84.138 %\n",
      "\n",
      "without headers, footers, shuffled 80/20\n",
      "Accuracy: 90.716 %\n",
      "\n",
      "with headers, footers, non-shuffled\n",
      "Accuracy: 89.39 %\n",
      "\n",
      "default\n",
      "Accuracy: 89.867 %\n",
      "\n",
      "\n",
      "RF\n",
      "\n",
      "without headers, footers, shuffled 90/10\n",
      "Accuracy: 81.326 %\n",
      "\n",
      "without headers, footers, shuffled 80/20\n",
      "Accuracy: 95.915 %\n",
      "\n",
      "with headers, footers, non-shuffled\n",
      "Accuracy: 91.989 %\n",
      "\n",
      "default\n",
      "Accuracy: 89.867 %\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---NEWSGROUPS---\\n')\n",
    "\n",
    "compare_newsgroups = {'KNN':{'without headers, footers, shuffled 90/10':newsgroups[6], \n",
    "                             'without headers, footers, shuffled 80/20':newsgroups_t20[6], \n",
    "                             'with headers, footers, non-shuffled':newsgroups1[6], \n",
    "                             'default':newsgroups2[6]}, \n",
    "                      'MNB':{'without headers, footers, shuffled 90/10':newsgroups[7], \n",
    "                             'without headers, footers, shuffled 80/20':newsgroups_t20[7], \n",
    "                             'with headers, footers, non-shuffled':newsgroups1[7], \n",
    "                             'default':newsgroups2[7]}, \n",
    "                      'RF':{'without headers, footers, shuffled 90/10':newsgroups[12], \n",
    "                             'without headers, footers, shuffled 80/20':newsgroups_t20[12], \n",
    "                             'with headers, footers, non-shuffled':newsgroups1[12], \n",
    "                             'default':newsgroups2[7]}}\n",
    "\n",
    "do_comparisons(compare_newsgroups, dataset='newsgroups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---REUTERS---\n",
      "\n",
      "KNN\n",
      "\n",
      "with NaN, 90/10\n",
      "Accuracy: 58.851 %\n",
      "\n",
      "with NaN 80/20\n",
      "Accuracy: 64.69 %\n",
      "\n",
      "without NaN\n",
      "Accuracy: 28.128 %\n",
      "\n",
      "cleaned catgeroies A\n",
      "Accuracy: 27.525 %\n",
      "\n",
      "cleaned categories B\n",
      "Accuracy: 27.804 %\n",
      "\n",
      "\n",
      "MNB\n",
      "\n",
      "with NaN, 90/10\n",
      "Accuracy: 60.009 %\n",
      "\n",
      "with NaN 80/20\n",
      "Accuracy: 60.751 %\n",
      "\n",
      "without NaN\n",
      "Accuracy: 33.781 %\n",
      "\n",
      "cleaned catgeroies A\n",
      "Accuracy: 33.874 %\n",
      "\n",
      "cleaned categories B\n",
      "Accuracy: 33.828 %\n",
      "\n",
      "\n",
      "RF\n",
      "\n",
      "with NaN, 90/10\n",
      "Accuracy: 74.699 %\n",
      "\n",
      "with NaN 80/20\n",
      "Accuracy: 91.891 %\n",
      "\n",
      "without NaN\n",
      "Accuracy: 47.59 %\n",
      "\n",
      "cleaned catgeroies A\n",
      "Accuracy: 46.664 %\n",
      "\n",
      "cleaned categories B\n",
      "Accuracy: 45.227 %\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---REUTERS---\\n')\n",
    "\n",
    "compare_reuters = {'KNN':{'with NaN, 90/10':reuters[6], \n",
    "                         'with NaN 80/20':reuters_t20[6], \n",
    "                         'without NaN':alt_reuters[6], \n",
    "                         'cleaned catgeroies A':alt_reuters_a[6], \n",
    "                         'cleaned categories B':alt_reuters_b[6]}, \n",
    "                  'MNB':{'with NaN, 90/10':reuters[7], \n",
    "                         'with NaN 80/20':reuters_t20[7], \n",
    "                         'without NaN':alt_reuters[7], \n",
    "                         'cleaned catgeroies A':alt_reuters_a[7], \n",
    "                         'cleaned categories B':alt_reuters_b[7]}, \n",
    "                  'RF':{'with NaN, 90/10':reuters[12], \n",
    "                         'with NaN 80/20':reuters_t20[12], \n",
    "                         'without NaN':alt_reuters[12], \n",
    "                         'cleaned catgeroies A':alt_reuters_a[12], \n",
    "                         'cleaned categories B':alt_reuters_b[12]}}\n",
    "\n",
    "do_comparisons(compare_reuters, dataset='reuters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Detailed metrics: NEWSGROUPS\n",
    "\n",
    "Only for those, which achieved highest accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 KNN with headers, footers, non-shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.88        73\n",
      "           1       0.65      0.72      0.68       102\n",
      "           2       0.59      0.74      0.66       103\n",
      "           3       0.67      0.73      0.70       101\n",
      "           4       0.74      0.72      0.73       104\n",
      "           5       0.85      0.64      0.73       108\n",
      "           6       0.73      0.53      0.61       110\n",
      "           7       0.78      0.87      0.82        92\n",
      "           8       0.89      0.82      0.85       106\n",
      "           9       0.88      0.92      0.90       101\n",
      "          10       0.85      0.93      0.89       107\n",
      "          11       0.88      0.97      0.92        96\n",
      "          12       0.78      0.76      0.77        84\n",
      "          13       0.93      0.80      0.86       100\n",
      "          14       0.86      0.93      0.90        92\n",
      "          15       0.93      0.82      0.87        91\n",
      "          16       0.88      0.89      0.88        88\n",
      "          17       0.92      0.94      0.93        99\n",
      "          18       0.80      0.78      0.79        76\n",
      "          19       0.86      0.73      0.79        52\n",
      "\n",
      "    accuracy                           0.81      1885\n",
      "   macro avg       0.81      0.81      0.81      1885\n",
      "weighted avg       0.81      0.81      0.81      1885\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(newsgroups1[0])\n",
    "do_metrics(newsgroups1[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 MNB with headers, footers, non-shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91        73\n",
      "           1       0.86      0.81      0.83       102\n",
      "           2       0.84      0.84      0.84       103\n",
      "           3       0.79      0.84      0.81       101\n",
      "           4       0.94      0.91      0.93       104\n",
      "           5       0.95      0.88      0.91       108\n",
      "           6       0.92      0.83      0.87       110\n",
      "           7       0.89      0.95      0.92        92\n",
      "           8       0.99      0.96      0.98       106\n",
      "           9       0.97      0.98      0.98       101\n",
      "          10       0.91      1.00      0.95       107\n",
      "          11       0.86      0.99      0.92        96\n",
      "          12       0.91      0.87      0.89        84\n",
      "          13       0.98      0.90      0.94       100\n",
      "          14       0.89      0.98      0.93        92\n",
      "          15       0.71      0.96      0.82        91\n",
      "          16       0.80      0.94      0.86        88\n",
      "          17       0.92      0.98      0.95        99\n",
      "          18       0.94      0.66      0.78        76\n",
      "          19       0.94      0.33      0.49        52\n",
      "\n",
      "    accuracy                           0.89      1885\n",
      "   macro avg       0.90      0.87      0.88      1885\n",
      "weighted avg       0.90      0.89      0.89      1885\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(newsgroups1[2])\n",
    "do_metrics(newsgroups1[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 Random Forest without headers, footers, shuffled 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81       157\n",
      "           1       0.63      0.79      0.70       173\n",
      "           2       0.70      0.84      0.77       198\n",
      "           3       0.78      0.68      0.73       228\n",
      "           4       0.81      0.85      0.83       185\n",
      "           5       0.82      0.76      0.79       191\n",
      "           6       0.61      0.86      0.71       184\n",
      "           7       0.87      0.80      0.84       212\n",
      "           8       0.88      0.85      0.87       179\n",
      "           9       0.87      0.92      0.89       201\n",
      "          10       0.89      0.95      0.92       218\n",
      "          11       0.94      0.85      0.89       203\n",
      "          12       0.82      0.64      0.72       195\n",
      "          13       0.89      0.84      0.86       193\n",
      "          14       0.86      0.87      0.86       178\n",
      "          15       0.76      0.92      0.83       209\n",
      "          16       0.80      0.83      0.82       200\n",
      "          17       0.91      0.94      0.93       188\n",
      "          18       0.90      0.62      0.74       146\n",
      "          19       0.81      0.38      0.52       132\n",
      "\n",
      "    accuracy                           0.81      3770\n",
      "   macro avg       0.82      0.80      0.80      3770\n",
      "weighted avg       0.82      0.81      0.81      3770\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(newsgroups_t20[10])\n",
    "do_metrics(newsgroups_t20[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Detailed metrics: REUTERS\n",
    "\n",
    "Only for those, which achieved highest accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 KNN with NaN 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "                      0.59      0.87      0.70      2120\n",
      "           wool       0.26      0.21      0.23       469\n",
      "          trade       0.00      0.00      0.00        13\n",
      "          sugar       0.00      0.00      0.00         1\n",
      "           heat       0.50      0.09      0.15        11\n",
      "         lumber       0.00      0.00      0.00         9\n",
      "     iron-steel       1.00      0.25      0.40        12\n",
      "         nickel       0.67      0.07      0.13        27\n",
      "          crude       1.00      0.11      0.20        18\n",
      "        housing       0.00      0.00      0.00         1\n",
      "            tea       1.00      0.17      0.29         6\n",
      "            ipi       0.83      0.29      0.43        17\n",
      "         silver       0.00      0.00      0.00         2\n",
      "            stg       0.30      0.18      0.22       112\n",
      "          grain       0.00      0.00      0.00         1\n",
      "         income       0.00      0.00      0.00         9\n",
      "      meal-feed       0.92      0.67      0.78       768\n",
      "      livestock       1.00      0.50      0.67         4\n",
      "            tin       0.00      0.00      0.00         3\n",
      "            gas       0.00      0.00      0.00        18\n",
      "           zinc       0.00      0.00      0.00        17\n",
      "           corn       0.83      0.20      0.33        98\n",
      "           gold       1.00      0.67      0.80         3\n",
      "        carcass       0.00      0.00      0.00         1\n",
      "        plywood       0.67      0.50      0.57         4\n",
      "       money-fx       1.00      0.25      0.40         4\n",
      "        veg-oil       0.00      0.00      0.00         3\n",
      "          wheat       0.20      0.10      0.13        70\n",
      "         coffee       0.00      0.00      0.00         1\n",
      "         orange       1.00      0.22      0.36         9\n",
      "            cpu       0.00      0.00      0.00        11\n",
      "            dlr       0.00      0.00      0.00         0\n",
      "            wpi       0.00      0.00      0.00         8\n",
      "           ship       0.00      0.00      0.00         1\n",
      "        cruzado       1.00      0.50      0.67         6\n",
      "         retail       0.00      0.00      0.00         2\n",
      "            gnp       0.00      0.00      0.00         7\n",
      "        nat-gas       0.00      0.00      0.00         5\n",
      "       reserves       0.00      0.00      0.00         3\n",
      "       l-cattle       0.78      0.25      0.38       122\n",
      "            cpi       0.67      0.26      0.37        31\n",
      "             hk       0.00      0.00      0.00        10\n",
      "            yen       0.00      0.00      0.00         1\n",
      "         copper       1.00      0.18      0.30        17\n",
      "         barley       0.00      0.00      0.00         4\n",
      "         cotton       0.00      0.00      0.00         1\n",
      "           jobs       0.00      0.00      0.00         5\n",
      "            bop       0.00      0.00      0.00         1\n",
      "       pet-chem       0.00      0.00      0.00         1\n",
      "           alum       0.00      0.00      0.00         2\n",
      "       platinum       1.00      0.14      0.25        14\n",
      "          cocoa       0.00      0.00      0.00         3\n",
      "         potato       1.00      0.11      0.20         9\n",
      "         rubber       0.67      0.07      0.12        30\n",
      "           fuel       0.00      0.00      0.00         6\n",
      "    inventories       0.00      0.00      0.00         3\n",
      "            lei       0.00      0.00      0.00         3\n",
      "           lead       0.88      0.19      0.32        36\n",
      "   money-supply       0.00      0.00      0.00         1\n",
      "strategic-metal       1.00      0.14      0.25         7\n",
      "        oilseed       0.43      0.03      0.06        92\n",
      "       interest       1.00      0.11      0.19        19\n",
      "       palm-oil       0.00      0.00      0.00         5\n",
      "            acq       0.00      0.00      0.00         1\n",
      "            hog       1.00      0.11      0.20         9\n",
      "           earn       0.00      0.00      0.00         2\n",
      "          ERROR       0.00      0.00      0.00         7\n",
      "\n",
      "       accuracy                           0.60      4316\n",
      "      macro avg       0.35      0.11      0.15      4316\n",
      "   weighted avg       0.60      0.60      0.56      4316\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(reuters_t20[0])\n",
    "do_metrics(reuters_t20[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 MNB default dataset, 90/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "                      0.55      0.97      0.70      1037\n",
      "            acq       1.00      0.04      0.07       227\n",
      "           alum       0.00      0.00      0.00         7\n",
      "            bop       0.00      0.00      0.00         6\n",
      "        carcass       0.00      0.00      0.00         5\n",
      "          cocoa       0.00      0.00      0.00         6\n",
      "         coffee       0.00      0.00      0.00        11\n",
      "         copper       0.00      0.00      0.00         8\n",
      "           corn       0.00      0.00      0.00         4\n",
      "         cotton       0.00      0.00      0.00         2\n",
      "            cpi       0.00      0.00      0.00         9\n",
      "          crude       1.00      0.02      0.04        55\n",
      "            dlr       0.00      0.00      0.00        13\n",
      "           earn       0.90      0.76      0.83       364\n",
      "            gas       0.00      0.00      0.00         2\n",
      "            gnp       0.00      0.00      0.00        14\n",
      "           gold       0.00      0.00      0.00        15\n",
      "          grain       0.00      0.00      0.00        52\n",
      "           heat       0.00      0.00      0.00         1\n",
      "            hog       0.00      0.00      0.00         2\n",
      "        housing       0.00      0.00      0.00         4\n",
      "         income       0.00      0.00      0.00         2\n",
      "    instal-debt       0.00      0.00      0.00         1\n",
      "       interest       0.00      0.00      0.00        41\n",
      "            ipi       0.00      0.00      0.00         6\n",
      "     iron-steel       0.00      0.00      0.00         7\n",
      "           jobs       0.00      0.00      0.00         6\n",
      "           lead       0.00      0.00      0.00         1\n",
      "      livestock       0.00      0.00      0.00        10\n",
      "         lumber       0.00      0.00      0.00         3\n",
      "      meal-feed       0.00      0.00      0.00         3\n",
      "       money-fx       0.00      0.00      0.00        82\n",
      "   money-supply       0.00      0.00      0.00        17\n",
      "        nat-gas       0.00      0.00      0.00         8\n",
      "         nickel       0.00      0.00      0.00         1\n",
      "        oilseed       0.00      0.00      0.00         7\n",
      "         orange       0.00      0.00      0.00         3\n",
      "       pet-chem       0.00      0.00      0.00         5\n",
      "       platinum       0.00      0.00      0.00         1\n",
      "         potato       0.00      0.00      0.00         1\n",
      "        propane       0.00      0.00      0.00         1\n",
      "       reserves       0.00      0.00      0.00         4\n",
      "         retail       0.00      0.00      0.00         2\n",
      "         rubber       0.00      0.00      0.00         3\n",
      "           ship       0.00      0.00      0.00        16\n",
      "         silver       0.00      0.00      0.00         1\n",
      "        soybean       0.00      0.00      0.00         1\n",
      "strategic-metal       0.00      0.00      0.00         1\n",
      "          sugar       0.00      0.00      0.00        11\n",
      "            tea       0.00      0.00      0.00         1\n",
      "            tin       0.00      0.00      0.00         3\n",
      "          trade       0.00      0.00      0.00        49\n",
      "        veg-oil       0.00      0.00      0.00        10\n",
      "          wheat       0.00      0.00      0.00         2\n",
      "            wpi       0.00      0.00      0.00         2\n",
      "            yen       0.00      0.00      0.00         1\n",
      "           zinc       0.00      0.00      0.00         1\n",
      "\n",
      "       accuracy                           0.60      2158\n",
      "      macro avg       0.06      0.03      0.03      2158\n",
      "   weighted avg       0.55      0.60      0.48      2158\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlsAAAIMCAYAAADCTmk+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA7pUlEQVR4nO3dfZhkdX3n/fdnmHGGySiPAYyQ4BNx45qFgMbsJkokPgWj7mWI3mQXjMZZvRIfsrtBcnPvEvYOCYhGXVdzp4MgaqJBdBXFsCIKbuIGaBQFxYeoKBMZFEWRDAMM873/qJrYTnfXqaqu01Vd9X55naurz+nz+33rex3K7/zOr34nVYUkSZLasW7cAUiSJE0ziy1JkqQWWWxJkiS1yGJLkiSpRRZbkiRJLbLYkiRJapHFliRJmmlJLkjyrSQ3Ldh3YJIrkny5+/OABcf+IMk/JPlikqc3tW+xJUmSZt3bgGfste904MqqejRwZfd3kvwM8ALgsd1z3pJkn16NW2xJkqSZVlWfAL671+7nABd1X18EPHfB/ndX1b1V9TXgH4An9GrfYkuSJGmxQ6vqNoDuz0O6+x8G3Lrg77Z19y1rfSvhLbDvMb/b83lA93z6f7BzV9tRjMam9axKrKvVTz8++Q/f6Xn8KY85aOZy0mQWr5Mm05YTcz++fkbBnCy2aT0ZV99NdcJK7bzhzf8B2Lpg11xVza2gyaVy1fM9tF5sSZIkjUu3sBqmuLo9yUOr6rYkDwW+1d2/DThiwd8dDnyzV0ONxVaSx9C5P/kwOpXbN4FLq+rmIQKXJEn6oUzsjKZLgVOBc7o/P7Bg/18l+VPgJ4BHA9f2aqjnO0zyauDddIbMrgWu675+V5LTV/AGJEmSJkKSdwH/B/jpJNuSvJhOkfXUJF8Gntr9nar6HHAx8HngcuB3quqBXu03jWy9GHhsVd2/V1B/CnxuT8dLBL2V7v3R9Ycfz/qDH9vQjSRJmkkZ23Sxf1ZV/9cyh05Y5u/PBs7ut/2msbvddIbI9vbQ7rElVdVcVR1XVcdZaEmSpFnWNLL1KuDK7hDanq85/iTwKOB3W4xLkiTNgsmdszUyPYutqro8yVF0Fut6GJ35WtuA65ruT0qSJKmPbyNW1W7g79sM4ns77u95fP/NG9rsXj3860cdNO4QJEnTbALmbLVt+sfuJEmSxshFTSVJ0vjMwJyt6X+HkiRJY+TIliRJGp8ZmLNlsSVJksbH24iSJElaCUe2JEnS+HgbceW+8Yk3NP6N62hJkqRp5ciWJEkaH+dsSZIkaSUai60kj0lyQpIte+1/RnthSZKkmZC0u02AnsVWklcAHwBeDtyU5DkLDv9xm4FJkiRNg6aRrZcAx1bVc4Hjgf+S5JXdY8uWi0m2JplPMv/2C/9iJIFKkqQplHXtbhOgaYL8PlV1N0BV3ZLkeOCSJD9Fj2KrquaAOYBv/2BXjSZUSZKktaep5Nue5Og9v3QLr2cBBwOPazEuSZI0C2Z9zhZwCrB94Y6q2lVVpwBPai0qSZKkKdHzNmJVbetx7O/66WBCikpJkjSJJmReVZum/x1KkiSNkSvIS5Kk8XFkS5IkSSvhyJYkSRqfddM/uduRLUmSpBY5siVJksbHOVuSJElaidZHtg7e0tzFpjU0vrZasZqT8fUzCuZksWnLibkfXz+jYE4myAwsyNn6ZXDnjgd6Hj9g8z7s3NV2FKOxaT2rEutq9TMK5mQxc7LYtOXE3I+vn1EwJ4uNtSj0NqIkSZJWYuBiK8nb2whEkiTNoBl4EHXPgcMkl+69C/jlJPsDVNWzW4pLkiRpKjTdpT0c+DxwPlB0iq3jgNf1OinJVmArwJ++6c944YtesvJIJUnS9JmBOVtNxdZxwCuBM4Dfr6obktxTVVf3Oqmq5oA5gDt3PFAjiVSSJGkN6llsVdVu4PVJ3tP9eXvTOZIkSX2bkHlVbeqrcKqqbcBJSU4E7mo3JEmSpOkx0ChVVV0GXDbIOQ/s9i6iJElaxgzM2Zr+dyhJkjRGzr+SJEnjMwNzthzZkiRJapEjW5IkaXycsyVJkqSVcGRLkiSNj3O2JEmStBKObEmSpPGZgTlbrRdbO+57YNwhSJIkjY2VjiRJGp8ZGNnq+Q6T/HySh3Rf75vkrCQfTHJukv1WJ0RJkqS1q6mcvADY0X39RmA/4NzuvgtbjEuSJM2CpN1tAjQVW+uqalf39XFV9aqq+tuqOgt4xHInJdmaZD7J/F9ddP7IgpUkSVMm69rdJkDTnK2bkvxWVV0IfCbJcVU1n+Qo4P7lTqqqOWAO4BvfvbdGF64kSdLa0lRs/TbwxiT/D3AH8H+S3Arc2j0mSZI0vAm51demnsVWVX0feGGSB9O5bbge2FZVt69GcJIkSWtdX0s/VNUPgM8M08FPHrix8W82raEFKFYrVnMyvn5GwZwsNm05Mffj62cUzMkEmZB5VW1q/TLYfteyU7sAOOwhG9i5q+efTIxN61mVWFern1EwJ4uZk8WmLSfmfnz9jII5WcyisF2mV5Ikjc8MzNma/rE7SZKkMXJkS5IkjU0c2ZIkSdJKOLIlSZLGxpEtSZIkrYgjW5IkaXymf2Cr/WJr0wYHzyRJ0uxyZEuSJI2Nc7YkSZK0Ij1HtpI8CHgB8M2q+miSk4F/DdwMzFVV72fxSJIk9TALI1tNtxEv7P7N5iSnAluA9wEnAE8ATm03PEmSpLWtqdh6XFX9bJL1wD8CP1FVDyR5J/CZ5U5KshXYCvD6N/0ZL3zxS0YWsCRJmh6ObMG67q3EHwM2A/sB3wU2AhuWO6mq5oA5gO/d80CNJlRJkqS1p6nYeivwBWAf4AzgPUm+CjwReHfLsUmSpCk38yNbVfX6JH/dff3NJG8HfgX4i6q6tq8O1vmFR0mSNLsa19mqqm8ueP094JI2A5IkSTNk+ge2XNRUkiSNzyzcRvQenyRJUosc2ZIkSWPjyJYkSZJWxJEtSZI0No5sSZIkaUUc2ZIkSWMzCyNbrRdbd91zf8/jWzY+qO0QJEmSxsaRLUmSND7TP7DlnC1JkqQ2ObIlSZLGZhbmbDmyJUmS1KKexVaS/ZKck+QLSb7T3W7u7tu/x3lbk8wnmX/n284fedCSJGk6JGl1mwRNtxEvBj4GHF9V2wGSHAacCrwHeOpSJ1XVHDAH8M3v3Vcji1aSJGmNaSq2jqyqcxfu6BZd5yZ5UXthSZKkWTApo09taiq2vp7kNOCiqrodIMmhwAuBW/vp4Cf2b15Ha9Mamqa/WrGak/H1MwrmZLFpy4m5H18/o2BOtJqaLoPnA6cDVyc5pLvvduBS4KR+Ojjlrz7b8/jbT/5Zdu7qp6Xx27SeVYl1FP3srua7t+tG8K+JtZST1WJOFpu2nJj78fUzCuZksbEWhRMwsJXk94DfBgq4EfgtYDPw18CRwC3Ab1TVncO033OCfFXdWVWvrqrHVNWB3e1fVNWrgecO06EkSdKkSPIw4BXAcVX1L4F9gBfQGWy6sqoeDVzZ/X0oK1n64awVnCtJkjQp30ZcD+ybZD2dEa1vAs8BLuoev4gVDDL1HDhMstw9wACHDtupJEnSakiyFdi6YNdcd9UEAKrqH5O8FvgGcA/wkar6SJJDq+q27t/ctmA61cCa7tIeCjwd2PseZYBPDtupJEkStP9txIXLUS3T/wF0RrEeDnwPeE+SfzfKGJqKrQ8BW6rqhiWCu2qUgUiSpNkzAUs//Arwtar6NkCS9wH/Grg9yUO7o1oPBb41bAdNE+RfXFV/u8yxk4ftVJIkaUJ8A3hiks3pVH4nADfTWXnh1O7fnAp8YNgOXAFEkiSNzbhHtqrqmiSXAJ8CdgGfpnPbcQtwcZIX0ynI+lryaimtF1t/+NSj2u5CSxjFGlqSJM2CqjoTOHOv3ffSGeVaMUe2JEnS+MzA2MBK1tmSJElSA0e2JEnS2Ix7ztZqcGRLkiSpRT2LrSQPSfInSd6R5OS9jr2lx3lbk8wnmX/X2986qlglSdKUmZDH9bSq6TbihcCXgfcCL0ryPODkqroXeOJyJy1crfWr395ZI4pVkiRpzWkqth5ZVc/rvn5/kjOAjyV5dstxSZKkGTApo09taiq2NiZZV1W7Aarq7CTbgE/QWexLkiRJPTQVWx8EngJ8dM+Oqrooye3Am/rp4F++9K96Ht/x3hf104zG5IDH/27P4/d8+n+sUiSSpKk0/QNbvYutqjptmf2XJ/njdkKSJEmaHitZ+uGskUUhSZJm0sx/GzHJZ5c7BBw6+nAkSZKmS9OcrUOBpwN37rU/wCdbiUiSJM2MSRl9alNTsfUhYEtV3bD3gSRXtRGQJEnSNGmaIP/iHsdOXu6YJElSP2ZhZMtnI0qSJLUoVa0/TcfH9UiSNNnGNrz08Fdd1mqd8LU3nDj2obOmOVsrdve9vXO4ZWPYuavtKEZj03pWJdbV6mcUzMli5mSxacuJuR9fP6NgThbb1Ho10MPYS6H2eRtRkiSpReOsZSVJ0oxzgvwSkhzSRiCSJEnTqGexleTAvbaDgGuTHJDkwB7nbU0yn2T+gvPnRh60JEmaDjP/uB7gDuDre+17GPApOt8yfMRSJ1XVHDAHcPe97X/dUZIkaVI1FVunAb8C/H5V3QiQ5GtV9fDWI5MkSVNvQgafWtXzNmJVvRb4beC/JvnTJA/GdbMkSZL61vhtxKraBpyU5NeAK4DNg3Rw+/d39jy+5ZB9B2lOkiRNkUmZV9Wmvr+NWFUfBH6Zzm1FkvxWW0FJkiRNi4GWfqiqe6rqpu6vZ7UQjyRJmiFJu9sk6HkbMclnlzsEHDr6cCRJkqZL05ytQ4GnA3futT/AJ1uJSJIkzYxZmLPVVGx9CNhSVTfsfSDJVW0EJEmSNE16FltV9eIex04efTiSJGmWzMDA1uDPRpQkSVL/GtfZWqkHfFqPJElaxrp10z+05ciWJElSi1of2ZIkSVqOc7YkSZK0Io5sSZKksZmFdbYGHtlKclAff7M1yXyS+b9+xwXDRSZJkqaej+tJzgFeW1V3JDkOuBjYnWQDcEpVXb3UeVU1B8wBfOn2HX4dUZIkzaymka0Tq+qO7uvzgOdX1aOApwKvazUySZI09ZK0uk2CpmJrQ5I9o1/7VtV1AFX1JWBjq5FJkiRNgaYJ8m8GPty9nXh5kjcA7wNOAG7op4PX/+0tPY//2fN+pp9mNCa7GxelnYx/NUiS1qZJGX1qU9OzEd+U5EbgZcBR3b8/Cng/8P+2Hp0kSdIa17j0Q1VdBVy19/4kvwVcOPqQJEnSrJiBga0VLWp61siikCRJmlJNSz98drlDwKGjD0eSJM2SmZ+zRaegejpw5177A3yylYgkSZKmSFOx9SFgS1XdsPeBJFe1EZAkSZodMzCw1fhtxBf3OHby6MORJEmaLj6IWpIkjY1ztkagn0VLN62hkm+1Yp2cnDT/RzB7OWlmThabtpyY+/H1MwrmRKup9ctgx/29VyDfvCHs3NV2FKOxaT2rEutq9TMK5mQxc7LYtOXE3I+vn1EwJ4uNsyicgYGtFa2zJUmSpAYOcEqSpLGZhTlbrYxsJdmaZD7J/AXnz7XRhSRJ0prQtIL8ccB5wD8CfwBcADwB+BKwtao+vdR5VTUHzAHsuL96T9qSJEkzawYGthpHtt4CvAa4jM6K8X9eVfsBp3ePSZIkqYemYmtDVf1NVb0LqKq6hM6LK4FNrUcnSZKmWpJWt0nQNEF+Z5KnAfsBleS5VfX+JE8GHuing927VxqiJEnS2tVUbL2Uzm3E3XQeSP2yJG+jM4frJe2GJkmSpt2EDD61qunZiJ+hU2Tt8cruRpLfojOPS5IkaSiTcquvTStZ+uGskUUhSZI0pZqWfvjscoeAQ0cfjiRJmiUzMLDVOGfrUDq3Ee/ca3/wFqIkSVKjpmLrQ8CWqrph7wNJrmojIEmSNDtmYc5W0wT5F/c4dvLow5EkSZouPohakiSNzQwMbLVfbO1qXNV0n7ZDkCRJGhtHtiRJ0tjMwpytlayzJUmSpAaObEmSpLGZ+ZGtJPslOSfJF5J8p7vd3N23/yrFKEmStGY13Ua8mM6CpsdX1UFVdRDwy91971nupCRbk8wnmX/bW/9idNFKkqSpkrS7TYKm24hHVtW5C3dU1Xbg3CQvWu6kqpoD5gC+d88DteIoJUmS1qimka2vJzktyT8/BzHJoUleDdzabmiSJGnaJWl1mwRNI1vPB04Hru4WXAXcDlwK/EY/Hey/b/M6WpvW0DT91YrVnIyvn1EwJ4tNW07M/fj6GQVzotXU9LieO5NcCFwB/H1V3b3nWJJnAJc3dXD3vb3vIm7ZGHbu6i/Ycdu0nlWJdbX6GQVzspg5WWzacmLux9fPKJiTxcZZFE7I4FOrmr6N+ArgA8DvAjclec6Cw3/cZmCSJEnToKmWfQlwbFXdneRI4JIkR1bVG4EZqEUlSVKbJmVeVZuaiq199tw6rKpbkhxPp+D6KSy2JEmSGjV9G3F7kqP3/NItvJ4FHAw8rsW4JEnSDHCdLTgF+JHpfVW1CzglyZ+3FpUkSZoJ6yalImpR07cRt/U49nejD0eSJGm6uAKIJEkamxkY2Gq/2FrXNCtMkiRpijmyJUmSxmYWln5w3EmSJKlFjmxJkqSxWTf9A1uNj+t5SJI/SfKOJCfvdewt7YYmSZLUviT7J7kkyReS3JzkF5IcmOSKJF/u/jxg2PabbiNeSGel+PcCL0jy3iQbu8ee2CPorUnmk8xfcP7csLFJkqQpl6TVrU9vBC6vqscA/wq4GTgduLKqHg1c2f19KE23ER9ZVc/rvn5/kjOAjyV5dq+TqmoOmAPYcX/VsMFJkiS1KclDgCcBLwSoqvuA+5I8Bzi++2cXAVcBrx6mj6Zia2OSdVW1uxvA2Um2AZ8AtgzToSRJ0h5tfxkxyVZg64Jdc91BoT0eAXwbuDDJvwKuB14JHFpVtwFU1W1JDhk2hqZi64PAU4CP7tlRVRcluR14Uz8dnH/NLT2Pv+IXH95PM5IkSQNbeLdtGeuBnwNeXlXXJHkjK7hluJSec7aq6jRgW5ITkmxZsP9y4BWjDESSJM2etPy/PmwDtlXVNd3fL6FTfN2e5KEA3Z/fGvY9Nn0b8eXAB4CXAzd171/ucfawnUqSJE2CqtoO3Jrkp7u7TgA+D1wKnNrddyqdemgoTbcRtwLHVtXdSY4ELklyZFW9EforFyVJkpYzIetsvRz4yyQPAr4K/BadAamLk7wY+AZw0rCNNxVb+1TV3QBVdUuS4+kUXD+FxZYkSZoCVXUDcNwSh04YRftN62xtT3L0gmDuBp4FHAw8bhQBSJKk2TUh62y1qqnYOgXYvnBHVe2qqlPorEkhSZKkHnreRqyqbT2O/d3ow5EkSbNkQgafWtU0siVJkqQVaJogv2InH31E211IkqQ1at0MDG21XmxJkiQtZwZqLW8jSpIktWngka0kh1TV0EvWS5Ik7TEpyzO0qWexleTAvXcB1yY5BkhVfbe1yCRJkqZA023EO4DrF2zzwMOAT3VfLynJ1iTzSebffsFfjCpWSZI0ZZJ2t0nQdBvxNOBXgN+vqhsBknytqh7e66SqmgPmAO64e1eNIlBJkqS1qGlR09cmeTfw+iS3AmcCFk+SJGkkZmHph8ZvI1bVtqo6Cfg4cAWwufWoJEmSpkTjtxGTPIbOPK2PAx8FHtnd/4yqurzp/IO3NH/hcdMaWu1rtWI1J+PrZxTMyWLTlhNzP75+RsGcTI7pH9dq/jbiK4DfAW4G3gq8sqo+0D38x0BjsfXtH+zqefzHH7yenb3/ZGJsWs+qxLpa/YyCOVnMnCw2bTkx9+PrZxTMyWIWhe1qSu9LgGOr6u4kRwKXJDmyqt7IbBSjkiSpRTO/zhawT1XdDVBVtyQ5nk7B9VNYbEmSJDVqmiC/PcnRe37pFl7PAg4GHtdiXJIkaQasS7vbJGgqtk4Bti/cUVW7quoU4EmtRSVJkjQlmtbZ2tbj2N+NPhxJkjRLZmHOVuM6W5IkSRpe61/2nIGCVZIkDWkW6gRHtiRJklrkMmaSJGlsnLO1hCQHtRGIJEnSNOpZbCU5J8nB3dfHJfkqcE2Sryd58qpEKEmSppbrbMGJVXVH9/V5wPOr6lHAU4HXLXdSkq1J5pPMv/2CvxhRqJIkadokaXWbBE1ztjYkWV9Vu4B9q+o6gKr6UpKNy51UVXPAHMAdd++qkUUrSZK0xjQVW28GPpzkHODyJG8A3gecANzQbmiSJGnaTcbYU7uaVpB/U5IbgZcBR3X//ijg/cAftR6dJEnSGtfP0g/b6dwSvKb7IGoAkjwDuLzp5M0b9xk+OkmSNNXWTci8qjY1fRvxFcAHgJcDNyV5zoLDf9xmYJIkSdOgaWTrJcCxVXV3kiOBS5IcWVVvZDZus0qSpBbNwMBWY7G1z55bh1V1S5Lj6RRcP4XFliRJUqOmdba2Jzl6zy/dwutZwMHA41qMS5IkzYBZWGerqdg6hc4E+X9WVbuq6hTgSa1FJUmSNCWaln7Y1uPY340+HEmSNEsmZPCpVQM/iFqSJEn962edrRXZvKG5ZN3UehSjs1qxmpPx9TMK5mSxacuJuR9fP6NgTibHLKyz1fplsO3O+3oeP/yAB7FzV9tRjMam9axKrKvVzyiYk8XMyWLTlhNzP75+RsGcLGZR2C7TK0mSxmYGBracsyVJktQmR7YkSdLYTMpaWG1qejbicUk+nuSdSY5IckWS7ye5LskxPc7bmmQ+yfxfvu380UctSZK0RjSNbL0FOBPYH/gk8HtV9dQkJ3SP/cJSJ1XVHDAHsO3O+2pk0UqSpKkyC/OZmt7jhqr6m6p6F1BVdQmdF1cCm1qPTpIkaY1rGtnameRpwH5AJXluVb0/yZOBB9oPT5IkTbNZmLPVVGy9FHgNsBt4OvCyJG8D/hF4ST8d7Levc/AlSdLsano24meSvAr4CWBbVb0SeCVAkme0H54kSZpm66Z/YKvx24ivAP4n8HLgpiTPWXD4j9sMTJIkTb91aXebBE33+F4CHFdVdyc5ErgkyZFV9UZgQt6CJEnS5GoqtvapqrsBquqWJMfTKbh+CostSZK0QrMwQb5p6YftSY7e80u38HoWcDDwuBbjkiRJmgpNI1unAD/yzPKq2gWckuTPW4tKkiTNhEmZV9Wmpm8jbutx7O9GH44kSdJ0cREsSZI0NjMwZWsmHkkkSZI0No5sSZKksVk3A0NbjmxJkiS1yJEtSZI0NrMw6tP0uJ79kpyT5AtJvtPdbu7u27/HeVuTzCeZv/CtcyMPWpIkaa1oGtm6GPgYcHxVbQdIchhwKvAe4KlLnVRVc8AcwA927q6RRStJkqbKDEzZahy9O7Kqzt1TaAFU1faqOhf4yXZDkyRJWvuaRra+nuQ04KKquh0gyaHAC4FbW45NkiRNuVn4NmJTsfV84HTg6m6RVcDtwKXAb/TTwcNfenHP43e87QX9NCNJkrQmNT2u584k7wUuqarrkjwWeAZwc1V9d1UilCRJU2sGBrZ6F1tJzgSeCaxPcgXwBOBq4PQkx1TV2asQoyRJ0prVdBvx14GjgY3AduDwqroryXnANYDFliRJGtq6GRjZavo24q6qeqCqdgBfqaq7AKrqHmB369FJkiStcU0jW/cl2dwtto7dszPJflhsSZKkFfLbiPCkqroXoKoWFlcb6CxsKkmSNLQZqLUav4147zL77wDuaCUiSZKkKeKDqCVJ0tjMwgT51outfhYt3bSGSr7VitWcjK+fUTAni01bTsz9+PoZBXOi1dT6ZfDF7Tt6Hv/pwzazc1fbUYzGpvWsSqyr1U8/dlfv54hv3pCZy0mTWbxOmkxbTsz9+PoZBXOy2DiLwjD9Q1tNSz9IkiRpBRzglCRJYzMLc7Z6jmwleUiSP0nyjiQn73XsLe2GJkmStPY13Ua8EAjwXuAFSd6bZGP32BOXOynJ1iTzSeb/+h0XjChUSZI0bdal3W0SNN1GfGRVPa/7+v1JzgA+luTZvU6qqjlgDuCL23f0nmEtSZI0xZqKrY1J1u1ZPb6qzk6yDfgEsKX16CRJ0lTLDCwh31RsfRB4CvDRPTuq6qIktwNv6qeD/TZvGD46jd0sPLNKkqQ29ZyzVVWnAXcleTxAkp9J8h+BdVX16NUIUJIkTa+Zn7OV5EzgmcD6JFcAPw9cBZye5JiqOrv9ECVJktauptuIvw4cDWwEtgOHV9VdSc4DrgEstiRJ0tBmYbZK09IPu6rqgaraAXylqu4CqKp7gN2tRydJkrTGNY1s3Zdkc7fYOnbPziT7YbElSZJWaBa+iNVUbD2pqu4F2LP8Q9cG4NTWopIkSZoSPYutPYXWEvvvAO5oJSJJkjQzJuUbg21qmrMlSZI09ZLsk+TTST7U/f3AJFck+XL35wHDtt16sfWQfdf33CRJ0uxK2t0G8Erg5gW/nw5c2V1X9Mru70NxZEuSJI3NOtLq1o8khwMnAucv2P0c4KLu64uA5w7/HiVJkqZUkq1J5hdsW5f4szcAp/GjKy0cWlW3AXR/HjJsDAPfx0tySFV9a9gOJUmS9mh75YeqmgPmlu8/zwK+VVXXJzm+jRiaHtdz4N67gGuTHAOkqr7bRlCSJEmr5N8Az07yq8Am4CFJ3gncnuShVXVbkocCQw80Nd1GvAO4fsE2DzwM+FT39ZIWDtldcP6yxaQkSZpx434QdVX9QVUdXlVHAi8APlZV/w64lB+uKXoq8IFh32PTbcTTgF8Bfr+qbgRI8rWqenhD4P88ZLfj/qphg5MkSRqTc4CLk7wY+AZw0rANNS1q+tok7wZen+RW4EzA4kmSJI3EJD2up6quAq7qvv4OcMIo2m2cIF9V24CTkvwacAWweZAONm9oTuKmNbTc1mrFak7G188omJPFpi0n5n58/YyCOdFqarwMkjwBqKr6YJJbgOck+dWq+nA/HXz7B7t6Hv/xB69nZ+8/mRib1rMqsa5WP6NgThYzJ4tNW07M/fj6GQVzstg4i8IJGthqTdO3Ec8EngmsT3IF8ATgauD0JMdU1dmrEKMkSdKa1VTL/jpwNLAR2A4cXlV3JTkPuAaw2JIkSUObpDlbbWla+mFXVT1QVTuAr1TVXQBVdQ8/usqqJEmSltA0snVfks3dYuvYPTuT7IfFliRJWqEZGNhqLLaeVFX3AlTVwuJqAz9c6EuSJEnLaFpn695l9t9BZ3V5SZKkoTXNZ5oGs/AeJUmSxqb1lTU2bbCekyRJS8sMTNqyEpIkSWqRDxKQJEljM/3jWkOMbCU5qI1AJEmSplHPYivJOUkO7r4+LslXgWuSfD3Jk1clQkmSNLXWJa1uk6BpZOvE7jIPAOcBz6+qRwFPBV633ElJtiaZTzJ/4VvnRhSqJEmaNml5mwRNc7Y2JFlfVbuAfavqOoCq+lKSjcudVFVzwBzAD3burpFFK0mStMY0FVtvBj6c5Bzg8iRvAN4HnADc0G5okiRp2k3Inb5WNa0g/6YkNwIvA47q/v1RwPuBP2o9OkmSpDWun6UfdgCvrarrkjwWeAawraru76eDXd5FlCRJy5iFRU17FltJzgSeCaxPcgXwBOBq4PQkx1TV2asQoyRJ0prVNLL168DRwEZgO3B4Vd2V5DzgGsBiS5IkDW0WHmXT9B53VdUDVbUD+EpV3QVQVfcAu1uPTpIkaY1rGtm6L8nmbrF17J6dSfbDYkuSJK3QzM/ZAp5UVfcCVNXC4moDcGprUUmSJE2JpqUf7l1m/x3AHUsdkyRJ6tf0j2vNxrw0SZKkselnna0V2bjBek6SJC1tFuZsWQlJkiS1qPWRLUmSpOXMwqjPLLxHSZKkselZbCU5LsnHk7wzyRFJrkjy/STXJTlmtYKUJEnTKUmr2yRoGtl6C/Aa4DLgk8CfV9V+wOndY0tKsjXJfJL5C86fG1mwkiRJa03TnK0NVfU3AEnOrapLAKrqyiSvXe6kqpoD5gB23F81qmAlSdJ0mYyxp3Y1jWztTPK0JCcBleS5AEmeDDzQdnCSJElrXdPI1kvp3EbcDTwdeFmSC4FvAltbjk2SJE25CZlW1apUw12+JD8P7K6q65I8FngGcHNVfbjPPryNKEnSZBtbyfPBG29vtU74tccdOvZyrufIVpIzgWcC65NcATwBuBo4PckxVXV2Uwc77u+dw80bws5d/Qc8TpvWsyqxrlY/o2BOFjMni01bTsz9+PoZBXOy2CZX3WxVU3p/HTga2AhsBw6vqruSnAdcAzQWW5IkScuZhduITRPkd1XVA1W1A/hKVd0FUFX30JnHJUmSpB6aRrbuS7K5W2wdu2dnkv2w2JIkSSuUGVj8oanYelJV3QtQVQuLqw3Aqa1FJUmSNCV6Flt7Cq0l9t8B3NFKRJIkaWY4Z0uSJEkr4pc9JUnS2KybgTlbjmxJkiS1yJEtSZI0Ns7ZkiRJ0oo4siVJksZm5ke2kuyX5JwkX0jyne52c3ff/j3O25pkPsn8BefPjTxoSZKktaJpZOti4GPA8VW1HSDJYXQWNH0P8NSlTqqqOWAOYMf91erTvCVJ0to1CyvIN83ZOrKqzt1TaAFU1faqOhf4yXZDkyRJWvuaiq2vJzktyaF7diQ5NMmrgVvbDU2SJE27dWl3mwRNxdbzgYOAq5PcmeRO4Kruvt/op4P7du3uuUmSJE2znsVWVd1ZVa+uqsdU1QFVdQAwX1WnVdV3VylGSZI0pdLy/yZBzwnySS5dYvdT9uyvqme3EpUkSdKUaPo24uHA54HzgQICPB54XctxSZKkGTDz62wBxwHXA2cA36+qq4B7qurqqrq67eAkSZLWup4jW1W1G3h9kvd0f97edI4kSVK/JmVeVZv6KpyqahtwUpITgbvaDUmSJM2KSVmeoU0DjVJV1WXAZS3FIkmSNHW8JShJksbG24gjsP+++zT+zaY1VPKtVqzmZHz9jII5WWzacmLux9fPKJgTrabWL4O77+39HOotG8POXW1HMRqb1rMqsa5WP6NgThYzJ4tNW07M/fj6GQVzstg4i0KXfpAkSdKKOMApSZLGZgYGtnqPbCV5SJI/SfKOJCfvdewtPc7bmmQ+yfwF58+NKlZJkqQ1p2lk60Lgy8B7gRcleR5wclXdCzxxuZOqag6YA7j73uo9aUuSJM2sdTMwaatpztYjq+r0qnp/96HTnwI+luSgVYhNkiRpzWsa2dqYZF33sT1U1dlJtgGfALa0Hp0kSZpq0z+u1Tyy9UHgKQt3VNVFwH8C7uung6rquUmSJE2zpgdRn7b3viRvr6pTgEe3FpUkSZoNMzC01bPYSnLp3ruAX06yP0B3HpckSZKW0TRn6wjgc8D5QNEpto4DXtdyXJIkaQbMwrMRm+ZsHQtcD5wBfL+qrgLuqaqrq+rqtoOTJEla65rmbO0GXp/kPd2ftzedI0mS1K8ZWGarv8KpqrYBJyU5Ebir3ZAkSZKmx0CjVFV1GXBZS7FIkqQZMwMDW41ztiRJkrQCrc+/+ub3dvY8/tOHbW47BEmSNKlmYGjLye6SJGlsXPpBkiRJKzLwyFaSQ6rqW20EI0mSZsvML/2Q5MC9dwHXJjkGSFV9t7XIJEmSpkDTbcQ76Kwgv2ebBx4GfKr7eklJtiaZTzL/1++4YFSxSpKkKZOWt0nQdBvxNOBXgN+vqhsBknytqh7e66SqmgPmAL64fUeNIlBJkqS1qOlxPa9N8m46j+q5FTiTzgOpJUmSVm5Shp9a1DhBfsGjep4NXAEMtDDWEQftO2RokiRJa1/f30asqkuTXAG8vcV4JEnSDJmFdbaavo146RK7n7Jnf1U9u5WoJEmSpkTTyNbhwOeB8+nM1QrweOB1LcclSZJmwLjX2UpyBJ27docBu4G5qnpjd/mrvwaOBG4BfqOq7hymj6alH46js+TDGcD3q+oq4J6qurqqrh6mQ0mSpAmyC/hPVfUvgCcCv5PkZ4DTgSur6tHAld3fh9L0bcTddL6J+J7uz9ubzpEkSerXuGdsVdVtwG3d1z9IcjOdNUWfAxzf/bOLgKuAVw/TR1+F04JvJJ4I3DVMR5IkSastyVZg64Jdc931QJf62yOBY4BrgEO7hRhVdVuSQ4aNYaBRqqq6DLhs2M4kSZJ+RMtDWwsXWu8ZRrIFeC/wqqq6KyOcTNY0Z0uSJGmqJdlAp9D6y6p6X3f37Uke2j3+UOBbw7bf+vyrzRuaK8NNa2gW2GrFak7G188omJPFpi0n5n58/YyCOZkc415nK50hrLcCN1fVny44dClwKnBO9+cHhu6jqt2n7+y4v3cHmzeEnbtaDWFkNq1nVWJdrX5GwZwsZk4Wm7acmPvx9TMK5mSxTevHV/F89ta7Wy1EfvaILT3fW5JfBP43cCOdpR8A/m8687YuBn4S+AZwUlV9d5gYrLklSdLYjHudrar6W5afOXbCKPoYeM5WkoNG0bEkSdIs6FlsJTknycHd18cl+SpwTZKvJ3nyqkQoSZKmVlreJkHTyNaJVXVH9/V5wPOr6lHAU+nxyJ4kW5PMJ5m/4PzGb1tKkqRZNQPVVtOcrQ1J1lfVLmDfqroOoKq+lGTjcictXNOiaYK8JEnSNGsqtt4MfDjJOcDlSd4AvI/OhLEb2g1NkiRNu3Ev/bAamp6N+KYkNwEvBY7q/v1RdNaa+KP2w5MkSVrbGpd+qKqPAx/f83uSt1fVn7calSRJmgnjXvphNfQstpJcusTupyTZH6Cqnt1GUJIkSdOiaWTrcODzwPlA0ZnX/3h6fBNRkiSpXzMwsNW49MNxwPXAGcD3q+oq4J6qurqqrm47OEmSpLWuaYL8buD1Sd7T/Xl70zmSJEl9m4Ghrb4Kp6raBpyU5ETgrnZDkiRJmh4DjVJV1WXAZS3FIkmSZswsrLM18IOoJUmS1L/W51/d8YP7eh7/yQOXfeqPJEmacrOwzpYjW5IkSS3ym4WSJGlsZmBgy5EtSZKkNvUstpIcl+TjSd6Z5IgkVyT5fpLrkhyzWkFKkqQplZa3CdA0svUW4DV0lnv4JPDnVbUfcHr32JKSbE0yn2T+ry46f2TBSpIkrTVNc7Y2VNXfACQ5t6ouAaiqK5O8drmTqmoOmAP4xnfvrVEFK0mSpovrbMHOJE9LchJQSZ4LkOTJwANtBydJkrTWNY1svQw4F9gNPB14WZILgW8CW1uOTZIkTblZWGcrVYPd5Uvyjqr69wOc4m1ESZIm29hKnq98655W64RHHrLv2Mu5niNbSS5dYvdT9uyvqmc3dbDj/t453Lwh7NzV1Mpk2LSeVYl1tfoZBXOymDlZbNpyYu7H188omJPFNrnqZqua0nsE8DngfDojVAEeD7yu5bgkSdIsGPu4U/uaJsgfC1wPnAF8v6quAu6pqqur6uq2g5MkSVrreo5sVdVu4PVJ3tP9eXvTOZIkSf2ahaUf+iqcqmobcFKSE4G72g1JkiRpegw0SlVVl9FZTV6SJGnFZmHpBx9ELUmS1KLW51898EDD8hkbZqCklSRJS5qFKsCRLUmSpBb5zUJJkjQ+MzC05ciWJElSi3oWW0n2S3JOki8k+U53u7m7b/9VilGSJE2ptPy/SdA0snUxcCdwfFUdVFUHAb/c3fee5U5KsjXJfJL5C986N7poJUmS1pimOVtHVtW5C3dU1Xbg3CQvWu6kqpoD5gB+sHN3q0/zliRJa5frbMHXk5yW5NA9O5IcmuTVwK3thiZJkrT2NRVbzwcOAq5OcmeS7wJXAQcCv9FybJIkacql5W0SND2I+k7g1d2NJL8EPAG4saq+208H/+V/fann8Tc85zF9BSpJkrQWNX0b8doFr38b+O/AFuDMJKe3HJskSZpySbvbJGi6jbhhwev/ADytqs4Cngb8ZmtRSZIkTYmmbyOuS3IAnaIsVfVtgKr6pyS7Wo9OkiRNuQkZfmpRU7G1H3A9nUxUksOqanuSLcxCdiRJklaoaYL8kcsc2g3825FHI0mSZsqkzKtq01APoq6qHcDXRhyLJEmaMTNQa/kgakmSpDYNNbI1iP/8pEe03YUkSVqjZuE2oiNbkiRJLWp9ZEuSJGk5mYFZW45sSZIktciRLUmSND7TP7DV+GzEhyT5kyTvSHLyXsfe0uO8rUnmk8z/5dvOH1WskiRJa07TyNaFwJeB9wIvSvI84OSquhd44nInVdUcMAew7c77akSxSpKkKTMDA1uNc7YeWVWnV9X7q+rZwKeAjyU5aBVikyRJWvOaRrY2JllXVbsBqursJNuATwBbWo9OkiRNtVlYZ6up2Pog8BTgo3t2VNVFSW4H3tRPB/tv3jB8dJIkSWtc04OoT1v4e5JfBJ4A3FRVj24zMEmSNP1mfp2tJNcueP0S4H8ADwbOTHJ6y7FJkiSteU0T5BfeA9wKPLWqzgKeBvxma1FJkqTZkJa3CdA0Z2tdkgPoFGWpqm8DVNU/JdnVenSSJElrXFOxtR9wPZ3asJIcVlXbk2xhYupFSZK0Vs1CMdE0Qf7IZQ7tBv7tyKORJEmaMkM9G7GqdgBfG3EskiRpxszCOltNE+QlSZK0AkONbEmSJI3CLKyzZbElSZLGxtuIkiRJWpGBi60kh7QRiCRJ0jRqelzPgXttBwHXJjkgyYE9ztuaZD7J/AXnz408aEmSpLWiac7WHcDX99r3MOBTQAGPWOqkqpoD5gDuvrdqhTFKkqQp5ZwtOA34IvDsqnp4VT0c2NZ9vWShJUmSpB9qWkH+tUneDbw+ya3AmXRGtCRJklbMpR+AqtoGnJTk14ArgM2DdLDO7ztKkqQZ1vc6W1X1wSTfA56c5GlV9ZH2wpIkSbNg5udsJbl2weuXAP8d2Ac4M8npLccmSZK05jXd5Nuw4PVW4GlVdRbwNOA3W4tKkiTNhLS8TYKm24jrkhxApyhLVX0boKr+Kcmu1qOTJEla45qKrf2A6+kUh5XksKranmQLk1MwSpKktWoGqommpR+OXObQbuDfjjwaSZKkKdP3txEXqqodwNdGHIskSZoxs7DOlqtgSZIktSjV/qMLXXFekqTJNrbhpX+6r91C5MceNP6VvIa6jTiIHff3zuHmDWHnGvle46b1rEqsq9XPKJiTxczJYtOWE3M/vn5GwZwstqn1amC2mV5JkjQ2Yx92WgUDz9lKclAbgUiSJE2jpsf1nJPk4O7r45J8FbgmydeTPHlVIpQkSdNrBpaQbxrZOrGq7ui+Pg94flU9Cngq8LrlTkqyNcl8kvkLzp8bUaiSJGnapOX/9RVD8owkX0zyD208+7lpztaGJOurahewb1VdB1BVX0qycbmTqmoOmAPYcX/7X3eUJEkaRpJ9gDfTGUjaBlyX5NKq+vyo+mgqtt4MfDjJOcDlSd4AvA84AbhhVEFIkqTZNP6FGXgC8A9V9VWAJO8GngOsTrFVVW9KciPwMuCo7t8fBbwf+KNRBSFJkjQmDwNuXfD7NuDnR9pDVfW9Ab8E/CfgaYOct0Q7W1dyvm1MdiyT0sYkxTJNbUxSLJPSxiTFMiltTFIs09TGpMWyFjZgKzC/YNu61/GTgPMX/P7vgTeNMoambyNeu+D1bwP/HdgCnLnCCWRbV3CubbTbzjS1Map2bKOddqapjVG1M01tjKod22innVHFMvGqaq6qjluw7f3NvW3AEQt+Pxz45ihjaPo24oYFr/8DnRGts4CnAb85ykAkSZLG4Drg0UkenuRBwAuAS0fZQdME+XVJDqBTlKWqvg1QVf+UZI08hECSJGlpVbUrye8C/wvYB7igqj43yj6aiq39gOvpLAtWSQ6rqu1JtrCypcJGsfiWbbTTzjS1Map2bKOddqapjVG1M01tjKod22inHRfBXKCqPgx8uK32050MNthJyWbg0Kr62uhDkiRJmh5DFVuSJEnqz8APol6JlS6Hn+SIJB9PcnOSzyV55Qpi2SfJp5N8aAVt7J/kkiRf6Mb0C0O08Xvd93JTkncl2dTHORck+VaSmxbsOzDJFUm+3P15wJDtnNd9P59N8j+T7D9oGwuO/ecktef5moO2keTl3evlc0leM8R7OTrJ3ye5ofv4qCc0tLHk9TVIbnu0MWhee17r/eS2Vxv95rbH++k7t0k2Jbk2yWe6bZzV3T/QNdujnb5zu1wbC473k9dl2xggr8u9l4Gu2e45P/JZNmhel2ljoOt1uXYW7O/rs2C5NvrNa4/3M0xeb0ly455zuvsGvWaXamPQz4JFbSw41u9n7JJtDJpXrcAqrnOxD/AV4BHAg4DPAD8zYBsPBX6u+/rBwJcGbWNBW/8R+CvgQyt4TxcBv919/SBg/wHPfxjwNTqPQgK4GHhhH+c9Cfg54KYF+14DnN59fTpw7pDtPA1Y3319blM7S7XR3X8EncmGXwcOHiKOXwY+Cmzs/n7IEG18BHhm9/WvAlcNc30NktsebQya12Wv9X5z2yOWvnPbo42+c0tnfueW7usNwDXAEwe9Znu003dul2tjwLwuF8cgeV2ujYGu2e7f/chn2aB5XaaNga7X5doZJK89Yhnos2CZNobJ6y17xzvENbtUG4N+FixqY9C8LhPHwHl1G35bzZGtf14Ov6ruA/Ysh9+3qrqtqj7Vff0D4GY6BctAkhwOnAicP+i5C9p4CJ3/g39rN577qup7QzS1Htg3yXpgM32s7VFVnwC+u9fu59Ap/uj+fO4w7VTVR6rzLEyAv6ez3sigsQC8HjgNaLxPvUwbLwPOqap7u3/zrSHaKOAh3df70ZDbHtdX37ldro0h8trrWu8rtz3a6Du3PdroO7fVcXf31w3drRjwml2unUFy2yMW6D+vy7UxSF6Xa2Oga3aZz7KB8rpUG4Nerz1igQE+C5ZpY6DPgmXaGCivPQz8Obu3YXK7jL7zuoyB8qqVWc1ia6nl8AculPZIciRwDJ1/EQ7qDXQu0t3D9k9nhO7bwIXd4erzk/zYIA1U1T8CrwW+AdwGfL+qPjJkPIdW1W3ddm8DDhmynYVeBPzNoCcleTbwj1X1mRX0fRTwS0muSXJ1kscP0cargPOS3Eonz3/Q74l7XV9D5bbHNTpQXhe2M2xu94plqNzu1carGCC33ds6NwDfAq6oqqHyukw7CzXmdqk2Bs3rMnEMlNdl2ngVg12zb2DxZ9mgeV2qjYX6vV4XtTPE9bpULINer0u18SoG/ywo4CNJrk+yZwHQQXO7VBsL9ZPbRW0Mkdel4hjFZ6z6tJrF1lJLRQxVkaez9MR7gVdV1V0Dnvss4FtVdf0wfS+wns5tqz+rqmOAf6IzrDxILAfQ+ZfSw4GfAH4syb9bYVwjkeQMYBfwlwOetxk4A/ivKwxhPXAAnVsrvw9cnAz8uNKXAb9XVUcAv0d3FLLJSq6vpjYGzevCdrrnDZzbJWIZOLdLtDFQbqvqgao6ms6/4p+Q5F8O8h76aaff3C7Rxs8yYF6XiWOgvC7TRt95HcVnWVMb/eZ0qXYG/SzoEUvfee3RxjCfBf+mqn4OeCbwO0me1M/76LeNAT4Llmpj0M+BpdoYxWes+lWrdL8S+AXgfy34/Q+APxiinQ107lP/xyHj+BM6o2q3ANuBHcA7h2jnMOCWBb//EnDZgG2cBLx1we+nAG/p89wj+dH5SV8EHtp9/VDgi8O00913KvB/gM2DtgE8js6/1G/pbrvojNwdNuD7uRw4fsHvXwF+fMA2vs8Pv3Eb4K5hrq9Bc7vcNTpEXn+knWFyu8z7GSi3y7QxcG4XnHsm8J+HvWb3bmeY3O7Vxn8Z5ppd4v0MfM0u0UbfeWWZz7JB8rpcG4PmdJl23jtIXnu8n77z2qONoa/X7jl/uNJrdk8bK7xe/3AE1+ue9zL09eo2+LZ6HXWq6K/SGcXZM0H+sQO2EeDtwBtGFNPxrGyC/P8Gfrr7+g+B8wY8/+eBz9GZqxU6cwBe3ue5R/KjhcV5/OjEzdcM2c4zgM8P8h/d3m3sdewW+psUu3ccLwX+W/f1UXRuQWfANm7e82ECnABcP8z1NUhue7QxUF77udabctsjlr5z26ONvnML/DjdL48A+3b/u3nWoNdsj3b6zu1ybQyY1+XiGCSvy7Ux0DW7oL3j+eFk8GE/Cxa2MfDnwFLtDJLXHrEM/FmwRBuDfhb8GPDgBa8/2c3JIJ8Fy7UxyPW6ZBsDXq/LxTFUXt2G21a3s863QL5Ep4I+Y4jzf5HOrcfPAjd0t19dQTxLfigMcP7RdJ4g/lng/cABQ7RxFvAF4CbgHXS/GdJwzrvozPG6n86/4l4MHARcCXy5+/PAIdv5h+5/dHvy+/8N2sZex3t+EPSI40F0/kV6E/Ap4ClDtPGLdJ6A8Bk684yOHeb6GiS3PdoYNK+N13pTbnvE0ndue7TRd26BnwU+3W3jJuC/dvcPdM32aKfv3C7XxoB5XS6OQfK6XBsDXbML2jueHxYWA38WLNHGQNfrcu0M+lmwTCwDfRYs08agnwWP6P7tZ+j8g/iMQXPbo41Brtcl2xjwel0ujqHy6jbc5qKmkiRJLVrVRU0lSZJmjcWWJElSiyy2JEmSWmSxJUmS1CKLLUmSpBZZbEmSJLXIYkuSJKlFFluSJEkt+v8BhWwipQlTHSsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 792x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(reuters[2])\n",
    "do_metrics(reuters[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 RF with NaN 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "                      0.70      0.96      0.81      2120\n",
      "            acq       0.90      0.61      0.73       469\n",
      "           alum       1.00      0.15      0.27        13\n",
      "         barley       0.00      0.00      0.00         1\n",
      "            bop       1.00      0.09      0.17        11\n",
      "        carcass       1.00      0.11      0.20         9\n",
      "          cocoa       1.00      0.33      0.50        12\n",
      "         coffee       0.86      0.22      0.35        27\n",
      "         copper       1.00      0.28      0.43        18\n",
      "           corn       0.00      0.00      0.00         1\n",
      "         cotton       0.00      0.00      0.00         6\n",
      "            cpi       0.67      0.35      0.46        17\n",
      "            cpu       0.00      0.00      0.00         2\n",
      "          crude       0.89      0.44      0.59       112\n",
      "        cruzado       0.00      0.00      0.00         1\n",
      "            dlr       0.33      0.11      0.17         9\n",
      "           earn       0.94      0.83      0.88       768\n",
      "           fuel       1.00      0.25      0.40         4\n",
      "            gas       1.00      0.33      0.50         3\n",
      "            gnp       0.67      0.11      0.19        18\n",
      "           gold       0.89      0.47      0.62        17\n",
      "          grain       0.74      0.60      0.66        98\n",
      "           heat       1.00      0.67      0.80         3\n",
      "             hk       0.00      0.00      0.00         1\n",
      "            hog       0.50      0.25      0.33         4\n",
      "        housing       1.00      0.25      0.40         4\n",
      "         income       0.00      0.00      0.00         3\n",
      "       interest       0.80      0.29      0.42        70\n",
      "    inventories       0.00      0.00      0.00         1\n",
      "            ipi       1.00      0.67      0.80         9\n",
      "     iron-steel       1.00      0.09      0.17        11\n",
      "           jobs       1.00      0.62      0.77         8\n",
      "       l-cattle       0.00      0.00      0.00         1\n",
      "           lead       1.00      0.17      0.29         6\n",
      "            lei       0.00      0.00      0.00         2\n",
      "      livestock       0.00      0.00      0.00         7\n",
      "         lumber       0.00      0.00      0.00         5\n",
      "      meal-feed       0.00      0.00      0.00         3\n",
      "       money-fx       0.78      0.44      0.57       122\n",
      "   money-supply       0.90      0.29      0.44        31\n",
      "        nat-gas       0.00      0.00      0.00        10\n",
      "         nickel       0.00      0.00      0.00         1\n",
      "        oilseed       1.00      0.12      0.21        17\n",
      "         orange       0.00      0.00      0.00         4\n",
      "       palm-oil       0.00      0.00      0.00         1\n",
      "       pet-chem       0.00      0.00      0.00         5\n",
      "       platinum       0.00      0.00      0.00         1\n",
      "        plywood       0.00      0.00      0.00         1\n",
      "         potato       0.00      0.00      0.00         2\n",
      "       reserves       0.00      0.00      0.00        14\n",
      "         retail       0.00      0.00      0.00         3\n",
      "         rubber       1.00      0.11      0.20         9\n",
      "           ship       0.70      0.23      0.35        30\n",
      "         silver       0.00      0.00      0.00         6\n",
      "            stg       1.00      0.33      0.50         3\n",
      "strategic-metal       0.00      0.00      0.00         3\n",
      "          sugar       1.00      0.42      0.59        36\n",
      "            tea       0.00      0.00      0.00         1\n",
      "            tin       0.50      0.14      0.22         7\n",
      "          trade       0.89      0.36      0.51        92\n",
      "        veg-oil       0.86      0.32      0.46        19\n",
      "          wheat       0.00      0.00      0.00         5\n",
      "           wool       0.00      0.00      0.00         1\n",
      "            wpi       1.00      0.11      0.20         9\n",
      "            yen       0.00      0.00      0.00         2\n",
      "           zinc       1.00      0.14      0.25         7\n",
      "\n",
      "       accuracy                           0.76      4316\n",
      "      macro avg       0.49      0.19      0.25      4316\n",
      "   weighted avg       0.78      0.76      0.73      4316\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(reuters_t20[10])\n",
    "do_metrics(reuters_t20[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cr_kn': 0,\n",
       " 'cm_kn': 1,\n",
       " 'cr_nb': 2,\n",
       " 'cm_nb': 3,\n",
       " 'x_train': 4,\n",
       " 'y_train': 5,\n",
       " 'model_kn': 6,\n",
       " 'model_nb': 7,\n",
       " 'y_hat_kn': 8,\n",
       " 'y_hat_nb': 9,\n",
       " 'cr_rf': 10,\n",
       " 'cm_rf': 11,\n",
       " 'model_rf': 12,\n",
       " 'y_hat_rf': 13,\n",
       " 'x_test': 14,\n",
       " 'y_test': 15}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lazy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter search:** For hyperparameters a grid search was implemented. For both KNN and Multinomial NB most of the possible metrics were explored due to the fast nature of the chosen design. For Random Forest it was assumed the majority of trials will go 'NaN' due to incompatability of parameters, which proved to be true. However, in order not to burn the CPU, `n_jobs` parameter was chosen as 1 and training size was reduced to only 3000 units, as with two-fold cross-validation there were already 432 candidates with 864 fits for KNN. The results revealed that accuracy for both Random Forest Trees and Multinomial NB fluctuates about 10\\%, whereas KNN relies heavily on hyperparameters, fluctuation up to 60\\%.\n",
    "\n",
    "**Generability:** the only un-generalisible part of the whole pipeline is data preprocessing. However, not all data is created equal - naturally, the preprocessing step will always differ. As regards to models itself, the most adaptive one proved to be Random Forest Trees, whereas KNN depended heavily on data preprocessing and randomness, thus, results fluctuated the most.\n",
    "\n",
    "**Future design choices and ideas:** 1) as most of the data in Reuters data set is non-labeled, it would be interesting to see how a non-supervised or semi-supervised algorithm would perform on the data 2) I am still not sure how to deal with mutli-labels and would love to see the solution 3) would split data into train, test and validation 4) as the implementation of \\path{pipe()} function allows it, would try out more models in order to educate myself through observations 5) would run hyperparameter tuning on fewer hyperparameters, but more options per one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# ----KNN ----\n",
    "\n",
    "parameters_kn = {\n",
    "    'vect__stop_words': ('english', None),\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__n_neighbors': (5, 7, 11),\n",
    "    'clf__weights':('uniform', 'distance'),\n",
    "    'clf__p':(1, 2),  \n",
    "    'clf__metric': ('euclidean', 'manhattan', 'minkowski')\n",
    "}\n",
    "\n",
    "# ---- MULTINOMIAL NAIVE BAYES ----\n",
    "\n",
    "\n",
    "parameters_nb = {\n",
    "    'vect__stop_words': ('english', None),\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__alpha': (0.1, 0.01, 0.001, 0.0001), \n",
    "    'clf__fit_prior':(True, False),\n",
    "}\n",
    "\n",
    "# ---- RANDOM FOREST ----\n",
    "\n",
    "parameters_rf = {\n",
    "    'vect__stop_words': ('english', None),\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__class_weight':('balanced', 'balanced_subsample', None),\n",
    "    'clf__criterion':('gini', 'entropy'),\n",
    "    'clf__min_samples_split': (2, 3, 4),\n",
    "    'clf__min_samples_split': (1, 2, 3),\n",
    "    'clf__n_estimators':(20, 50, 100, 200),\n",
    "    'clf__warm_start':(True, False)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chosen_model = newsgroups\n",
    "chosen_model = newsgroups_t20\n",
    "# chosen_model = newsgroups1\n",
    "# chosen_model = newsgroups2\n",
    "\n",
    "# chosen_model = reuters\n",
    "# chosen_model = reuters_t20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cr_kn': 0,\n",
       " 'cm_kn': 1,\n",
       " 'cr_nb': 2,\n",
       " 'cm_nb': 3,\n",
       " 'x_train': 4,\n",
       " 'y_train': 5,\n",
       " 'model_kn': 6,\n",
       " 'model_nb': 7,\n",
       " 'y_hat_kn': 8,\n",
       " 'y_hat_nb': 9,\n",
       " 'cr_rf': 10,\n",
       " 'cm_rf': 11,\n",
       " 'model_rf': 12,\n",
       " 'y_hat_rf': 13,\n",
       " 'x_test': 14,\n",
       " 'y_test': 15}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lazy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_kn = GridSearchCV(chosen_model[6], parameters_kn, cv=2, n_jobs=3, verbose=True)\n",
    "\n",
    "# To change parameters:\n",
    "\n",
    "# print('For the KN model available parameters are:\\n')\n",
    "# print('Parameters for the whole model pipeline:', gs_kn.get_params().keys())\n",
    "\n",
    "# for i in gs_kn.get_params().keys():\n",
    "#     if 'clf' in i:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_nb = GridSearchCV(chosen_model[7], parameters_nb, cv=2, n_jobs=3, verbose=True)\n",
    "\n",
    "# To change parameters:\n",
    "\n",
    "# print('For the Multinomial Naive Bayes model available parameters are:\\n')\n",
    "# print('Parameters for the whole model pipeline:', gs_nb.get_params().keys())\n",
    "\n",
    "# for i in gs_nb.get_params().keys():\n",
    "#     if 'clf' in i:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the Random Forest model available parameters are:\n",
      "\n",
      "estimator__clf\n",
      "estimator__clf__bootstrap\n",
      "estimator__clf__ccp_alpha\n",
      "estimator__clf__class_weight\n",
      "estimator__clf__criterion\n",
      "estimator__clf__max_depth\n",
      "estimator__clf__max_features\n",
      "estimator__clf__max_leaf_nodes\n",
      "estimator__clf__max_samples\n",
      "estimator__clf__min_impurity_decrease\n",
      "estimator__clf__min_impurity_split\n",
      "estimator__clf__min_samples_leaf\n",
      "estimator__clf__min_samples_split\n",
      "estimator__clf__min_weight_fraction_leaf\n",
      "estimator__clf__n_estimators\n",
      "estimator__clf__n_jobs\n",
      "estimator__clf__oob_score\n",
      "estimator__clf__random_state\n",
      "estimator__clf__verbose\n",
      "estimator__clf__warm_start\n"
     ]
    }
   ],
   "source": [
    "gs_rf = GridSearchCV(chosen_model[12], parameters_rf, cv=2, n_jobs=1, verbose=True)\n",
    "\n",
    "# To change parameters:\n",
    "\n",
    "print('For the Random Forest model available parameters are:\\n')\n",
    "# print('Parameters for the whole model pipeline:', gs_nb.get_params().keys())\n",
    "\n",
    "for i in gs_rf.get_params().keys():\n",
    "    if 'clf' in i:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source for the cell below: https://stackoverflow.com/questions/39977117/ipython-display-full-dataframe-in-new-tab/40878617"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "def view(df):\n",
    "    css = \"\"\"<style>\n",
    "    table { border-collapse: collapse; border: 3px solid #eee; }\n",
    "    table tr th:first-child { background-color: #eeeeee; color: #333; font-weight: bold }\n",
    "    table thead th { background-color: #eee; color: #000; }\n",
    "    tr, th, td { border: 1px solid #ccc; border-width: 1px 0 0 1px; border-collapse: collapse;\n",
    "    padding: 3px; font-family: monospace; font-size: 10px }</style>\n",
    "    \"\"\"\n",
    "    s  = '<script type=\"text/Javascript\">'\n",
    "    s += 'var win = window.open(\"\", \"Title\", \"toolbar=no, location=no, directories=no, status=no, menubar=no, scrollbars=yes, resizable=yes, width=780, height=200, top=\"+(screen.height-400)+\", left=\"+(screen.width-840));'\n",
    "    s += 'win.document.body.innerHTML = \\'' + (df.to_html() + css).replace(\"\\n\",'\\\\') + '\\';'\n",
    "    s += '</script>'\n",
    "    return(HTML(s+css))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 288 candidates, totalling 576 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=3)]: Done 576 out of 576 | elapsed:  6.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.6s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.0s\n",
      "Search executed in: 404.0057876589999\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "gs_kn = gs_kn.fit(chosen_model[4][:3000], chosen_model[5][:3000])\n",
    "end = timer()\n",
    "print('Search executed in:', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best achieved score: 0.5700000000000001 \n",
      "\n",
      "With these params:\n",
      " {'clf__metric': 'euclidean', 'clf__n_neighbors': 11, 'clf__p': 1, 'clf__weights': 'uniform', 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english'}\n"
     ]
    }
   ],
   "source": [
    "print('Best achieved score:', gs_kn.best_score_, '\\n')\n",
    "\n",
    "print('With these params:\\n', gs_kn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf__metric</th>\n",
       "      <th>clf__n_neighbors</th>\n",
       "      <th>clf__p</th>\n",
       "      <th>clf__weights</th>\n",
       "      <th>tfidf__use_idf</th>\n",
       "      <th>vect__ngram_range</th>\n",
       "      <th>vect__stop_words</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>euclidean</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.169000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>euclidean</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.162333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>euclidean</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>euclidean</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.153333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>euclidean</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.153333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>minkowski</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.397000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>minkowski</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.309333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>minkowski</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.222000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>minkowski</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.304000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>minkowski</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.180000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    clf__metric  clf__n_neighbors  clf__p clf__weights  tfidf__use_idf  \\\n",
       "0     euclidean                 5       1      uniform            True   \n",
       "1     euclidean                 5       1      uniform            True   \n",
       "2     euclidean                 5       1      uniform            True   \n",
       "3     euclidean                 5       1      uniform            True   \n",
       "4     euclidean                 5       1      uniform           False   \n",
       "..          ...               ...     ...          ...             ...   \n",
       "283   minkowski                11       2     distance            True   \n",
       "284   minkowski                11       2     distance           False   \n",
       "285   minkowski                11       2     distance           False   \n",
       "286   minkowski                11       2     distance           False   \n",
       "287   minkowski                11       2     distance           False   \n",
       "\n",
       "    vect__ngram_range vect__stop_words  Accuracy  \n",
       "0              (1, 1)          english  0.169000  \n",
       "1              (1, 1)             None  0.162333  \n",
       "2              (1, 2)          english  0.166667  \n",
       "3              (1, 2)             None  0.153333  \n",
       "4              (1, 1)          english  0.153333  \n",
       "..                ...              ...       ...  \n",
       "283            (1, 2)             None  0.397000  \n",
       "284            (1, 1)          english  0.309333  \n",
       "285            (1, 1)             None  0.222000  \n",
       "286            (1, 2)          english  0.304000  \n",
       "287            (1, 2)             None  0.180000  \n",
       "\n",
       "[288 rows x 8 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.concat([pd.DataFrame(gs_kn.cv_results_[\"params\"]),\n",
    "                 pd.DataFrame(gs_kn.cv_results_[\"mean_test_score\"], \n",
    "                              columns=[\"Accuracy\"])],axis=1)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/Javascript\">var win = window.open(\"\", \"Title\", \"toolbar=no, location=no, directories=no, status=no, menubar=no, scrollbars=yes, resizable=yes, width=780, height=200, top=\"+(screen.height-400)+\", left=\"+(screen.width-840));win.document.body.innerHTML = '<table border=\"1\" class=\"dataframe\">\\  <thead>\\    <tr style=\"text-align: right;\">\\      <th></th>\\      <th>clf__metric</th>\\      <th>clf__n_neighbors</th>\\      <th>clf__p</th>\\      <th>clf__weights</th>\\      <th>tfidf__use_idf</th>\\      <th>vect__ngram_range</th>\\      <th>vect__stop_words</th>\\      <th>Accuracy</th>\\    </tr>\\  </thead>\\  <tbody>\\    <tr>\\      <th>0</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.169000</td>\\    </tr>\\    <tr>\\      <th>1</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.162333</td>\\    </tr>\\    <tr>\\      <th>2</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.166667</td>\\    </tr>\\    <tr>\\      <th>3</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.153333</td>\\    </tr>\\    <tr>\\      <th>4</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.153333</td>\\    </tr>\\    <tr>\\      <th>5</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.187000</td>\\    </tr>\\    <tr>\\      <th>6</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.134333</td>\\    </tr>\\    <tr>\\      <th>7</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.155333</td>\\    </tr>\\    <tr>\\      <th>8</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.156667</td>\\    </tr>\\    <tr>\\      <th>9</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.160333</td>\\    </tr>\\    <tr>\\      <th>10</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.146667</td>\\    </tr>\\    <tr>\\      <th>11</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.135667</td>\\    </tr>\\    <tr>\\      <th>12</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.166667</td>\\    </tr>\\    <tr>\\      <th>13</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.216000</td>\\    </tr>\\    <tr>\\      <th>14</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.148667</td>\\    </tr>\\    <tr>\\      <th>15</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.183333</td>\\    </tr>\\    <tr>\\      <th>16</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.169000</td>\\    </tr>\\    <tr>\\      <th>17</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.162333</td>\\    </tr>\\    <tr>\\      <th>18</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.166667</td>\\    </tr>\\    <tr>\\      <th>19</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.153333</td>\\    </tr>\\    <tr>\\      <th>20</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.153333</td>\\    </tr>\\    <tr>\\      <th>21</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.187000</td>\\    </tr>\\    <tr>\\      <th>22</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.134333</td>\\    </tr>\\    <tr>\\      <th>23</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.155333</td>\\    </tr>\\    <tr>\\      <th>24</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.156667</td>\\    </tr>\\    <tr>\\      <th>25</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.160333</td>\\    </tr>\\    <tr>\\      <th>26</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.146667</td>\\    </tr>\\    <tr>\\      <th>27</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.135667</td>\\    </tr>\\    <tr>\\      <th>28</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.166667</td>\\    </tr>\\    <tr>\\      <th>29</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.216000</td>\\    </tr>\\    <tr>\\      <th>30</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.148667</td>\\    </tr>\\    <tr>\\      <th>31</th>\\      <td>euclidean</td>\\      <td>5</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.183333</td>\\    </tr>\\    <tr>\\      <th>32</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.463333</td>\\    </tr>\\    <tr>\\      <th>33</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.387000</td>\\    </tr>\\    <tr>\\      <th>34</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.440000</td>\\    </tr>\\    <tr>\\      <th>35</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.339333</td>\\    </tr>\\    <tr>\\      <th>36</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.251667</td>\\    </tr>\\    <tr>\\      <th>37</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.197000</td>\\    </tr>\\    <tr>\\      <th>38</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.237000</td>\\    </tr>\\    <tr>\\      <th>39</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.165333</td>\\    </tr>\\    <tr>\\      <th>40</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.447000</td>\\    </tr>\\    <tr>\\      <th>41</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.378333</td>\\    </tr>\\    <tr>\\      <th>42</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.427667</td>\\    </tr>\\    <tr>\\      <th>43</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.325333</td>\\    </tr>\\    <tr>\\      <th>44</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.255000</td>\\    </tr>\\    <tr>\\      <th>45</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.221333</td>\\    </tr>\\    <tr>\\      <th>46</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.242333</td>\\    </tr>\\    <tr>\\      <th>47</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.184667</td>\\    </tr>\\    <tr>\\      <th>48</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.463333</td>\\    </tr>\\    <tr>\\      <th>49</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.387000</td>\\    </tr>\\    <tr>\\      <th>50</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.440000</td>\\    </tr>\\    <tr>\\      <th>51</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.339333</td>\\    </tr>\\    <tr>\\      <th>52</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.251667</td>\\    </tr>\\    <tr>\\      <th>53</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.197000</td>\\    </tr>\\    <tr>\\      <th>54</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.237000</td>\\    </tr>\\    <tr>\\      <th>55</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.165333</td>\\    </tr>\\    <tr>\\      <th>56</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.447000</td>\\    </tr>\\    <tr>\\      <th>57</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.378333</td>\\    </tr>\\    <tr>\\      <th>58</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.427667</td>\\    </tr>\\    <tr>\\      <th>59</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.325333</td>\\    </tr>\\    <tr>\\      <th>60</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.255000</td>\\    </tr>\\    <tr>\\      <th>61</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.221333</td>\\    </tr>\\    <tr>\\      <th>62</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.242333</td>\\    </tr>\\    <tr>\\      <th>63</th>\\      <td>euclidean</td>\\      <td>7</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.184667</td>\\    </tr>\\    <tr>\\      <th>64</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.570000</td>\\    </tr>\\    <tr>\\      <th>65</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.470667</td>\\    </tr>\\    <tr>\\      <th>66</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.547667</td>\\    </tr>\\    <tr>\\      <th>67</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.402667</td>\\    </tr>\\    <tr>\\      <th>68</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.301333</td>\\    </tr>\\    <tr>\\      <th>69</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.205667</td>\\    </tr>\\    <tr>\\      <th>70</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.289667</td>\\    </tr>\\    <tr>\\      <th>71</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.166667</td>\\    </tr>\\    <tr>\\      <th>72</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.563667</td>\\    </tr>\\    <tr>\\      <th>73</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.466000</td>\\    </tr>\\    <tr>\\      <th>74</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.550000</td>\\    </tr>\\    <tr>\\      <th>75</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.397000</td>\\    </tr>\\    <tr>\\      <th>76</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.309333</td>\\    </tr>\\    <tr>\\      <th>77</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.222000</td>\\    </tr>\\    <tr>\\      <th>78</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.304000</td>\\    </tr>\\    <tr>\\      <th>79</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.180000</td>\\    </tr>\\    <tr>\\      <th>80</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.570000</td>\\    </tr>\\    <tr>\\      <th>81</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.470667</td>\\    </tr>\\    <tr>\\      <th>82</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.547667</td>\\    </tr>\\    <tr>\\      <th>83</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.402667</td>\\    </tr>\\    <tr>\\      <th>84</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.301333</td>\\    </tr>\\    <tr>\\      <th>85</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.205667</td>\\    </tr>\\    <tr>\\      <th>86</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.289667</td>\\    </tr>\\    <tr>\\      <th>87</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.166667</td>\\    </tr>\\    <tr>\\      <th>88</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.563667</td>\\    </tr>\\    <tr>\\      <th>89</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.466000</td>\\    </tr>\\    <tr>\\      <th>90</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.550000</td>\\    </tr>\\    <tr>\\      <th>91</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.397000</td>\\    </tr>\\    <tr>\\      <th>92</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.309333</td>\\    </tr>\\    <tr>\\      <th>93</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.222000</td>\\    </tr>\\    <tr>\\      <th>94</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.304000</td>\\    </tr>\\    <tr>\\      <th>95</th>\\      <td>euclidean</td>\\      <td>11</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.180000</td>\\    </tr>\\    <tr>\\      <th>96</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.064667</td>\\    </tr>\\    <tr>\\      <th>97</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.064333</td>\\    </tr>\\    <tr>\\      <th>98</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.063000</td>\\    </tr>\\    <tr>\\      <th>99</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.061667</td>\\    </tr>\\    <tr>\\      <th>100</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.067333</td>\\    </tr>\\    <tr>\\      <th>101</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.075000</td>\\    </tr>\\    <tr>\\      <th>102</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.065667</td>\\    </tr>\\    <tr>\\      <th>103</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.062000</td>\\    </tr>\\    <tr>\\      <th>104</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.083000</td>\\    </tr>\\    <tr>\\      <th>105</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.086333</td>\\    </tr>\\    <tr>\\      <th>106</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.081333</td>\\    </tr>\\    <tr>\\      <th>107</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.081333</td>\\    </tr>\\    <tr>\\      <th>108</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.084333</td>\\    </tr>\\    <tr>\\      <th>109</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.104000</td>\\    </tr>\\    <tr>\\      <th>110</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.080000</td>\\    </tr>\\    <tr>\\      <th>111</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.082667</td>\\    </tr>\\    <tr>\\      <th>112</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.064667</td>\\    </tr>\\    <tr>\\      <th>113</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.064333</td>\\    </tr>\\    <tr>\\      <th>114</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.063000</td>\\    </tr>\\    <tr>\\      <th>115</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.061667</td>\\    </tr>\\    <tr>\\      <th>116</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.067333</td>\\    </tr>\\    <tr>\\      <th>117</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.075000</td>\\    </tr>\\    <tr>\\      <th>118</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.065667</td>\\    </tr>\\    <tr>\\      <th>119</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.062000</td>\\    </tr>\\    <tr>\\      <th>120</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.083000</td>\\    </tr>\\    <tr>\\      <th>121</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.086333</td>\\    </tr>\\    <tr>\\      <th>122</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.081333</td>\\    </tr>\\    <tr>\\      <th>123</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.081333</td>\\    </tr>\\    <tr>\\      <th>124</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.084333</td>\\    </tr>\\    <tr>\\      <th>125</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.104000</td>\\    </tr>\\    <tr>\\      <th>126</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.080000</td>\\    </tr>\\    <tr>\\      <th>127</th>\\      <td>manhattan</td>\\      <td>5</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.082667</td>\\    </tr>\\    <tr>\\      <th>128</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.069667</td>\\    </tr>\\    <tr>\\      <th>129</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.070667</td>\\    </tr>\\    <tr>\\      <th>130</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.070000</td>\\    </tr>\\    <tr>\\      <th>131</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.065667</td>\\    </tr>\\    <tr>\\      <th>132</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.073667</td>\\    </tr>\\    <tr>\\      <th>133</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.091667</td>\\    </tr>\\    <tr>\\      <th>134</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.069000</td>\\    </tr>\\    <tr>\\      <th>135</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.067000</td>\\    </tr>\\    <tr>\\      <th>136</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.087000</td>\\    </tr>\\    <tr>\\      <th>137</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.085333</td>\\    </tr>\\    <tr>\\      <th>138</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.085667</td>\\    </tr>\\    <tr>\\      <th>139</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.081667</td>\\    </tr>\\    <tr>\\      <th>140</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.086667</td>\\    </tr>\\    <tr>\\      <th>141</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.109667</td>\\    </tr>\\    <tr>\\      <th>142</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.086000</td>\\    </tr>\\    <tr>\\      <th>143</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.081333</td>\\    </tr>\\    <tr>\\      <th>144</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.069667</td>\\    </tr>\\    <tr>\\      <th>145</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.070667</td>\\    </tr>\\    <tr>\\      <th>146</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.070000</td>\\    </tr>\\    <tr>\\      <th>147</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.065667</td>\\    </tr>\\    <tr>\\      <th>148</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.073667</td>\\    </tr>\\    <tr>\\      <th>149</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.091667</td>\\    </tr>\\    <tr>\\      <th>150</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.069000</td>\\    </tr>\\    <tr>\\      <th>151</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.067000</td>\\    </tr>\\    <tr>\\      <th>152</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.087000</td>\\    </tr>\\    <tr>\\      <th>153</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.085333</td>\\    </tr>\\    <tr>\\      <th>154</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.085667</td>\\    </tr>\\    <tr>\\      <th>155</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.081667</td>\\    </tr>\\    <tr>\\      <th>156</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.086667</td>\\    </tr>\\    <tr>\\      <th>157</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.109667</td>\\    </tr>\\    <tr>\\      <th>158</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.086000</td>\\    </tr>\\    <tr>\\      <th>159</th>\\      <td>manhattan</td>\\      <td>7</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.081333</td>\\    </tr>\\    <tr>\\      <th>160</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.064667</td>\\    </tr>\\    <tr>\\      <th>161</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.066667</td>\\    </tr>\\    <tr>\\      <th>162</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.060667</td>\\    </tr>\\    <tr>\\      <th>163</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.056000</td>\\    </tr>\\    <tr>\\      <th>164</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.077333</td>\\    </tr>\\    <tr>\\      <th>165</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.101333</td>\\    </tr>\\    <tr>\\      <th>166</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.063333</td>\\    </tr>\\    <tr>\\      <th>167</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.059333</td>\\    </tr>\\    <tr>\\      <th>168</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.072667</td>\\    </tr>\\    <tr>\\      <th>169</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.088000</td>\\    </tr>\\    <tr>\\      <th>170</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.072000</td>\\    </tr>\\    <tr>\\      <th>171</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.074000</td>\\    </tr>\\    <tr>\\      <th>172</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.085333</td>\\    </tr>\\    <tr>\\      <th>173</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.123667</td>\\    </tr>\\    <tr>\\      <th>174</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.071333</td>\\    </tr>\\    <tr>\\      <th>175</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.075333</td>\\    </tr>\\    <tr>\\      <th>176</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.064667</td>\\    </tr>\\    <tr>\\      <th>177</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.066667</td>\\    </tr>\\    <tr>\\      <th>178</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.060667</td>\\    </tr>\\    <tr>\\      <th>179</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.056000</td>\\    </tr>\\    <tr>\\      <th>180</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.077333</td>\\    </tr>\\    <tr>\\      <th>181</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.101333</td>\\    </tr>\\    <tr>\\      <th>182</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.063333</td>\\    </tr>\\    <tr>\\      <th>183</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.059333</td>\\    </tr>\\    <tr>\\      <th>184</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.072667</td>\\    </tr>\\    <tr>\\      <th>185</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.088000</td>\\    </tr>\\    <tr>\\      <th>186</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.072000</td>\\    </tr>\\    <tr>\\      <th>187</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.074000</td>\\    </tr>\\    <tr>\\      <th>188</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.085333</td>\\    </tr>\\    <tr>\\      <th>189</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.123667</td>\\    </tr>\\    <tr>\\      <th>190</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.071333</td>\\    </tr>\\    <tr>\\      <th>191</th>\\      <td>manhattan</td>\\      <td>11</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.075333</td>\\    </tr>\\    <tr>\\      <th>192</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.064667</td>\\    </tr>\\    <tr>\\      <th>193</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.064333</td>\\    </tr>\\    <tr>\\      <th>194</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.063000</td>\\    </tr>\\    <tr>\\      <th>195</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.061667</td>\\    </tr>\\    <tr>\\      <th>196</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.067333</td>\\    </tr>\\    <tr>\\      <th>197</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.075000</td>\\    </tr>\\    <tr>\\      <th>198</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.065667</td>\\    </tr>\\    <tr>\\      <th>199</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.062000</td>\\    </tr>\\    <tr>\\      <th>200</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.083000</td>\\    </tr>\\    <tr>\\      <th>201</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.086333</td>\\    </tr>\\    <tr>\\      <th>202</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.081333</td>\\    </tr>\\    <tr>\\      <th>203</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.081333</td>\\    </tr>\\    <tr>\\      <th>204</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.084333</td>\\    </tr>\\    <tr>\\      <th>205</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.104000</td>\\    </tr>\\    <tr>\\      <th>206</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.080000</td>\\    </tr>\\    <tr>\\      <th>207</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.082667</td>\\    </tr>\\    <tr>\\      <th>208</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.169000</td>\\    </tr>\\    <tr>\\      <th>209</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.162333</td>\\    </tr>\\    <tr>\\      <th>210</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.166667</td>\\    </tr>\\    <tr>\\      <th>211</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.153333</td>\\    </tr>\\    <tr>\\      <th>212</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.153333</td>\\    </tr>\\    <tr>\\      <th>213</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.187000</td>\\    </tr>\\    <tr>\\      <th>214</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.134333</td>\\    </tr>\\    <tr>\\      <th>215</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.155333</td>\\    </tr>\\    <tr>\\      <th>216</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.156667</td>\\    </tr>\\    <tr>\\      <th>217</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.160333</td>\\    </tr>\\    <tr>\\      <th>218</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.146667</td>\\    </tr>\\    <tr>\\      <th>219</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.135667</td>\\    </tr>\\    <tr>\\      <th>220</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.166667</td>\\    </tr>\\    <tr>\\      <th>221</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.216000</td>\\    </tr>\\    <tr>\\      <th>222</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.148667</td>\\    </tr>\\    <tr>\\      <th>223</th>\\      <td>minkowski</td>\\      <td>5</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.183333</td>\\    </tr>\\    <tr>\\      <th>224</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.069667</td>\\    </tr>\\    <tr>\\      <th>225</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.070667</td>\\    </tr>\\    <tr>\\      <th>226</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.070000</td>\\    </tr>\\    <tr>\\      <th>227</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.065667</td>\\    </tr>\\    <tr>\\      <th>228</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.073667</td>\\    </tr>\\    <tr>\\      <th>229</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.091667</td>\\    </tr>\\    <tr>\\      <th>230</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.069000</td>\\    </tr>\\    <tr>\\      <th>231</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.067000</td>\\    </tr>\\    <tr>\\      <th>232</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.087000</td>\\    </tr>\\    <tr>\\      <th>233</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.085333</td>\\    </tr>\\    <tr>\\      <th>234</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.085667</td>\\    </tr>\\    <tr>\\      <th>235</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.081667</td>\\    </tr>\\    <tr>\\      <th>236</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.086667</td>\\    </tr>\\    <tr>\\      <th>237</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.109667</td>\\    </tr>\\    <tr>\\      <th>238</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.086000</td>\\    </tr>\\    <tr>\\      <th>239</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.081333</td>\\    </tr>\\    <tr>\\      <th>240</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.463333</td>\\    </tr>\\    <tr>\\      <th>241</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.387000</td>\\    </tr>\\    <tr>\\      <th>242</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.440000</td>\\    </tr>\\    <tr>\\      <th>243</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.339333</td>\\    </tr>\\    <tr>\\      <th>244</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.251667</td>\\    </tr>\\    <tr>\\      <th>245</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.197000</td>\\    </tr>\\    <tr>\\      <th>246</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.237000</td>\\    </tr>\\    <tr>\\      <th>247</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.165333</td>\\    </tr>\\    <tr>\\      <th>248</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.447000</td>\\    </tr>\\    <tr>\\      <th>249</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.378333</td>\\    </tr>\\    <tr>\\      <th>250</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.427667</td>\\    </tr>\\    <tr>\\      <th>251</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.325333</td>\\    </tr>\\    <tr>\\      <th>252</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.255000</td>\\    </tr>\\    <tr>\\      <th>253</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.221333</td>\\    </tr>\\    <tr>\\      <th>254</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.242333</td>\\    </tr>\\    <tr>\\      <th>255</th>\\      <td>minkowski</td>\\      <td>7</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.184667</td>\\    </tr>\\    <tr>\\      <th>256</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.064667</td>\\    </tr>\\    <tr>\\      <th>257</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.066667</td>\\    </tr>\\    <tr>\\      <th>258</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.060667</td>\\    </tr>\\    <tr>\\      <th>259</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.056000</td>\\    </tr>\\    <tr>\\      <th>260</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.077333</td>\\    </tr>\\    <tr>\\      <th>261</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.101333</td>\\    </tr>\\    <tr>\\      <th>262</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.063333</td>\\    </tr>\\    <tr>\\      <th>263</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>1</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.059333</td>\\    </tr>\\    <tr>\\      <th>264</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.072667</td>\\    </tr>\\    <tr>\\      <th>265</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.088000</td>\\    </tr>\\    <tr>\\      <th>266</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.072000</td>\\    </tr>\\    <tr>\\      <th>267</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.074000</td>\\    </tr>\\    <tr>\\      <th>268</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.085333</td>\\    </tr>\\    <tr>\\      <th>269</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.123667</td>\\    </tr>\\    <tr>\\      <th>270</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.071333</td>\\    </tr>\\    <tr>\\      <th>271</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>1</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.075333</td>\\    </tr>\\    <tr>\\      <th>272</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.570000</td>\\    </tr>\\    <tr>\\      <th>273</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.470667</td>\\    </tr>\\    <tr>\\      <th>274</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.547667</td>\\    </tr>\\    <tr>\\      <th>275</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.402667</td>\\    </tr>\\    <tr>\\      <th>276</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.301333</td>\\    </tr>\\    <tr>\\      <th>277</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.205667</td>\\    </tr>\\    <tr>\\      <th>278</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.289667</td>\\    </tr>\\    <tr>\\      <th>279</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>2</td>\\      <td>uniform</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.166667</td>\\    </tr>\\    <tr>\\      <th>280</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.563667</td>\\    </tr>\\    <tr>\\      <th>281</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.466000</td>\\    </tr>\\    <tr>\\      <th>282</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.550000</td>\\    </tr>\\    <tr>\\      <th>283</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.397000</td>\\    </tr>\\    <tr>\\      <th>284</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.309333</td>\\    </tr>\\    <tr>\\      <th>285</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.222000</td>\\    </tr>\\    <tr>\\      <th>286</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.304000</td>\\    </tr>\\    <tr>\\      <th>287</th>\\      <td>minkowski</td>\\      <td>11</td>\\      <td>2</td>\\      <td>distance</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.180000</td>\\    </tr>\\  </tbody>\\</table><style>\\    table { border-collapse: collapse; border: 3px solid #eee; }\\    table tr th:first-child { background-color: #eeeeee; color: #333; font-weight: bold }\\    table thead th { background-color: #eee; color: #000; }\\    tr, th, td { border: 1px solid #ccc; border-width: 1px 0 0 1px; border-collapse: collapse;\\    padding: 3px; font-family: monospace; font-size: 10px }</style>\\    ';</script><style>\n",
       "    table { border-collapse: collapse; border: 3px solid #eee; }\n",
       "    table tr th:first-child { background-color: #eeeeee; color: #333; font-weight: bold }\n",
       "    table thead th { background-color: #eee; color: #000; }\n",
       "    tr, th, td { border: 1px solid #ccc; border-width: 1px 0 0 1px; border-collapse: collapse;\n",
       "    padding: 3px; font-family: monospace; font-size: 10px }</style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 96 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=3)]: Done 192 out of 192 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.6s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.0s\n",
      "Search executed in: 127.8036241750001\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "gs_nb = gs_nb.fit(chosen_model[4][:3000], chosen_model[5][:3000])\n",
    "end = timer()\n",
    "print('Search executed in:', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best achieved score: 0.7593333333333333 \n",
      "\n",
      "With these params:\n",
      " {'clf__alpha': 0.1, 'clf__fit_prior': True, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1), 'vect__stop_words': 'english'}\n"
     ]
    }
   ],
   "source": [
    "print('Best achieved score:', gs_nb.best_score_, '\\n')\n",
    "\n",
    "print('With these params:\\n', gs_nb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf__alpha</th>\n",
       "      <th>clf__fit_prior</th>\n",
       "      <th>tfidf__use_idf</th>\n",
       "      <th>vect__ngram_range</th>\n",
       "      <th>vect__stop_words</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.759333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.749333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.676333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.746000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.712333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.718000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.695000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.718000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.689333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    clf__alpha  clf__fit_prior  tfidf__use_idf vect__ngram_range  \\\n",
       "0       0.1000            True            True            (1, 1)   \n",
       "1       0.1000            True            True            (1, 1)   \n",
       "2       0.1000            True            True            (1, 2)   \n",
       "3       0.1000            True            True            (1, 2)   \n",
       "4       0.1000            True            True            (1, 3)   \n",
       "..         ...             ...             ...               ...   \n",
       "91      0.0001           False           False            (1, 1)   \n",
       "92      0.0001           False           False            (1, 2)   \n",
       "93      0.0001           False           False            (1, 2)   \n",
       "94      0.0001           False           False            (1, 3)   \n",
       "95      0.0001           False           False            (1, 3)   \n",
       "\n",
       "   vect__stop_words  Accuracy  \n",
       "0           english  0.759333  \n",
       "1              None  0.720000  \n",
       "2           english  0.749333  \n",
       "3              None  0.676333  \n",
       "4           english  0.746000  \n",
       "..              ...       ...  \n",
       "91             None  0.712333  \n",
       "92          english  0.718000  \n",
       "93             None  0.695000  \n",
       "94          english  0.718000  \n",
       "95             None  0.689333  \n",
       "\n",
       "[96 rows x 6 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.concat([pd.DataFrame(gs_nb.cv_results_[\"params\"]),\n",
    "                 pd.DataFrame(gs_nb.cv_results_[\"mean_test_score\"], \n",
    "                              columns=[\"Accuracy\"])],axis=1)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/Javascript\">var win = window.open(\"\", \"Title\", \"toolbar=no, location=no, directories=no, status=no, menubar=no, scrollbars=yes, resizable=yes, width=780, height=200, top=\"+(screen.height-400)+\", left=\"+(screen.width-840));win.document.body.innerHTML = '<table border=\"1\" class=\"dataframe\">\\  <thead>\\    <tr style=\"text-align: right;\">\\      <th></th>\\      <th>clf__alpha</th>\\      <th>clf__fit_prior</th>\\      <th>tfidf__use_idf</th>\\      <th>vect__ngram_range</th>\\      <th>vect__stop_words</th>\\      <th>Accuracy</th>\\    </tr>\\  </thead>\\  <tbody>\\    <tr>\\      <th>0</th>\\      <td>0.1000</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.759333</td>\\    </tr>\\    <tr>\\      <th>1</th>\\      <td>0.1000</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.720000</td>\\    </tr>\\    <tr>\\      <th>2</th>\\      <td>0.1000</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.749333</td>\\    </tr>\\    <tr>\\      <th>3</th>\\      <td>0.1000</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.676333</td>\\    </tr>\\    <tr>\\      <th>4</th>\\      <td>0.1000</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 3)</td>\\      <td>english</td>\\      <td>0.746000</td>\\    </tr>\\    <tr>\\      <th>5</th>\\      <td>0.1000</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 3)</td>\\      <td>None</td>\\      <td>0.659333</td>\\    </tr>\\    <tr>\\      <th>6</th>\\      <td>0.1000</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.715667</td>\\    </tr>\\    <tr>\\      <th>7</th>\\      <td>0.1000</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.564667</td>\\    </tr>\\    <tr>\\      <th>8</th>\\      <td>0.1000</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.706667</td>\\    </tr>\\    <tr>\\      <th>9</th>\\      <td>0.1000</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.519667</td>\\    </tr>\\    <tr>\\      <th>10</th>\\      <td>0.1000</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 3)</td>\\      <td>english</td>\\      <td>0.702333</td>\\    </tr>\\    <tr>\\      <th>11</th>\\      <td>0.1000</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 3)</td>\\      <td>None</td>\\      <td>0.494667</td>\\    </tr>\\    <tr>\\      <th>12</th>\\      <td>0.1000</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.759000</td>\\    </tr>\\    <tr>\\      <th>13</th>\\      <td>0.1000</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.728000</td>\\    </tr>\\    <tr>\\      <th>14</th>\\      <td>0.1000</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.749667</td>\\    </tr>\\    <tr>\\      <th>15</th>\\      <td>0.1000</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.684667</td>\\    </tr>\\    <tr>\\      <th>16</th>\\      <td>0.1000</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 3)</td>\\      <td>english</td>\\      <td>0.747333</td>\\    </tr>\\    <tr>\\      <th>17</th>\\      <td>0.1000</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 3)</td>\\      <td>None</td>\\      <td>0.665667</td>\\    </tr>\\    <tr>\\      <th>18</th>\\      <td>0.1000</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.728000</td>\\    </tr>\\    <tr>\\      <th>19</th>\\      <td>0.1000</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.583333</td>\\    </tr>\\    <tr>\\      <th>20</th>\\      <td>0.1000</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.713667</td>\\    </tr>\\    <tr>\\      <th>21</th>\\      <td>0.1000</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.537667</td>\\    </tr>\\    <tr>\\      <th>22</th>\\      <td>0.1000</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 3)</td>\\      <td>english</td>\\      <td>0.706333</td>\\    </tr>\\    <tr>\\      <th>23</th>\\      <td>0.1000</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 3)</td>\\      <td>None</td>\\      <td>0.514667</td>\\    </tr>\\    <tr>\\      <th>24</th>\\      <td>0.0100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.757000</td>\\    </tr>\\    <tr>\\      <th>25</th>\\      <td>0.0100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.756667</td>\\    </tr>\\    <tr>\\      <th>26</th>\\      <td>0.0100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.751000</td>\\    </tr>\\    <tr>\\      <th>27</th>\\      <td>0.0100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.725667</td>\\    </tr>\\    <tr>\\      <th>28</th>\\      <td>0.0100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 3)</td>\\      <td>english</td>\\      <td>0.746000</td>\\    </tr>\\    <tr>\\      <th>29</th>\\      <td>0.0100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 3)</td>\\      <td>None</td>\\      <td>0.710333</td>\\    </tr>\\    <tr>\\      <th>30</th>\\      <td>0.0100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.747333</td>\\    </tr>\\    <tr>\\      <th>31</th>\\      <td>0.0100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.723333</td>\\    </tr>\\    <tr>\\      <th>32</th>\\      <td>0.0100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.739667</td>\\    </tr>\\    <tr>\\      <th>33</th>\\      <td>0.0100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.676667</td>\\    </tr>\\    <tr>\\      <th>34</th>\\      <td>0.0100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 3)</td>\\      <td>english</td>\\      <td>0.737667</td>\\    </tr>\\    <tr>\\      <th>35</th>\\      <td>0.0100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 3)</td>\\      <td>None</td>\\      <td>0.656333</td>\\    </tr>\\    <tr>\\      <th>36</th>\\      <td>0.0100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.755667</td>\\    </tr>\\    <tr>\\      <th>37</th>\\      <td>0.0100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.754667</td>\\    </tr>\\    <tr>\\      <th>38</th>\\      <td>0.0100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.749000</td>\\    </tr>\\    <tr>\\      <th>39</th>\\      <td>0.0100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.725000</td>\\    </tr>\\    <tr>\\      <th>40</th>\\      <td>0.0100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 3)</td>\\      <td>english</td>\\      <td>0.745333</td>\\    </tr>\\    <tr>\\      <th>41</th>\\      <td>0.0100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 3)</td>\\      <td>None</td>\\      <td>0.710667</td>\\    </tr>\\    <tr>\\      <th>42</th>\\      <td>0.0100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.746000</td>\\    </tr>\\    <tr>\\      <th>43</th>\\      <td>0.0100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.732333</td>\\    </tr>\\    <tr>\\      <th>44</th>\\      <td>0.0100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.741667</td>\\    </tr>\\    <tr>\\      <th>45</th>\\      <td>0.0100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.680667</td>\\    </tr>\\    <tr>\\      <th>46</th>\\      <td>0.0100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 3)</td>\\      <td>english</td>\\      <td>0.737667</td>\\    </tr>\\    <tr>\\      <th>47</th>\\      <td>0.0100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 3)</td>\\      <td>None</td>\\      <td>0.660000</td>\\    </tr>\\    <tr>\\      <th>48</th>\\      <td>0.0010</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.738000</td>\\    </tr>\\    <tr>\\      <th>49</th>\\      <td>0.0010</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.739333</td>\\    </tr>\\    <tr>\\      <th>50</th>\\      <td>0.0010</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.745000</td>\\    </tr>\\    <tr>\\      <th>51</th>\\      <td>0.0010</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.730000</td>\\    </tr>\\    <tr>\\      <th>52</th>\\      <td>0.0010</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 3)</td>\\      <td>english</td>\\      <td>0.740333</td>\\    </tr>\\    <tr>\\      <th>53</th>\\      <td>0.0010</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 3)</td>\\      <td>None</td>\\      <td>0.715333</td>\\    </tr>\\    <tr>\\      <th>54</th>\\      <td>0.0010</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.732667</td>\\    </tr>\\    <tr>\\      <th>55</th>\\      <td>0.0010</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.733333</td>\\    </tr>\\    <tr>\\      <th>56</th>\\      <td>0.0010</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.734333</td>\\    </tr>\\    <tr>\\      <th>57</th>\\      <td>0.0010</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.711667</td>\\    </tr>\\    <tr>\\      <th>58</th>\\      <td>0.0010</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 3)</td>\\      <td>english</td>\\      <td>0.730333</td>\\    </tr>\\    <tr>\\      <th>59</th>\\      <td>0.0010</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 3)</td>\\      <td>None</td>\\      <td>0.700000</td>\\    </tr>\\    <tr>\\      <th>60</th>\\      <td>0.0010</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.737333</td>\\    </tr>\\    <tr>\\      <th>61</th>\\      <td>0.0010</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.738333</td>\\    </tr>\\    <tr>\\      <th>62</th>\\      <td>0.0010</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.743333</td>\\    </tr>\\    <tr>\\      <th>63</th>\\      <td>0.0010</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.725333</td>\\    </tr>\\    <tr>\\      <th>64</th>\\      <td>0.0010</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 3)</td>\\      <td>english</td>\\      <td>0.739333</td>\\    </tr>\\    <tr>\\      <th>65</th>\\      <td>0.0010</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 3)</td>\\      <td>None</td>\\      <td>0.715667</td>\\    </tr>\\    <tr>\\      <th>66</th>\\      <td>0.0010</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.732333</td>\\    </tr>\\    <tr>\\      <th>67</th>\\      <td>0.0010</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.734000</td>\\    </tr>\\    <tr>\\      <th>68</th>\\      <td>0.0010</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.733000</td>\\    </tr>\\    <tr>\\      <th>69</th>\\      <td>0.0010</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.712000</td>\\    </tr>\\    <tr>\\      <th>70</th>\\      <td>0.0010</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 3)</td>\\      <td>english</td>\\      <td>0.729333</td>\\    </tr>\\    <tr>\\      <th>71</th>\\      <td>0.0010</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 3)</td>\\      <td>None</td>\\      <td>0.698333</td>\\    </tr>\\    <tr>\\      <th>72</th>\\      <td>0.0001</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.718000</td>\\    </tr>\\    <tr>\\      <th>73</th>\\      <td>0.0001</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.719333</td>\\    </tr>\\    <tr>\\      <th>74</th>\\      <td>0.0001</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.730000</td>\\    </tr>\\    <tr>\\      <th>75</th>\\      <td>0.0001</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.710000</td>\\    </tr>\\    <tr>\\      <th>76</th>\\      <td>0.0001</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 3)</td>\\      <td>english</td>\\      <td>0.727000</td>\\    </tr>\\    <tr>\\      <th>77</th>\\      <td>0.0001</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 3)</td>\\      <td>None</td>\\      <td>0.698000</td>\\    </tr>\\    <tr>\\      <th>78</th>\\      <td>0.0001</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.712667</td>\\    </tr>\\    <tr>\\      <th>79</th>\\      <td>0.0001</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.716667</td>\\    </tr>\\    <tr>\\      <th>80</th>\\      <td>0.0001</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.719333</td>\\    </tr>\\    <tr>\\      <th>81</th>\\      <td>0.0001</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.696000</td>\\    </tr>\\    <tr>\\      <th>82</th>\\      <td>0.0001</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 3)</td>\\      <td>english</td>\\      <td>0.719667</td>\\    </tr>\\    <tr>\\      <th>83</th>\\      <td>0.0001</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 3)</td>\\      <td>None</td>\\      <td>0.691000</td>\\    </tr>\\    <tr>\\      <th>84</th>\\      <td>0.0001</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.716667</td>\\    </tr>\\    <tr>\\      <th>85</th>\\      <td>0.0001</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.717333</td>\\    </tr>\\    <tr>\\      <th>86</th>\\      <td>0.0001</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.727333</td>\\    </tr>\\    <tr>\\      <th>87</th>\\      <td>0.0001</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.707667</td>\\    </tr>\\    <tr>\\      <th>88</th>\\      <td>0.0001</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 3)</td>\\      <td>english</td>\\      <td>0.724667</td>\\    </tr>\\    <tr>\\      <th>89</th>\\      <td>0.0001</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 3)</td>\\      <td>None</td>\\      <td>0.697000</td>\\    </tr>\\    <tr>\\      <th>90</th>\\      <td>0.0001</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.711333</td>\\    </tr>\\    <tr>\\      <th>91</th>\\      <td>0.0001</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.712333</td>\\    </tr>\\    <tr>\\      <th>92</th>\\      <td>0.0001</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.718000</td>\\    </tr>\\    <tr>\\      <th>93</th>\\      <td>0.0001</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.695000</td>\\    </tr>\\    <tr>\\      <th>94</th>\\      <td>0.0001</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 3)</td>\\      <td>english</td>\\      <td>0.718000</td>\\    </tr>\\    <tr>\\      <th>95</th>\\      <td>0.0001</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 3)</td>\\      <td>None</td>\\      <td>0.689333</td>\\    </tr>\\  </tbody>\\</table><style>\\    table { border-collapse: collapse; border: 3px solid #eee; }\\    table tr th:first-child { background-color: #eeeeee; color: #333; font-weight: bold }\\    table thead th { background-color: #eee; color: #000; }\\    tr, th, td { border: 1px solid #ccc; border-width: 1px 0 0 1px; border-collapse: collapse;\\    padding: 3px; font-family: monospace; font-size: 10px }</style>\\    ';</script><style>\n",
       "    table { border-collapse: collapse; border: 3px solid #eee; }\n",
       "    table tr th:first-child { background-color: #eeeeee; color: #333; font-weight: bold }\n",
       "    table thead th { background-color: #eee; color: #000; }\n",
       "    tr, th, td { border: 1px solid #ccc; border-width: 1px 0 0 1px; border-collapse: collapse;\n",
       "    padding: 3px; font-family: monospace; font-size: 10px }</style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1152 candidates, totalling 2304 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  15.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  16.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  11.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  12.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  14.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   9.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  12.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  12.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  16.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  12.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  11.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  14.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.4s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  12.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  11.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  11.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  11.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  11.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  15.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  16.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  12.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  15.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  11.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  14.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  16.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  14.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  14.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  16.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  14.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  11.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  12.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  14.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.4s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.4s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  11.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  15.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   9.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  12.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  16.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  14.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  16.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  11.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  14.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  14.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  15.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   9.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  12.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  15.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  12.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   9.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  11.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  12.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  11.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.4s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   9.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   9.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   9.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.4s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   9.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  12.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  17.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  14.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  19.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  14.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  16.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  15.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  18.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  17.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  15.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  18.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  15.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  17.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   9.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  11.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  11.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   9.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:586: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  14.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.4s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   9.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  11.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   9.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  14.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  12.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  11.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  14.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.4s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.4s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  11.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  14.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  16.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  11.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  12.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  16.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  12.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  11.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  14.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  12.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  16.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   9.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  12.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   9.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   9.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  11.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   9.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   9.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  12.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  11.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 228, in fit\n",
      "    raise ValueError(\"min_samples_split must be an integer \"\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.4s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  15.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  16.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  14.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  16.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  16.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  14.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  16.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.4s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   2.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.3s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   2.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   2.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.4s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   9.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   7.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.5s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  21.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   3.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.3s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.2s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  23.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   7.5s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.3s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   2.5s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   2.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   5.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   2.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   7.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  11.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  12.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  15.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.4s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  10.5s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  11.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  11.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  15.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.7s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  11.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  12.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  15.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.6s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   3.9s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  11.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  13.8s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  12.4s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  16.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2304 out of 2304 | elapsed: 485.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   1.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  41.0s\n",
      "Search executed in: 8434.38369184\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "gs_rf = gs_rf.fit(chosen_model[4][:3000], chosen_model[5][:3000])\n",
    "end = timer()\n",
    "print('Search executed in:', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best achieved score: 0.6753333333333333 \n",
      "\n",
      "With these params:\n",
      " {'clf__class_weight': 'balanced_subsample', 'clf__criterion': 'gini', 'clf__min_samples_split': 3, 'clf__n_estimators': 200, 'clf__warm_start': False, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2), 'vect__stop_words': 'english'}\n"
     ]
    }
   ],
   "source": [
    "print('Best achieved score:', gs_rf.best_score_, '\\n')\n",
    "\n",
    "print('With these params:\\n', gs_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf__class_weight</th>\n",
       "      <th>clf__criterion</th>\n",
       "      <th>clf__min_samples_split</th>\n",
       "      <th>clf__n_estimators</th>\n",
       "      <th>clf__warm_start</th>\n",
       "      <th>tfidf__use_idf</th>\n",
       "      <th>vect__ngram_range</th>\n",
       "      <th>vect__stop_words</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>english</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.438667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.556667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.473333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>english</td>\n",
       "      <td>0.555667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>0.431000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1152 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     clf__class_weight clf__criterion  clf__min_samples_split  \\\n",
       "0             balanced           gini                       1   \n",
       "1             balanced           gini                       1   \n",
       "2             balanced           gini                       1   \n",
       "3             balanced           gini                       1   \n",
       "4             balanced           gini                       1   \n",
       "...                ...            ...                     ...   \n",
       "1147              None        entropy                       3   \n",
       "1148              None        entropy                       3   \n",
       "1149              None        entropy                       3   \n",
       "1150              None        entropy                       3   \n",
       "1151              None        entropy                       3   \n",
       "\n",
       "      clf__n_estimators  clf__warm_start  tfidf__use_idf vect__ngram_range  \\\n",
       "0                    20             True            True            (1, 1)   \n",
       "1                    20             True            True            (1, 1)   \n",
       "2                    20             True            True            (1, 2)   \n",
       "3                    20             True            True            (1, 2)   \n",
       "4                    20             True           False            (1, 1)   \n",
       "...                 ...              ...             ...               ...   \n",
       "1147                200            False            True            (1, 2)   \n",
       "1148                200            False           False            (1, 1)   \n",
       "1149                200            False           False            (1, 1)   \n",
       "1150                200            False           False            (1, 2)   \n",
       "1151                200            False           False            (1, 2)   \n",
       "\n",
       "     vect__stop_words  Accuracy  \n",
       "0             english       NaN  \n",
       "1                None       NaN  \n",
       "2             english       NaN  \n",
       "3                None       NaN  \n",
       "4             english       NaN  \n",
       "...               ...       ...  \n",
       "1147             None  0.438667  \n",
       "1148          english  0.556667  \n",
       "1149             None  0.473333  \n",
       "1150          english  0.555667  \n",
       "1151             None  0.431000  \n",
       "\n",
       "[1152 rows x 9 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.concat([pd.DataFrame(gs_rf.cv_results_[\"params\"]),\n",
    "                 pd.DataFrame(gs_rf.cv_results_[\"mean_test_score\"], \n",
    "                              columns=[\"Accuracy\"])],axis=1)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/Javascript\">var win = window.open(\"\", \"Title\", \"toolbar=no, location=no, directories=no, status=no, menubar=no, scrollbars=yes, resizable=yes, width=780, height=200, top=\"+(screen.height-400)+\", left=\"+(screen.width-840));win.document.body.innerHTML = '<table border=\"1\" class=\"dataframe\">\\  <thead>\\    <tr style=\"text-align: right;\">\\      <th></th>\\      <th>clf__class_weight</th>\\      <th>clf__criterion</th>\\      <th>clf__min_samples_split</th>\\      <th>clf__n_estimators</th>\\      <th>clf__warm_start</th>\\      <th>tfidf__use_idf</th>\\      <th>vect__ngram_range</th>\\      <th>vect__stop_words</th>\\      <th>Accuracy</th>\\    </tr>\\  </thead>\\  <tbody>\\    <tr>\\      <th>0</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>1</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>2</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>3</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>4</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>5</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>6</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>7</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>8</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>9</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>10</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>11</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>12</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>13</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>14</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>15</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>16</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>17</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>18</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>19</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>20</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>21</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>22</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>23</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>24</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>25</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>26</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>27</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>28</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>29</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>30</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>31</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>32</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>33</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>34</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>35</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>36</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>37</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>38</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>39</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>40</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>41</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>42</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>43</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>44</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>45</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>46</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>47</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>48</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>49</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>50</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>51</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>52</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>53</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>54</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>55</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>56</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>57</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>58</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>59</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>60</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>61</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>62</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>63</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>64</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.556667</td>\\    </tr>\\    <tr>\\      <th>65</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.485333</td>\\    </tr>\\    <tr>\\      <th>66</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.537333</td>\\    </tr>\\    <tr>\\      <th>67</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.444667</td>\\    </tr>\\    <tr>\\      <th>68</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.571000</td>\\    </tr>\\    <tr>\\      <th>69</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.485333</td>\\    </tr>\\    <tr>\\      <th>70</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.531000</td>\\    </tr>\\    <tr>\\      <th>71</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.456667</td>\\    </tr>\\    <tr>\\      <th>72</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.573667</td>\\    </tr>\\    <tr>\\      <th>73</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.480667</td>\\    </tr>\\    <tr>\\      <th>74</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.523000</td>\\    </tr>\\    <tr>\\      <th>75</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.459000</td>\\    </tr>\\    <tr>\\      <th>76</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.563667</td>\\    </tr>\\    <tr>\\      <th>77</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.464333</td>\\    </tr>\\    <tr>\\      <th>78</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.535000</td>\\    </tr>\\    <tr>\\      <th>79</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.461000</td>\\    </tr>\\    <tr>\\      <th>80</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.616000</td>\\    </tr>\\    <tr>\\      <th>81</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.588000</td>\\    </tr>\\    <tr>\\      <th>82</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.606000</td>\\    </tr>\\    <tr>\\      <th>83</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.548667</td>\\    </tr>\\    <tr>\\      <th>84</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.620000</td>\\    </tr>\\    <tr>\\      <th>85</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.579667</td>\\    </tr>\\    <tr>\\      <th>86</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.602333</td>\\    </tr>\\    <tr>\\      <th>87</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.557000</td>\\    </tr>\\    <tr>\\      <th>88</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.615333</td>\\    </tr>\\    <tr>\\      <th>89</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.562667</td>\\    </tr>\\    <tr>\\      <th>90</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.603667</td>\\    </tr>\\    <tr>\\      <th>91</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.545333</td>\\    </tr>\\    <tr>\\      <th>92</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.607667</td>\\    </tr>\\    <tr>\\      <th>93</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.578000</td>\\    </tr>\\    <tr>\\      <th>94</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.600333</td>\\    </tr>\\    <tr>\\      <th>95</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.538667</td>\\    </tr>\\    <tr>\\      <th>96</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.640333</td>\\    </tr>\\    <tr>\\      <th>97</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.622333</td>\\    </tr>\\    <tr>\\      <th>98</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.643667</td>\\    </tr>\\    <tr>\\      <th>99</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.602000</td>\\    </tr>\\    <tr>\\      <th>100</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.638333</td>\\    </tr>\\    <tr>\\      <th>101</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.623667</td>\\    </tr>\\    <tr>\\      <th>102</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.638667</td>\\    </tr>\\    <tr>\\      <th>103</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.594667</td>\\    </tr>\\    <tr>\\      <th>104</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.632000</td>\\    </tr>\\    <tr>\\      <th>105</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.616333</td>\\    </tr>\\    <tr>\\      <th>106</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.637333</td>\\    </tr>\\    <tr>\\      <th>107</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.599333</td>\\    </tr>\\    <tr>\\      <th>108</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.646000</td>\\    </tr>\\    <tr>\\      <th>109</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.627333</td>\\    </tr>\\    <tr>\\      <th>110</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.635333</td>\\    </tr>\\    <tr>\\      <th>111</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.593000</td>\\    </tr>\\    <tr>\\      <th>112</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.650000</td>\\    </tr>\\    <tr>\\      <th>113</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.635333</td>\\    </tr>\\    <tr>\\      <th>114</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.655000</td>\\    </tr>\\    <tr>\\      <th>115</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.634000</td>\\    </tr>\\    <tr>\\      <th>116</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.653333</td>\\    </tr>\\    <tr>\\      <th>117</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.649333</td>\\    </tr>\\    <tr>\\      <th>118</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.640333</td>\\    </tr>\\    <tr>\\      <th>119</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.618667</td>\\    </tr>\\    <tr>\\      <th>120</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.651667</td>\\    </tr>\\    <tr>\\      <th>121</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.643000</td>\\    </tr>\\    <tr>\\      <th>122</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.652667</td>\\    </tr>\\    <tr>\\      <th>123</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.625667</td>\\    </tr>\\    <tr>\\      <th>124</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.659333</td>\\    </tr>\\    <tr>\\      <th>125</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.640333</td>\\    </tr>\\    <tr>\\      <th>126</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.659333</td>\\    </tr>\\    <tr>\\      <th>127</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.616333</td>\\    </tr>\\    <tr>\\      <th>128</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.597000</td>\\    </tr>\\    <tr>\\      <th>129</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.496667</td>\\    </tr>\\    <tr>\\      <th>130</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.560667</td>\\    </tr>\\    <tr>\\      <th>131</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.503333</td>\\    </tr>\\    <tr>\\      <th>132</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.585333</td>\\    </tr>\\    <tr>\\      <th>133</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.510000</td>\\    </tr>\\    <tr>\\      <th>134</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.568667</td>\\    </tr>\\    <tr>\\      <th>135</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.490333</td>\\    </tr>\\    <tr>\\      <th>136</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.587000</td>\\    </tr>\\    <tr>\\      <th>137</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.508667</td>\\    </tr>\\    <tr>\\      <th>138</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.554667</td>\\    </tr>\\    <tr>\\      <th>139</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.481000</td>\\    </tr>\\    <tr>\\      <th>140</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.581667</td>\\    </tr>\\    <tr>\\      <th>141</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.494000</td>\\    </tr>\\    <tr>\\      <th>142</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.566000</td>\\    </tr>\\    <tr>\\      <th>143</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.472000</td>\\    </tr>\\    <tr>\\      <th>144</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.633333</td>\\    </tr>\\    <tr>\\      <th>145</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.605667</td>\\    </tr>\\    <tr>\\      <th>146</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.621000</td>\\    </tr>\\    <tr>\\      <th>147</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.577000</td>\\    </tr>\\    <tr>\\      <th>148</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.640667</td>\\    </tr>\\    <tr>\\      <th>149</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.606000</td>\\    </tr>\\    <tr>\\      <th>150</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.615667</td>\\    </tr>\\    <tr>\\      <th>151</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.576000</td>\\    </tr>\\    <tr>\\      <th>152</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.634333</td>\\    </tr>\\    <tr>\\      <th>153</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.599333</td>\\    </tr>\\    <tr>\\      <th>154</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.629000</td>\\    </tr>\\    <tr>\\      <th>155</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.572667</td>\\    </tr>\\    <tr>\\      <th>156</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.628000</td>\\    </tr>\\    <tr>\\      <th>157</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.600333</td>\\    </tr>\\    <tr>\\      <th>158</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.617000</td>\\    </tr>\\    <tr>\\      <th>159</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.569000</td>\\    </tr>\\    <tr>\\      <th>160</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.645667</td>\\    </tr>\\    <tr>\\      <th>161</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.621333</td>\\    </tr>\\    <tr>\\      <th>162</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.648667</td>\\    </tr>\\    <tr>\\      <th>163</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.609333</td>\\    </tr>\\    <tr>\\      <th>164</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.647667</td>\\    </tr>\\    <tr>\\      <th>165</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.633667</td>\\    </tr>\\    <tr>\\      <th>166</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.639000</td>\\    </tr>\\    <tr>\\      <th>167</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.616000</td>\\    </tr>\\    <tr>\\      <th>168</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.656667</td>\\    </tr>\\    <tr>\\      <th>169</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.628333</td>\\    </tr>\\    <tr>\\      <th>170</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.654000</td>\\    </tr>\\    <tr>\\      <th>171</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.609667</td>\\    </tr>\\    <tr>\\      <th>172</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.648333</td>\\    </tr>\\    <tr>\\      <th>173</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.629667</td>\\    </tr>\\    <tr>\\      <th>174</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.655667</td>\\    </tr>\\    <tr>\\      <th>175</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.604667</td>\\    </tr>\\    <tr>\\      <th>176</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.663000</td>\\    </tr>\\    <tr>\\      <th>177</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.648667</td>\\    </tr>\\    <tr>\\      <th>178</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.657000</td>\\    </tr>\\    <tr>\\      <th>179</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.635000</td>\\    </tr>\\    <tr>\\      <th>180</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.665667</td>\\    </tr>\\    <tr>\\      <th>181</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.657333</td>\\    </tr>\\    <tr>\\      <th>182</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.661667</td>\\    </tr>\\    <tr>\\      <th>183</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.644000</td>\\    </tr>\\    <tr>\\      <th>184</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.665333</td>\\    </tr>\\    <tr>\\      <th>185</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.652667</td>\\    </tr>\\    <tr>\\      <th>186</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.660333</td>\\    </tr>\\    <tr>\\      <th>187</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.637333</td>\\    </tr>\\    <tr>\\      <th>188</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.657667</td>\\    </tr>\\    <tr>\\      <th>189</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.653333</td>\\    </tr>\\    <tr>\\      <th>190</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.662667</td>\\    </tr>\\    <tr>\\      <th>191</th>\\      <td>balanced</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.637667</td>\\    </tr>\\    <tr>\\      <th>192</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>193</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>194</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>195</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>196</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>197</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>198</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>199</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>200</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>201</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>202</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>203</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>204</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>205</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>206</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>207</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>208</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>209</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>210</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>211</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>212</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>213</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>214</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>215</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>216</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>217</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>218</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>219</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>220</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>221</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>222</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>223</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>224</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>225</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>226</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>227</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>228</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>229</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>230</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>231</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>232</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>233</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>234</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>235</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>236</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>237</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>238</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>239</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>240</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>241</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>242</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>243</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>244</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>245</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>246</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>247</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>248</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>249</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>250</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>251</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>252</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>253</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>254</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>255</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>256</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.364667</td>\\    </tr>\\    <tr>\\      <th>257</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.245667</td>\\    </tr>\\    <tr>\\      <th>258</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.319667</td>\\    </tr>\\    <tr>\\      <th>259</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.222000</td>\\    </tr>\\    <tr>\\      <th>260</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.359000</td>\\    </tr>\\    <tr>\\      <th>261</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.247333</td>\\    </tr>\\    <tr>\\      <th>262</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.313000</td>\\    </tr>\\    <tr>\\      <th>263</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.232667</td>\\    </tr>\\    <tr>\\      <th>264</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.358333</td>\\    </tr>\\    <tr>\\      <th>265</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.253000</td>\\    </tr>\\    <tr>\\      <th>266</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.342333</td>\\    </tr>\\    <tr>\\      <th>267</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.245667</td>\\    </tr>\\    <tr>\\      <th>268</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.351333</td>\\    </tr>\\    <tr>\\      <th>269</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.236333</td>\\    </tr>\\    <tr>\\      <th>270</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.333333</td>\\    </tr>\\    <tr>\\      <th>271</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.226000</td>\\    </tr>\\    <tr>\\      <th>272</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.458000</td>\\    </tr>\\    <tr>\\      <th>273</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.350667</td>\\    </tr>\\    <tr>\\      <th>274</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.424000</td>\\    </tr>\\    <tr>\\      <th>275</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.306667</td>\\    </tr>\\    <tr>\\      <th>276</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.453000</td>\\    </tr>\\    <tr>\\      <th>277</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.336333</td>\\    </tr>\\    <tr>\\      <th>278</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.448333</td>\\    </tr>\\    <tr>\\      <th>279</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.304000</td>\\    </tr>\\    <tr>\\      <th>280</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.464000</td>\\    </tr>\\    <tr>\\      <th>281</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.329000</td>\\    </tr>\\    <tr>\\      <th>282</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.422667</td>\\    </tr>\\    <tr>\\      <th>283</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.291333</td>\\    </tr>\\    <tr>\\      <th>284</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.460333</td>\\    </tr>\\    <tr>\\      <th>285</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.330667</td>\\    </tr>\\    <tr>\\      <th>286</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.417333</td>\\    </tr>\\    <tr>\\      <th>287</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.313000</td>\\    </tr>\\    <tr>\\      <th>288</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.511000</td>\\    </tr>\\    <tr>\\      <th>289</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.393667</td>\\    </tr>\\    <tr>\\      <th>290</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.480333</td>\\    </tr>\\    <tr>\\      <th>291</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.381667</td>\\    </tr>\\    <tr>\\      <th>292</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.516667</td>\\    </tr>\\    <tr>\\      <th>293</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.398667</td>\\    </tr>\\    <tr>\\      <th>294</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.488667</td>\\    </tr>\\    <tr>\\      <th>295</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.377000</td>\\    </tr>\\    <tr>\\      <th>296</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.506333</td>\\    </tr>\\    <tr>\\      <th>297</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.416667</td>\\    </tr>\\    <tr>\\      <th>298</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.483667</td>\\    </tr>\\    <tr>\\      <th>299</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.378667</td>\\    </tr>\\    <tr>\\      <th>300</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.499000</td>\\    </tr>\\    <tr>\\      <th>301</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.390000</td>\\    </tr>\\    <tr>\\      <th>302</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.478333</td>\\    </tr>\\    <tr>\\      <th>303</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.388667</td>\\    </tr>\\    <tr>\\      <th>304</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.546333</td>\\    </tr>\\    <tr>\\      <th>305</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.447000</td>\\    </tr>\\    <tr>\\      <th>306</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.525333</td>\\    </tr>\\    <tr>\\      <th>307</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.440333</td>\\    </tr>\\    <tr>\\      <th>308</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.544667</td>\\    </tr>\\    <tr>\\      <th>309</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.444667</td>\\    </tr>\\    <tr>\\      <th>310</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.524333</td>\\    </tr>\\    <tr>\\      <th>311</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.422000</td>\\    </tr>\\    <tr>\\      <th>312</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.536667</td>\\    </tr>\\    <tr>\\      <th>313</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.451000</td>\\    </tr>\\    <tr>\\      <th>314</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.524667</td>\\    </tr>\\    <tr>\\      <th>315</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.422000</td>\\    </tr>\\    <tr>\\      <th>316</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.537000</td>\\    </tr>\\    <tr>\\      <th>317</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.433667</td>\\    </tr>\\    <tr>\\      <th>318</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.521000</td>\\    </tr>\\    <tr>\\      <th>319</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.426667</td>\\    </tr>\\    <tr>\\      <th>320</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.394000</td>\\    </tr>\\    <tr>\\      <th>321</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.278667</td>\\    </tr>\\    <tr>\\      <th>322</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.360667</td>\\    </tr>\\    <tr>\\      <th>323</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.258667</td>\\    </tr>\\    <tr>\\      <th>324</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.392333</td>\\    </tr>\\    <tr>\\      <th>325</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.267000</td>\\    </tr>\\    <tr>\\      <th>326</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.394333</td>\\    </tr>\\    <tr>\\      <th>327</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.264000</td>\\    </tr>\\    <tr>\\      <th>328</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.406667</td>\\    </tr>\\    <tr>\\      <th>329</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.275000</td>\\    </tr>\\    <tr>\\      <th>330</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.367333</td>\\    </tr>\\    <tr>\\      <th>331</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.264333</td>\\    </tr>\\    <tr>\\      <th>332</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.374667</td>\\    </tr>\\    <tr>\\      <th>333</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.282000</td>\\    </tr>\\    <tr>\\      <th>334</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.373000</td>\\    </tr>\\    <tr>\\      <th>335</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.259000</td>\\    </tr>\\    <tr>\\      <th>336</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.474000</td>\\    </tr>\\    <tr>\\      <th>337</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.382333</td>\\    </tr>\\    <tr>\\      <th>338</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.467000</td>\\    </tr>\\    <tr>\\      <th>339</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.348667</td>\\    </tr>\\    <tr>\\      <th>340</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.487667</td>\\    </tr>\\    <tr>\\      <th>341</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.367000</td>\\    </tr>\\    <tr>\\      <th>342</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.473000</td>\\    </tr>\\    <tr>\\      <th>343</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.344333</td>\\    </tr>\\    <tr>\\      <th>344</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.483000</td>\\    </tr>\\    <tr>\\      <th>345</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.361667</td>\\    </tr>\\    <tr>\\      <th>346</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.473667</td>\\    </tr>\\    <tr>\\      <th>347</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.352000</td>\\    </tr>\\    <tr>\\      <th>348</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.474333</td>\\    </tr>\\    <tr>\\      <th>349</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.345333</td>\\    </tr>\\    <tr>\\      <th>350</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.460333</td>\\    </tr>\\    <tr>\\      <th>351</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.335667</td>\\    </tr>\\    <tr>\\      <th>352</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.528667</td>\\    </tr>\\    <tr>\\      <th>353</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.414000</td>\\    </tr>\\    <tr>\\      <th>354</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.522000</td>\\    </tr>\\    <tr>\\      <th>355</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.411667</td>\\    </tr>\\    <tr>\\      <th>356</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.526667</td>\\    </tr>\\    <tr>\\      <th>357</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.420667</td>\\    </tr>\\    <tr>\\      <th>358</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.503000</td>\\    </tr>\\    <tr>\\      <th>359</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.404000</td>\\    </tr>\\    <tr>\\      <th>360</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.536333</td>\\    </tr>\\    <tr>\\      <th>361</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.419000</td>\\    </tr>\\    <tr>\\      <th>362</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.517333</td>\\    </tr>\\    <tr>\\      <th>363</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.401667</td>\\    </tr>\\    <tr>\\      <th>364</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.515000</td>\\    </tr>\\    <tr>\\      <th>365</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.433333</td>\\    </tr>\\    <tr>\\      <th>366</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.511000</td>\\    </tr>\\    <tr>\\      <th>367</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.402333</td>\\    </tr>\\    <tr>\\      <th>368</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.565667</td>\\    </tr>\\    <tr>\\      <th>369</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.466000</td>\\    </tr>\\    <tr>\\      <th>370</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.553667</td>\\    </tr>\\    <tr>\\      <th>371</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.450667</td>\\    </tr>\\    <tr>\\      <th>372</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.555667</td>\\    </tr>\\    <tr>\\      <th>373</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.473333</td>\\    </tr>\\    <tr>\\      <th>374</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.545000</td>\\    </tr>\\    <tr>\\      <th>375</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.451000</td>\\    </tr>\\    <tr>\\      <th>376</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.551000</td>\\    </tr>\\    <tr>\\      <th>377</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.467000</td>\\    </tr>\\    <tr>\\      <th>378</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.549667</td>\\    </tr>\\    <tr>\\      <th>379</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.452000</td>\\    </tr>\\    <tr>\\      <th>380</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.546000</td>\\    </tr>\\    <tr>\\      <th>381</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.476667</td>\\    </tr>\\    <tr>\\      <th>382</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.550333</td>\\    </tr>\\    <tr>\\      <th>383</th>\\      <td>balanced</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.452000</td>\\    </tr>\\    <tr>\\      <th>384</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>385</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>386</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>387</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>388</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>389</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>390</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>391</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>392</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>393</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>394</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>395</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>396</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>397</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>398</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>399</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>400</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>401</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>402</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>403</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>404</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>405</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>406</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>407</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>408</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>409</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>410</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>411</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>412</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>413</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>414</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>415</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>416</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>417</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>418</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>419</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>420</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>421</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>422</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>423</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>424</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>425</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>426</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>427</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>428</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>429</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>430</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>431</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>432</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>433</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>434</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>435</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>436</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>437</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>438</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>439</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>440</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>441</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>442</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>443</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>444</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>445</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>446</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>447</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>448</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.568000</td>\\    </tr>\\    <tr>\\      <th>449</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.493333</td>\\    </tr>\\    <tr>\\      <th>450</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.545667</td>\\    </tr>\\    <tr>\\      <th>451</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.461667</td>\\    </tr>\\    <tr>\\      <th>452</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.572333</td>\\    </tr>\\    <tr>\\      <th>453</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.518333</td>\\    </tr>\\    <tr>\\      <th>454</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.512333</td>\\    </tr>\\    <tr>\\      <th>455</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.453000</td>\\    </tr>\\    <tr>\\      <th>456</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.563667</td>\\    </tr>\\    <tr>\\      <th>457</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.488000</td>\\    </tr>\\    <tr>\\      <th>458</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.528000</td>\\    </tr>\\    <tr>\\      <th>459</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.481667</td>\\    </tr>\\    <tr>\\      <th>460</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.556000</td>\\    </tr>\\    <tr>\\      <th>461</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.487333</td>\\    </tr>\\    <tr>\\      <th>462</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.530667</td>\\    </tr>\\    <tr>\\      <th>463</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.439000</td>\\    </tr>\\    <tr>\\      <th>464</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.625667</td>\\    </tr>\\    <tr>\\      <th>465</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.586000</td>\\    </tr>\\    <tr>\\      <th>466</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.615000</td>\\    </tr>\\    <tr>\\      <th>467</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.556000</td>\\    </tr>\\    <tr>\\      <th>468</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.626333</td>\\    </tr>\\    <tr>\\      <th>469</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.587333</td>\\    </tr>\\    <tr>\\      <th>470</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.600333</td>\\    </tr>\\    <tr>\\      <th>471</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.563000</td>\\    </tr>\\    <tr>\\      <th>472</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.625667</td>\\    </tr>\\    <tr>\\      <th>473</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.579000</td>\\    </tr>\\    <tr>\\      <th>474</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.602667</td>\\    </tr>\\    <tr>\\      <th>475</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.556667</td>\\    </tr>\\    <tr>\\      <th>476</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.616000</td>\\    </tr>\\    <tr>\\      <th>477</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.584000</td>\\    </tr>\\    <tr>\\      <th>478</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.589333</td>\\    </tr>\\    <tr>\\      <th>479</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.550333</td>\\    </tr>\\    <tr>\\      <th>480</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.638000</td>\\    </tr>\\    <tr>\\      <th>481</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.616667</td>\\    </tr>\\    <tr>\\      <th>482</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.646333</td>\\    </tr>\\    <tr>\\      <th>483</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.590333</td>\\    </tr>\\    <tr>\\      <th>484</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.652000</td>\\    </tr>\\    <tr>\\      <th>485</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.619333</td>\\    </tr>\\    <tr>\\      <th>486</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.630667</td>\\    </tr>\\    <tr>\\      <th>487</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.594333</td>\\    </tr>\\    <tr>\\      <th>488</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.644667</td>\\    </tr>\\    <tr>\\      <th>489</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.639333</td>\\    </tr>\\    <tr>\\      <th>490</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.629667</td>\\    </tr>\\    <tr>\\      <th>491</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.607333</td>\\    </tr>\\    <tr>\\      <th>492</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.651667</td>\\    </tr>\\    <tr>\\      <th>493</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.632667</td>\\    </tr>\\    <tr>\\      <th>494</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.636667</td>\\    </tr>\\    <tr>\\      <th>495</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.592333</td>\\    </tr>\\    <tr>\\      <th>496</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.659667</td>\\    </tr>\\    <tr>\\      <th>497</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.642667</td>\\    </tr>\\    <tr>\\      <th>498</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.648333</td>\\    </tr>\\    <tr>\\      <th>499</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.626667</td>\\    </tr>\\    <tr>\\      <th>500</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.654667</td>\\    </tr>\\    <tr>\\      <th>501</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.631333</td>\\    </tr>\\    <tr>\\      <th>502</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.654667</td>\\    </tr>\\    <tr>\\      <th>503</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.626333</td>\\    </tr>\\    <tr>\\      <th>504</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.656333</td>\\    </tr>\\    <tr>\\      <th>505</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.640667</td>\\    </tr>\\    <tr>\\      <th>506</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.649667</td>\\    </tr>\\    <tr>\\      <th>507</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.630667</td>\\    </tr>\\    <tr>\\      <th>508</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.658333</td>\\    </tr>\\    <tr>\\      <th>509</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.653333</td>\\    </tr>\\    <tr>\\      <th>510</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.656333</td>\\    </tr>\\    <tr>\\      <th>511</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.635333</td>\\    </tr>\\    <tr>\\      <th>512</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.581667</td>\\    </tr>\\    <tr>\\      <th>513</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.530000</td>\\    </tr>\\    <tr>\\      <th>514</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.550000</td>\\    </tr>\\    <tr>\\      <th>515</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.498333</td>\\    </tr>\\    <tr>\\      <th>516</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.588667</td>\\    </tr>\\    <tr>\\      <th>517</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.501000</td>\\    </tr>\\    <tr>\\      <th>518</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.544333</td>\\    </tr>\\    <tr>\\      <th>519</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.490333</td>\\    </tr>\\    <tr>\\      <th>520</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.577000</td>\\    </tr>\\    <tr>\\      <th>521</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.515000</td>\\    </tr>\\    <tr>\\      <th>522</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.565000</td>\\    </tr>\\    <tr>\\      <th>523</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.502667</td>\\    </tr>\\    <tr>\\      <th>524</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.570333</td>\\    </tr>\\    <tr>\\      <th>525</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.519333</td>\\    </tr>\\    <tr>\\      <th>526</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.568667</td>\\    </tr>\\    <tr>\\      <th>527</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.464333</td>\\    </tr>\\    <tr>\\      <th>528</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.626667</td>\\    </tr>\\    <tr>\\      <th>529</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.590333</td>\\    </tr>\\    <tr>\\      <th>530</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.629667</td>\\    </tr>\\    <tr>\\      <th>531</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.582333</td>\\    </tr>\\    <tr>\\      <th>532</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.620333</td>\\    </tr>\\    <tr>\\      <th>533</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.601333</td>\\    </tr>\\    <tr>\\      <th>534</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.621333</td>\\    </tr>\\    <tr>\\      <th>535</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.573000</td>\\    </tr>\\    <tr>\\      <th>536</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.633000</td>\\    </tr>\\    <tr>\\      <th>537</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.604000</td>\\    </tr>\\    <tr>\\      <th>538</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.627333</td>\\    </tr>\\    <tr>\\      <th>539</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.566667</td>\\    </tr>\\    <tr>\\      <th>540</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.631333</td>\\    </tr>\\    <tr>\\      <th>541</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.606333</td>\\    </tr>\\    <tr>\\      <th>542</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.622000</td>\\    </tr>\\    <tr>\\      <th>543</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.572667</td>\\    </tr>\\    <tr>\\      <th>544</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.651333</td>\\    </tr>\\    <tr>\\      <th>545</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.625000</td>\\    </tr>\\    <tr>\\      <th>546</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.644000</td>\\    </tr>\\    <tr>\\      <th>547</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.608000</td>\\    </tr>\\    <tr>\\      <th>548</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.653333</td>\\    </tr>\\    <tr>\\      <th>549</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.629667</td>\\    </tr>\\    <tr>\\      <th>550</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.642333</td>\\    </tr>\\    <tr>\\      <th>551</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.604000</td>\\    </tr>\\    <tr>\\      <th>552</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.655667</td>\\    </tr>\\    <tr>\\      <th>553</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.625667</td>\\    </tr>\\    <tr>\\      <th>554</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.655000</td>\\    </tr>\\    <tr>\\      <th>555</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.614667</td>\\    </tr>\\    <tr>\\      <th>556</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.654000</td>\\    </tr>\\    <tr>\\      <th>557</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.632333</td>\\    </tr>\\    <tr>\\      <th>558</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.647000</td>\\    </tr>\\    <tr>\\      <th>559</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.617667</td>\\    </tr>\\    <tr>\\      <th>560</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.664000</td>\\    </tr>\\    <tr>\\      <th>561</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.647333</td>\\    </tr>\\    <tr>\\      <th>562</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.661333</td>\\    </tr>\\    <tr>\\      <th>563</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.642000</td>\\    </tr>\\    <tr>\\      <th>564</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.657667</td>\\    </tr>\\    <tr>\\      <th>565</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.654667</td>\\    </tr>\\    <tr>\\      <th>566</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.662000</td>\\    </tr>\\    <tr>\\      <th>567</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.635667</td>\\    </tr>\\    <tr>\\      <th>568</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.658000</td>\\    </tr>\\    <tr>\\      <th>569</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.639333</td>\\    </tr>\\    <tr>\\      <th>570</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.675333</td>\\    </tr>\\    <tr>\\      <th>571</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.634333</td>\\    </tr>\\    <tr>\\      <th>572</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.664333</td>\\    </tr>\\    <tr>\\      <th>573</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.655000</td>\\    </tr>\\    <tr>\\      <th>574</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.658000</td>\\    </tr>\\    <tr>\\      <th>575</th>\\      <td>balanced_subsample</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.634667</td>\\    </tr>\\    <tr>\\      <th>576</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>577</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>578</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>579</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>580</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>581</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>582</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>583</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>584</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>585</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>586</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>587</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>588</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>589</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>590</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>591</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>592</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>593</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>594</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>595</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>596</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>597</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>598</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>599</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>600</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>601</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>602</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>603</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>604</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>605</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>606</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>607</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>608</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>609</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>610</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>611</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>612</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>613</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>614</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>615</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>616</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>617</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>618</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>619</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>620</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>621</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>622</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>623</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>624</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>625</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>626</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>627</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>628</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>629</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>630</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>631</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>632</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>633</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>634</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>635</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>636</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>637</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>638</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>639</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>640</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.349333</td>\\    </tr>\\    <tr>\\      <th>641</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.231667</td>\\    </tr>\\    <tr>\\      <th>642</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.359667</td>\\    </tr>\\    <tr>\\      <th>643</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.237333</td>\\    </tr>\\    <tr>\\      <th>644</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.347000</td>\\    </tr>\\    <tr>\\      <th>645</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.259333</td>\\    </tr>\\    <tr>\\      <th>646</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.341000</td>\\    </tr>\\    <tr>\\      <th>647</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.225333</td>\\    </tr>\\    <tr>\\      <th>648</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.364667</td>\\    </tr>\\    <tr>\\      <th>649</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.240667</td>\\    </tr>\\    <tr>\\      <th>650</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.344333</td>\\    </tr>\\    <tr>\\      <th>651</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.234667</td>\\    </tr>\\    <tr>\\      <th>652</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.369000</td>\\    </tr>\\    <tr>\\      <th>653</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.243000</td>\\    </tr>\\    <tr>\\      <th>654</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.327333</td>\\    </tr>\\    <tr>\\      <th>655</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.227333</td>\\    </tr>\\    <tr>\\      <th>656</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.454667</td>\\    </tr>\\    <tr>\\      <th>657</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.339000</td>\\    </tr>\\    <tr>\\      <th>658</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.409667</td>\\    </tr>\\    <tr>\\      <th>659</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.322333</td>\\    </tr>\\    <tr>\\      <th>660</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.467333</td>\\    </tr>\\    <tr>\\      <th>661</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.342333</td>\\    </tr>\\    <tr>\\      <th>662</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.417000</td>\\    </tr>\\    <tr>\\      <th>663</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.318333</td>\\    </tr>\\    <tr>\\      <th>664</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.465333</td>\\    </tr>\\    <tr>\\      <th>665</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.330000</td>\\    </tr>\\    <tr>\\      <th>666</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.420000</td>\\    </tr>\\    <tr>\\      <th>667</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.331333</td>\\    </tr>\\    <tr>\\      <th>668</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.458333</td>\\    </tr>\\    <tr>\\      <th>669</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.330333</td>\\    </tr>\\    <tr>\\      <th>670</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.420000</td>\\    </tr>\\    <tr>\\      <th>671</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.322333</td>\\    </tr>\\    <tr>\\      <th>672</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.494000</td>\\    </tr>\\    <tr>\\      <th>673</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.411667</td>\\    </tr>\\    <tr>\\      <th>674</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.484000</td>\\    </tr>\\    <tr>\\      <th>675</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.367000</td>\\    </tr>\\    <tr>\\      <th>676</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.518667</td>\\    </tr>\\    <tr>\\      <th>677</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.408000</td>\\    </tr>\\    <tr>\\      <th>678</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.493000</td>\\    </tr>\\    <tr>\\      <th>679</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.369667</td>\\    </tr>\\    <tr>\\      <th>680</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.501000</td>\\    </tr>\\    <tr>\\      <th>681</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.399667</td>\\    </tr>\\    <tr>\\      <th>682</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.489000</td>\\    </tr>\\    <tr>\\      <th>683</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.376000</td>\\    </tr>\\    <tr>\\      <th>684</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.495667</td>\\    </tr>\\    <tr>\\      <th>685</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.401000</td>\\    </tr>\\    <tr>\\      <th>686</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.486667</td>\\    </tr>\\    <tr>\\      <th>687</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.380667</td>\\    </tr>\\    <tr>\\      <th>688</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.529667</td>\\    </tr>\\    <tr>\\      <th>689</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.452000</td>\\    </tr>\\    <tr>\\      <th>690</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.525333</td>\\    </tr>\\    <tr>\\      <th>691</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.419667</td>\\    </tr>\\    <tr>\\      <th>692</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.548000</td>\\    </tr>\\    <tr>\\      <th>693</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.451333</td>\\    </tr>\\    <tr>\\      <th>694</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.517333</td>\\    </tr>\\    <tr>\\      <th>695</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.414333</td>\\    </tr>\\    <tr>\\      <th>696</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.541667</td>\\    </tr>\\    <tr>\\      <th>697</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.457000</td>\\    </tr>\\    <tr>\\      <th>698</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.522333</td>\\    </tr>\\    <tr>\\      <th>699</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.419333</td>\\    </tr>\\    <tr>\\      <th>700</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.539000</td>\\    </tr>\\    <tr>\\      <th>701</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.454000</td>\\    </tr>\\    <tr>\\      <th>702</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.526000</td>\\    </tr>\\    <tr>\\      <th>703</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.416333</td>\\    </tr>\\    <tr>\\      <th>704</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.408000</td>\\    </tr>\\    <tr>\\      <th>705</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.285000</td>\\    </tr>\\    <tr>\\      <th>706</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.365333</td>\\    </tr>\\    <tr>\\      <th>707</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.259333</td>\\    </tr>\\    <tr>\\      <th>708</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.392000</td>\\    </tr>\\    <tr>\\      <th>709</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.262333</td>\\    </tr>\\    <tr>\\      <th>710</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.380667</td>\\    </tr>\\    <tr>\\      <th>711</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.266667</td>\\    </tr>\\    <tr>\\      <th>712</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.397000</td>\\    </tr>\\    <tr>\\      <th>713</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.261333</td>\\    </tr>\\    <tr>\\      <th>714</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.371667</td>\\    </tr>\\    <tr>\\      <th>715</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.268333</td>\\    </tr>\\    <tr>\\      <th>716</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.400667</td>\\    </tr>\\    <tr>\\      <th>717</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.291333</td>\\    </tr>\\    <tr>\\      <th>718</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.401000</td>\\    </tr>\\    <tr>\\      <th>719</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.284333</td>\\    </tr>\\    <tr>\\      <th>720</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.501667</td>\\    </tr>\\    <tr>\\      <th>721</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.348667</td>\\    </tr>\\    <tr>\\      <th>722</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.462000</td>\\    </tr>\\    <tr>\\      <th>723</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.338667</td>\\    </tr>\\    <tr>\\      <th>724</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.476667</td>\\    </tr>\\    <tr>\\      <th>725</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.381000</td>\\    </tr>\\    <tr>\\      <th>726</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.475333</td>\\    </tr>\\    <tr>\\      <th>727</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.351667</td>\\    </tr>\\    <tr>\\      <th>728</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.496000</td>\\    </tr>\\    <tr>\\      <th>729</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.366667</td>\\    </tr>\\    <tr>\\      <th>730</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.462667</td>\\    </tr>\\    <tr>\\      <th>731</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.355667</td>\\    </tr>\\    <tr>\\      <th>732</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.479333</td>\\    </tr>\\    <tr>\\      <th>733</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.373667</td>\\    </tr>\\    <tr>\\      <th>734</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.456333</td>\\    </tr>\\    <tr>\\      <th>735</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.352667</td>\\    </tr>\\    <tr>\\      <th>736</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.539000</td>\\    </tr>\\    <tr>\\      <th>737</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.418667</td>\\    </tr>\\    <tr>\\      <th>738</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.524000</td>\\    </tr>\\    <tr>\\      <th>739</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.412000</td>\\    </tr>\\    <tr>\\      <th>740</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.534333</td>\\    </tr>\\    <tr>\\      <th>741</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.417333</td>\\    </tr>\\    <tr>\\      <th>742</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.516333</td>\\    </tr>\\    <tr>\\      <th>743</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.404000</td>\\    </tr>\\    <tr>\\      <th>744</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.532333</td>\\    </tr>\\    <tr>\\      <th>745</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.430000</td>\\    </tr>\\    <tr>\\      <th>746</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.526333</td>\\    </tr>\\    <tr>\\      <th>747</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.405333</td>\\    </tr>\\    <tr>\\      <th>748</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.537667</td>\\    </tr>\\    <tr>\\      <th>749</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.421333</td>\\    </tr>\\    <tr>\\      <th>750</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.515000</td>\\    </tr>\\    <tr>\\      <th>751</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.405000</td>\\    </tr>\\    <tr>\\      <th>752</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.558333</td>\\    </tr>\\    <tr>\\      <th>753</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.468333</td>\\    </tr>\\    <tr>\\      <th>754</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.551000</td>\\    </tr>\\    <tr>\\      <th>755</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.458000</td>\\    </tr>\\    <tr>\\      <th>756</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.556667</td>\\    </tr>\\    <tr>\\      <th>757</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.469333</td>\\    </tr>\\    <tr>\\      <th>758</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.555667</td>\\    </tr>\\    <tr>\\      <th>759</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.454333</td>\\    </tr>\\    <tr>\\      <th>760</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.555667</td>\\    </tr>\\    <tr>\\      <th>761</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.470333</td>\\    </tr>\\    <tr>\\      <th>762</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.553333</td>\\    </tr>\\    <tr>\\      <th>763</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.452000</td>\\    </tr>\\    <tr>\\      <th>764</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.567333</td>\\    </tr>\\    <tr>\\      <th>765</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.466000</td>\\    </tr>\\    <tr>\\      <th>766</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.557000</td>\\    </tr>\\    <tr>\\      <th>767</th>\\      <td>balanced_subsample</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.442333</td>\\    </tr>\\    <tr>\\      <th>768</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>769</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>770</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>771</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>772</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>773</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>774</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>775</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>776</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>777</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>778</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>779</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>780</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>781</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>782</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>783</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>784</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>785</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>786</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>787</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>788</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>789</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>790</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>791</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>792</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>793</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>794</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>795</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>796</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>797</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>798</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>799</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>800</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>801</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>802</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>803</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>804</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>805</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>806</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>807</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>808</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>809</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>810</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>811</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>812</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>813</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>814</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>815</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>816</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>817</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>818</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>819</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>820</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>821</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>822</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>823</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>824</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>825</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>826</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>827</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>828</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>829</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>830</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>831</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>832</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.567000</td>\\    </tr>\\    <tr>\\      <th>833</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.485333</td>\\    </tr>\\    <tr>\\      <th>834</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.551667</td>\\    </tr>\\    <tr>\\      <th>835</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.445000</td>\\    </tr>\\    <tr>\\      <th>836</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.560667</td>\\    </tr>\\    <tr>\\      <th>837</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.495333</td>\\    </tr>\\    <tr>\\      <th>838</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.530333</td>\\    </tr>\\    <tr>\\      <th>839</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.441667</td>\\    </tr>\\    <tr>\\      <th>840</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.553667</td>\\    </tr>\\    <tr>\\      <th>841</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.501333</td>\\    </tr>\\    <tr>\\      <th>842</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.522333</td>\\    </tr>\\    <tr>\\      <th>843</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.455333</td>\\    </tr>\\    <tr>\\      <th>844</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.558667</td>\\    </tr>\\    <tr>\\      <th>845</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.499667</td>\\    </tr>\\    <tr>\\      <th>846</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.535000</td>\\    </tr>\\    <tr>\\      <th>847</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.443333</td>\\    </tr>\\    <tr>\\      <th>848</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.621333</td>\\    </tr>\\    <tr>\\      <th>849</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.579000</td>\\    </tr>\\    <tr>\\      <th>850</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.599667</td>\\    </tr>\\    <tr>\\      <th>851</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.546667</td>\\    </tr>\\    <tr>\\      <th>852</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.621333</td>\\    </tr>\\    <tr>\\      <th>853</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.572333</td>\\    </tr>\\    <tr>\\      <th>854</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.604333</td>\\    </tr>\\    <tr>\\      <th>855</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.556333</td>\\    </tr>\\    <tr>\\      <th>856</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.616333</td>\\    </tr>\\    <tr>\\      <th>857</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.579333</td>\\    </tr>\\    <tr>\\      <th>858</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.610000</td>\\    </tr>\\    <tr>\\      <th>859</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.545333</td>\\    </tr>\\    <tr>\\      <th>860</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.622000</td>\\    </tr>\\    <tr>\\      <th>861</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.583000</td>\\    </tr>\\    <tr>\\      <th>862</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.603333</td>\\    </tr>\\    <tr>\\      <th>863</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.545667</td>\\    </tr>\\    <tr>\\      <th>864</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.642000</td>\\    </tr>\\    <tr>\\      <th>865</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.615667</td>\\    </tr>\\    <tr>\\      <th>866</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.636667</td>\\    </tr>\\    <tr>\\      <th>867</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.603667</td>\\    </tr>\\    <tr>\\      <th>868</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.644000</td>\\    </tr>\\    <tr>\\      <th>869</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.624333</td>\\    </tr>\\    <tr>\\      <th>870</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.636333</td>\\    </tr>\\    <tr>\\      <th>871</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.600333</td>\\    </tr>\\    <tr>\\      <th>872</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.649000</td>\\    </tr>\\    <tr>\\      <th>873</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.617000</td>\\    </tr>\\    <tr>\\      <th>874</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.636667</td>\\    </tr>\\    <tr>\\      <th>875</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.601000</td>\\    </tr>\\    <tr>\\      <th>876</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.645667</td>\\    </tr>\\    <tr>\\      <th>877</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.618333</td>\\    </tr>\\    <tr>\\      <th>878</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.641667</td>\\    </tr>\\    <tr>\\      <th>879</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.603667</td>\\    </tr>\\    <tr>\\      <th>880</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.658333</td>\\    </tr>\\    <tr>\\      <th>881</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.653333</td>\\    </tr>\\    <tr>\\      <th>882</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.656000</td>\\    </tr>\\    <tr>\\      <th>883</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.622667</td>\\    </tr>\\    <tr>\\      <th>884</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.660333</td>\\    </tr>\\    <tr>\\      <th>885</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.647667</td>\\    </tr>\\    <tr>\\      <th>886</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.657333</td>\\    </tr>\\    <tr>\\      <th>887</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.627000</td>\\    </tr>\\    <tr>\\      <th>888</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.656333</td>\\    </tr>\\    <tr>\\      <th>889</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.640000</td>\\    </tr>\\    <tr>\\      <th>890</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.661333</td>\\    </tr>\\    <tr>\\      <th>891</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.621667</td>\\    </tr>\\    <tr>\\      <th>892</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.657000</td>\\    </tr>\\    <tr>\\      <th>893</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.645000</td>\\    </tr>\\    <tr>\\      <th>894</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.650000</td>\\    </tr>\\    <tr>\\      <th>895</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.633333</td>\\    </tr>\\    <tr>\\      <th>896</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.580000</td>\\    </tr>\\    <tr>\\      <th>897</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.502667</td>\\    </tr>\\    <tr>\\      <th>898</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.539333</td>\\    </tr>\\    <tr>\\      <th>899</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.482333</td>\\    </tr>\\    <tr>\\      <th>900</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.581333</td>\\    </tr>\\    <tr>\\      <th>901</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.506667</td>\\    </tr>\\    <tr>\\      <th>902</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.555667</td>\\    </tr>\\    <tr>\\      <th>903</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.488667</td>\\    </tr>\\    <tr>\\      <th>904</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.580333</td>\\    </tr>\\    <tr>\\      <th>905</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.508667</td>\\    </tr>\\    <tr>\\      <th>906</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.563667</td>\\    </tr>\\    <tr>\\      <th>907</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.497667</td>\\    </tr>\\    <tr>\\      <th>908</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.575667</td>\\    </tr>\\    <tr>\\      <th>909</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.507333</td>\\    </tr>\\    <tr>\\      <th>910</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.553333</td>\\    </tr>\\    <tr>\\      <th>911</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.470000</td>\\    </tr>\\    <tr>\\      <th>912</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.625000</td>\\    </tr>\\    <tr>\\      <th>913</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.576667</td>\\    </tr>\\    <tr>\\      <th>914</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.623667</td>\\    </tr>\\    <tr>\\      <th>915</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.584333</td>\\    </tr>\\    <tr>\\      <th>916</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.635333</td>\\    </tr>\\    <tr>\\      <th>917</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.597333</td>\\    </tr>\\    <tr>\\      <th>918</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.631333</td>\\    </tr>\\    <tr>\\      <th>919</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.578000</td>\\    </tr>\\    <tr>\\      <th>920</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.638667</td>\\    </tr>\\    <tr>\\      <th>921</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.595333</td>\\    </tr>\\    <tr>\\      <th>922</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.623000</td>\\    </tr>\\    <tr>\\      <th>923</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.577000</td>\\    </tr>\\    <tr>\\      <th>924</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.625667</td>\\    </tr>\\    <tr>\\      <th>925</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.589333</td>\\    </tr>\\    <tr>\\      <th>926</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.618333</td>\\    </tr>\\    <tr>\\      <th>927</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.577667</td>\\    </tr>\\    <tr>\\      <th>928</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.650333</td>\\    </tr>\\    <tr>\\      <th>929</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.622333</td>\\    </tr>\\    <tr>\\      <th>930</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.653667</td>\\    </tr>\\    <tr>\\      <th>931</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.608667</td>\\    </tr>\\    <tr>\\      <th>932</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.656000</td>\\    </tr>\\    <tr>\\      <th>933</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.635000</td>\\    </tr>\\    <tr>\\      <th>934</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.647667</td>\\    </tr>\\    <tr>\\      <th>935</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.608333</td>\\    </tr>\\    <tr>\\      <th>936</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.651333</td>\\    </tr>\\    <tr>\\      <th>937</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.630333</td>\\    </tr>\\    <tr>\\      <th>938</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.644667</td>\\    </tr>\\    <tr>\\      <th>939</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.621667</td>\\    </tr>\\    <tr>\\      <th>940</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.645000</td>\\    </tr>\\    <tr>\\      <th>941</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.625000</td>\\    </tr>\\    <tr>\\      <th>942</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.641000</td>\\    </tr>\\    <tr>\\      <th>943</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.607667</td>\\    </tr>\\    <tr>\\      <th>944</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.665333</td>\\    </tr>\\    <tr>\\      <th>945</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.649000</td>\\    </tr>\\    <tr>\\      <th>946</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.667333</td>\\    </tr>\\    <tr>\\      <th>947</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.630000</td>\\    </tr>\\    <tr>\\      <th>948</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.661333</td>\\    </tr>\\    <tr>\\      <th>949</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.648000</td>\\    </tr>\\    <tr>\\      <th>950</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.666000</td>\\    </tr>\\    <tr>\\      <th>951</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.634667</td>\\    </tr>\\    <tr>\\      <th>952</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.663000</td>\\    </tr>\\    <tr>\\      <th>953</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.654000</td>\\    </tr>\\    <tr>\\      <th>954</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.658333</td>\\    </tr>\\    <tr>\\      <th>955</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.636667</td>\\    </tr>\\    <tr>\\      <th>956</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.656667</td>\\    </tr>\\    <tr>\\      <th>957</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.644667</td>\\    </tr>\\    <tr>\\      <th>958</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.664333</td>\\    </tr>\\    <tr>\\      <th>959</th>\\      <td>None</td>\\      <td>gini</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.646000</td>\\    </tr>\\    <tr>\\      <th>960</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>961</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>962</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>963</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>964</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>965</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>966</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>967</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>968</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>969</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>970</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>971</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>972</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>973</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>974</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>975</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>976</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>977</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>978</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>979</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>980</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>981</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>982</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>983</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>984</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>985</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>986</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>987</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>988</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>989</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>990</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>991</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>992</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>993</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>994</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>995</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>996</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>997</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>998</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>999</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>1000</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>1001</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>1002</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>1003</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>1004</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>1005</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>1006</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>1007</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>1008</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>1009</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>1010</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>1011</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>1012</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>1013</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>1014</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>1015</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>1016</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>1017</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>1018</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>1019</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>1020</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>1021</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>1022</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>1023</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>1</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>NaN</td>\\    </tr>\\    <tr>\\      <th>1024</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.348000</td>\\    </tr>\\    <tr>\\      <th>1025</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.249000</td>\\    </tr>\\    <tr>\\      <th>1026</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.345333</td>\\    </tr>\\    <tr>\\      <th>1027</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.231667</td>\\    </tr>\\    <tr>\\      <th>1028</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.380667</td>\\    </tr>\\    <tr>\\      <th>1029</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.253667</td>\\    </tr>\\    <tr>\\      <th>1030</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.335333</td>\\    </tr>\\    <tr>\\      <th>1031</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.236333</td>\\    </tr>\\    <tr>\\      <th>1032</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.345000</td>\\    </tr>\\    <tr>\\      <th>1033</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.253000</td>\\    </tr>\\    <tr>\\      <th>1034</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.345000</td>\\    </tr>\\    <tr>\\      <th>1035</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.230000</td>\\    </tr>\\    <tr>\\      <th>1036</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.358333</td>\\    </tr>\\    <tr>\\      <th>1037</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.255000</td>\\    </tr>\\    <tr>\\      <th>1038</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.310667</td>\\    </tr>\\    <tr>\\      <th>1039</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.251333</td>\\    </tr>\\    <tr>\\      <th>1040</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.451333</td>\\    </tr>\\    <tr>\\      <th>1041</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.330000</td>\\    </tr>\\    <tr>\\      <th>1042</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.437667</td>\\    </tr>\\    <tr>\\      <th>1043</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.330333</td>\\    </tr>\\    <tr>\\      <th>1044</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.453333</td>\\    </tr>\\    <tr>\\      <th>1045</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.346333</td>\\    </tr>\\    <tr>\\      <th>1046</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.421000</td>\\    </tr>\\    <tr>\\      <th>1047</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.311000</td>\\    </tr>\\    <tr>\\      <th>1048</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.446667</td>\\    </tr>\\    <tr>\\      <th>1049</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.348000</td>\\    </tr>\\    <tr>\\      <th>1050</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.424667</td>\\    </tr>\\    <tr>\\      <th>1051</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.318000</td>\\    </tr>\\    <tr>\\      <th>1052</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.461667</td>\\    </tr>\\    <tr>\\      <th>1053</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.347000</td>\\    </tr>\\    <tr>\\      <th>1054</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.452667</td>\\    </tr>\\    <tr>\\      <th>1055</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.329667</td>\\    </tr>\\    <tr>\\      <th>1056</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.510000</td>\\    </tr>\\    <tr>\\      <th>1057</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.391000</td>\\    </tr>\\    <tr>\\      <th>1058</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.480333</td>\\    </tr>\\    <tr>\\      <th>1059</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.384000</td>\\    </tr>\\    <tr>\\      <th>1060</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.515667</td>\\    </tr>\\    <tr>\\      <th>1061</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.385333</td>\\    </tr>\\    <tr>\\      <th>1062</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.491333</td>\\    </tr>\\    <tr>\\      <th>1063</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.377333</td>\\    </tr>\\    <tr>\\      <th>1064</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.527333</td>\\    </tr>\\    <tr>\\      <th>1065</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.405000</td>\\    </tr>\\    <tr>\\      <th>1066</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.495333</td>\\    </tr>\\    <tr>\\      <th>1067</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.387000</td>\\    </tr>\\    <tr>\\      <th>1068</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.510667</td>\\    </tr>\\    <tr>\\      <th>1069</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.408333</td>\\    </tr>\\    <tr>\\      <th>1070</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.499333</td>\\    </tr>\\    <tr>\\      <th>1071</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.385333</td>\\    </tr>\\    <tr>\\      <th>1072</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.550333</td>\\    </tr>\\    <tr>\\      <th>1073</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.456333</td>\\    </tr>\\    <tr>\\      <th>1074</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.536000</td>\\    </tr>\\    <tr>\\      <th>1075</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.433333</td>\\    </tr>\\    <tr>\\      <th>1076</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.541667</td>\\    </tr>\\    <tr>\\      <th>1077</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.445667</td>\\    </tr>\\    <tr>\\      <th>1078</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.531667</td>\\    </tr>\\    <tr>\\      <th>1079</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.429667</td>\\    </tr>\\    <tr>\\      <th>1080</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.552667</td>\\    </tr>\\    <tr>\\      <th>1081</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.446333</td>\\    </tr>\\    <tr>\\      <th>1082</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.528333</td>\\    </tr>\\    <tr>\\      <th>1083</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.437667</td>\\    </tr>\\    <tr>\\      <th>1084</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.540667</td>\\    </tr>\\    <tr>\\      <th>1085</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.458333</td>\\    </tr>\\    <tr>\\      <th>1086</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.533333</td>\\    </tr>\\    <tr>\\      <th>1087</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>2</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.443000</td>\\    </tr>\\    <tr>\\      <th>1088</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.385667</td>\\    </tr>\\    <tr>\\      <th>1089</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.266667</td>\\    </tr>\\    <tr>\\      <th>1090</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.369000</td>\\    </tr>\\    <tr>\\      <th>1091</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.261667</td>\\    </tr>\\    <tr>\\      <th>1092</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.390000</td>\\    </tr>\\    <tr>\\      <th>1093</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.265333</td>\\    </tr>\\    <tr>\\      <th>1094</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.376667</td>\\    </tr>\\    <tr>\\      <th>1095</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.268333</td>\\    </tr>\\    <tr>\\      <th>1096</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.378667</td>\\    </tr>\\    <tr>\\      <th>1097</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.272000</td>\\    </tr>\\    <tr>\\      <th>1098</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.374667</td>\\    </tr>\\    <tr>\\      <th>1099</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.278333</td>\\    </tr>\\    <tr>\\      <th>1100</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.385000</td>\\    </tr>\\    <tr>\\      <th>1101</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.272000</td>\\    </tr>\\    <tr>\\      <th>1102</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.372333</td>\\    </tr>\\    <tr>\\      <th>1103</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>20</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.269000</td>\\    </tr>\\    <tr>\\      <th>1104</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.480000</td>\\    </tr>\\    <tr>\\      <th>1105</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.379000</td>\\    </tr>\\    <tr>\\      <th>1106</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.459333</td>\\    </tr>\\    <tr>\\      <th>1107</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.376667</td>\\    </tr>\\    <tr>\\      <th>1108</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.504333</td>\\    </tr>\\    <tr>\\      <th>1109</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.368000</td>\\    </tr>\\    <tr>\\      <th>1110</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.448333</td>\\    </tr>\\    <tr>\\      <th>1111</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.324000</td>\\    </tr>\\    <tr>\\      <th>1112</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.505333</td>\\    </tr>\\    <tr>\\      <th>1113</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.358000</td>\\    </tr>\\    <tr>\\      <th>1114</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.475333</td>\\    </tr>\\    <tr>\\      <th>1115</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.346333</td>\\    </tr>\\    <tr>\\      <th>1116</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.479000</td>\\    </tr>\\    <tr>\\      <th>1117</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.353000</td>\\    </tr>\\    <tr>\\      <th>1118</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.466333</td>\\    </tr>\\    <tr>\\      <th>1119</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>50</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.345333</td>\\    </tr>\\    <tr>\\      <th>1120</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.537000</td>\\    </tr>\\    <tr>\\      <th>1121</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.414667</td>\\    </tr>\\    <tr>\\      <th>1122</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.511333</td>\\    </tr>\\    <tr>\\      <th>1123</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.414667</td>\\    </tr>\\    <tr>\\      <th>1124</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.535000</td>\\    </tr>\\    <tr>\\      <th>1125</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.422333</td>\\    </tr>\\    <tr>\\      <th>1126</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.519667</td>\\    </tr>\\    <tr>\\      <th>1127</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.420000</td>\\    </tr>\\    <tr>\\      <th>1128</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.531333</td>\\    </tr>\\    <tr>\\      <th>1129</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.419000</td>\\    </tr>\\    <tr>\\      <th>1130</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.516000</td>\\    </tr>\\    <tr>\\      <th>1131</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.414000</td>\\    </tr>\\    <tr>\\      <th>1132</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.534333</td>\\    </tr>\\    <tr>\\      <th>1133</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.417333</td>\\    </tr>\\    <tr>\\      <th>1134</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.524000</td>\\    </tr>\\    <tr>\\      <th>1135</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>100</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.400667</td>\\    </tr>\\    <tr>\\      <th>1136</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.561333</td>\\    </tr>\\    <tr>\\      <th>1137</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.470333</td>\\    </tr>\\    <tr>\\      <th>1138</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.548667</td>\\    </tr>\\    <tr>\\      <th>1139</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.449333</td>\\    </tr>\\    <tr>\\      <th>1140</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.555667</td>\\    </tr>\\    <tr>\\      <th>1141</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.469667</td>\\    </tr>\\    <tr>\\      <th>1142</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.546667</td>\\    </tr>\\    <tr>\\      <th>1143</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>True</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.458667</td>\\    </tr>\\    <tr>\\      <th>1144</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.565000</td>\\    </tr>\\    <tr>\\      <th>1145</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.471333</td>\\    </tr>\\    <tr>\\      <th>1146</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.549667</td>\\    </tr>\\    <tr>\\      <th>1147</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>True</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.438667</td>\\    </tr>\\    <tr>\\      <th>1148</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>english</td>\\      <td>0.556667</td>\\    </tr>\\    <tr>\\      <th>1149</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 1)</td>\\      <td>None</td>\\      <td>0.473333</td>\\    </tr>\\    <tr>\\      <th>1150</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>english</td>\\      <td>0.555667</td>\\    </tr>\\    <tr>\\      <th>1151</th>\\      <td>None</td>\\      <td>entropy</td>\\      <td>3</td>\\      <td>200</td>\\      <td>False</td>\\      <td>False</td>\\      <td>(1, 2)</td>\\      <td>None</td>\\      <td>0.431000</td>\\    </tr>\\  </tbody>\\</table><style>\\    table { border-collapse: collapse; border: 3px solid #eee; }\\    table tr th:first-child { background-color: #eeeeee; color: #333; font-weight: bold }\\    table thead th { background-color: #eee; color: #000; }\\    tr, th, td { border: 1px solid #ccc; border-width: 1px 0 0 1px; border-collapse: collapse;\\    padding: 3px; font-family: monospace; font-size: 10px }</style>\\    ';</script><style>\n",
       "    table { border-collapse: collapse; border: 3px solid #eee; }\n",
       "    table tr th:first-child { background-color: #eeeeee; color: #333; font-weight: bold }\n",
       "    table thead th { background-color: #eee; color: #000; }\n",
       "    tr, th, td { border: 1px solid #ccc; border-width: 1px 0 0 1px; border-collapse: collapse;\n",
       "    padding: 3px; font-family: monospace; font-size: 10px }</style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
